# ml4cvd
Machine Learning for CardioVascular Disease - MGH/MIT edition!

## Contents
- [Setup](#setup)
- [Modes](#modes)
- [Jupyer Lab](#jupyter-lab)
- [Run scripts](#run-scripts)
- [Tests](#tests)
- [TensorMaps](#tensormaps)
- [Tensorize ECGs](docs/tensorize_ecgs.md)
- [Deidentify data](docs/deidentify.md)
- [Contribute](#contribute)

## Setup
1. install [docker](https://docs.docker.com/get-docker/) and [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/)
2. add user to group to run docker
    ```
    sudo usermod -aG docker $USER
    ```
3. build docker image
    ```
    ./docker/build.sh [-c for CPU image]
    ```
4. setup conda environment to install pre-commit into
    ```
    make setup
    ```
5. activate conda environment so that pre-commit hooks are run
    ```
    conda activate ml4cvd
    ```

## Modes

#### train
Dynamically generate, train, and evaluate a machine learning model.
```
./scripts/run.sh -t $PWD/ml4cvd/recipes.py \
--mode train \
--tensors /path/to/data \
--input_tensors ecg_signal \
--output_tensors patient_outcome \
--output_folder results \
--id my-experiment
```

#### infer
Evaluate model performance and save model predictions for inspection. The number of samples inferred is controlled by `--batch_size` and `--test_steps`
```
./scripts/run.sh -t $PWD/ml4cvd/recipes.py \
--mode infer \
--tensors /path/to/data \
--input_tensors ecg_signal \
--output_tensors patient_outcome \
--batch_size 64 \
--test_steps 100 \
--output_folder results \
--id my-inference
```

#### plot_ecg
Plot ECGs generated by the GE Muse system that have been tensorized to HD5 format. Supports plotting in two modes: `clinical` which plots the a composite view of the 12 leads that the GE Muse system would print and `full` which plots each lead individually for all 10 seconds.
```
./scripts/run.sh -c $PWD/ml4cvd/recipes.py \
--mode plot_ecg \
--plot_mode clinical \
--tensors /path/to/ecgs \
--output_folder results \
--id my-plots
```

## Jupyter Lab

> JupyterLab is a web-based interactive development environment for Jupyter notebooks, code, and data. [`source`](https://jupyter.org)

A Jupyter Lab instance can be run inside Docker containers with `ml4cvd` installed:
```
./scripts/run.sh -j [-p PORT, default is 8888]
```

If the notebook docker container is running locally, navigate to the link generated by the Jupyter server.

If the container is running remotely, a local port must be mapped to the remote port using an ssh tunnel before opening the link.
```
ssh -NL PORT:localhost:PORT USER@HOST
```

If changes to the code are made after a Jupyter Lab instance is launched, update the package within the Jupyter notebook by reinstalling and reimporting `ml4cvd`. The following code is run inside the notebook.
```
! pip install --user ~/ml
import ml4cvd
```

> replace `~/ml` with the path to the repo on your machine

## Run scripts
Run scripts are stored in [this Dropbox folder](https://www.dropbox.com/sh/hjz7adj01x1erfs/AABnZifp1mUqs7Z_26zm4ly9a?dl=0).

### Script dispatcher

To distribute training scripts across bootstraps and GPUs, use [`scripts/dispatch.py`](https://github.com/aguirre-lab/ml/blob/er_dispatcher/scripts/dispatch.py):

```zsh
python scripts/dispatch.py \
--gpus 0-3 \
--bootstraps 0-9 \
--scripts \
    ~/dropbox/ml4cvd_run_scripts/sts_ecg/train-simple.sh
    ~/dropbox/ml4cvd_run_scripts/sts_ecg/train-varied.sh
    ~/dropbox/ml4cvd_run_scripts/sts_ecg/train-deeper.sh
```

### Tests
To run unit tests in Docker:
```
bash scripts/run.sh -T $PWD/tests
```

Some of the unit tests are slow due to creating, saving and loading `tensorflow` models.
To skip those tests to move quickly, run
```
./scripts/run.sh -T $PWD/tests -m '"not slow"'
```
Ensure you wrap `"not slow"` in single quotes.

pytest can also run specific tests using `::`. For example
```
./scripts/run.sh -T $PWD/tests/test_recipes.py::TestRecipes::test_explore -m '"not slow"'
```

For more pytest usage information, checkout the [usage guide](https://docs.pytest.org/en/latest/usage.html).


## TensorMaps
A TensorMap takes any kind of data stored in an hd5 file, tags it with a semantic interpretation and converts it into a structured numpy tensor.

TensorMaps can be used as inputs, outputs, or hidden layers of models made by the model factory.

TensorMaps can perform any computation by providing a callback function called `tensor_from_file`.

A default `tensor_from_file` will be attempted when a callback `tensor_from_file` is not provided.

TensorMaps guarantee shape, name, interpretation and mapping from hd5 to numpy array.

### Build TMaps for labels from ECG reads
ECG reads contain valuable information that can be parsed into labels via TMaps. For example, one can train a model to classify an ECG as AFib or not by using a TMap that looks for matching phrases in the ECG read.

Our system involves a number of `c_$TASK.xlsx` files stored in Dropbox (under the `ecg/labeling` folder). We call these spreadsheets "label maps". They are simple for clinical collaborators (most of whom are nontechnical) to revise. The first column contains source phrases, e.g. `atrial fibrillation`. The second through N'th column contain the string of the label, e.g. `afib`.

The script `scripts/make_tensor_maps_for_ecg_labels.py` parses label maps into code, resulting in the creation of `ml4cvd/tensor_maps_ecg_labels.py`.

Whenever label maps are updated, re-run the generating script to update the TMaps; note the `-c` flag to use the CPU image, and the `-t` flag for interactive mode in case you need to place breakpoints and debug.

```
./scripts/run.sh -c -t $PWD/scripts/make_tensor_maps_for_ecg_labels.py
```

The generated script is not initially formatted with `Black`. However, `pre-commit` should fix that prior to the script being committed to the repo.

## Contribute

### Issues
Every task has an issue, and each issue is labeled to help us stay organized.

New issues are created using one of our three [issue templates](https://github.com/aguirre-lab/ml/issues/new/choose): 1) new feature request or enhancement, 2) bug report, or 3) question.

We track issues and PRs on our [ECG project board](https://github.com/orgs/aguirre-lab/projects/3).

Good issues are clearly written and sufficiently small in scope to be addressed in one sprint of work (1-5 days).

If a new issue is low priority, it is added to the `To do (backlog)` column.

If a new issue is high priority, it is added to the `To do (current sprint)` column and addressed the current week.

Issues that are being actively worked on are moved to the `In progress (issues)` column.

Issues do not go in `In review (PRs)` column. Only PRs go there.

We prefer to close linked issues via PR instead of manually closing issues.

### Branches
Name your branch with your initials, a description of the purpose of the branch, and dashes between words:

```
git checkout -B er-fix-grid-ecg-plot
```

### Commit messages
We do not enforce strict commit message style, but try to follow good practices as described in this blog post: https://chris.beams.io/posts/git-commit/#capitalize.

### PRs
To contribute code or documentation changes from your branch to the `master` branch in the repo, open a PR.

Select `aguirre-lab/ml` instead of `broadinstitute/ml` (the core Broad repo) as the destination for your PR.

New PRs use our repo template by default. Describe the major changes, at a high level.

Assign at least one reviewer from Aguirre Lab.

Reviewers approve PRs before code is merged to `master`.

Reviewers review their assigned PRs within 48 hours. If your requested PR review is overdue, remind the reviewer on Slack.

When PRs are approved, all commits are "squash merged", e.g. combine all commits from the head branch into a single commit in the base branch. Also, the branch is automatically deleted.
