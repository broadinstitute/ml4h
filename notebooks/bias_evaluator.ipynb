{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import h5py\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import logging\n",
    "import hashlib\n",
    "import operator\n",
    "from textwrap import wrap\n",
    "from functools import reduce\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "from itertools import islice, product\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "from typing import Iterable, DefaultDict, Dict, List, Tuple, Optional, Callable\n",
    "\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import brier_score_loss, precision_score, recall_score, f1_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "import seaborn as sns\n",
    "from biosppy.signals import ecg\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy import stats\n",
    "\n",
    "from ml4h.TensorMap import TensorMap\n",
    "from ml4h.metrics import concordance_index, coefficient_of_determination\n",
    "from ml4h.defines import IMAGE_EXT, JOIN_CHAR, PDF_EXT, TENSOR_EXT, ECG_REST_LEADS, PARTNERS_DATETIME_FORMAT, PARTNERS_DATE_FORMAT\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Need this to write images from the GSA servers.  Order matters:\n",
    "import matplotlib.pyplot as plt  # First import matplotlib, then use Agg, then import plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
    "\n",
    "RECALL_LABEL = 'Recall | Sensitivity | True Positive Rate | TP/(TP+FN)'\n",
    "FALLOUT_LABEL = 'Fallout | 1 - Specificity | False Positive Rate | FP/(FP+TN)'\n",
    "PRECISION_LABEL = 'Precision | Positive Predictive Value | TP/(TP+FP)'\n",
    "\n",
    "SUBPLOT_SIZE = 8\n",
    "\n",
    "COLOR_ARRAY = [\n",
    "    'tan', 'indigo', 'cyan', 'pink', 'purple', 'blue', 'chartreuse', 'deepskyblue', 'green', 'salmon', 'aqua', 'magenta', 'aquamarine', 'red',\n",
    "    'coral', 'tomato', 'grey', 'black', 'maroon', 'hotpink', 'steelblue', 'orange', 'papayawhip', 'wheat', 'chocolate', 'darkkhaki', 'gold',\n",
    "    'orange', 'crimson', 'slategray', 'violet', 'cadetblue', 'midnightblue', 'darkorchid', 'paleturquoise', 'plum', 'lime',\n",
    "    'teal', 'peru', 'silver', 'darkgreen', 'rosybrown', 'firebrick', 'saddlebrown', 'dodgerblue', 'orangered',\n",
    "]\n",
    "\n",
    "import csv\n",
    "import gzip\n",
    "import h5py\n",
    "import shutil\n",
    "import zipfile\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Keras imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tensorflow.keras.layers import LeakyReLU, PReLU, ELU, ThresholdedReLU, Lambda, Reshape, LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.layers import SpatialDropout1D, SpatialDropout2D, SpatialDropout3D, add, concatenate\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, Flatten, LSTM, RepeatVector\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Conv3D, UpSampling1D, UpSampling2D, UpSampling3D, MaxPooling1D\n",
    "from tensorflow.keras.layers import MaxPooling2D, MaxPooling3D, AveragePooling1D, AveragePooling2D, AveragePooling3D, Layer\n",
    "from tensorflow.keras.layers import SeparableConv1D, SeparableConv2D, DepthwiseConv2D\n",
    "\n",
    "\n",
    "from ml4h.defines import StorageType\n",
    "from ml4h.arguments import parse_args, TMAPS, _get_tmap\n",
    "from ml4h.TensorMap import TensorMap, Interpretation\n",
    "from ml4h.tensor_generators import test_train_valid_tensor_generators, big_batch_from_minibatch_generator\n",
    "from ml4h.models import train_model_from_generators, make_multimodal_multitask_model, _inspect_model, train_model_from_generators, make_hidden_layer_model\n",
    "from ml4h.recipes import test_multimodal_multitask, train_multimodal_multitask, saliency_maps, _predict_and_evaluate\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Constants\n",
    "HD5_FOLDER = '/mnt/disks/ecg-rest-38k-tensors/2020-03-14/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'ecg_rest', 'genetic_caucasian',\n",
    "            '--output_tensors', 'poor_data_quality',\n",
    "            '--protected_tensors', 'sex', 'genetic_caucasian', 'age_0',\n",
    "            '--training_steps', '96',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '24',\n",
    "            '--epochs', '6',\n",
    "            '--batch_size', '24',\n",
    "            '--id', 'ecg_rest_bias'\n",
    "           ]\n",
    "\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "train_model_from_generators(model, generate_train, generate_valid, args.training_steps, args.validation_steps, \n",
    "                            args.batch_size, args.epochs, args.patience, args.output_folder, args.id, \n",
    "                            args.inspect_model, args.inspect_show_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(\n",
    "    tm: TensorMap, y_predictions: np.ndarray, y_truth: np.ndarray, protected: Dict[TensorMap, np.ndarray], title: str, folder: str, test_paths: List[str] = None,\n",
    "    max_melt: int = 150000, rocs: List[Tuple[np.ndarray, np.ndarray, Dict[str, int]]] = [],\n",
    "    scatters: List[Tuple[np.ndarray, np.ndarray, str, List[str]]] = [],\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\" Evaluate predictions for a given TensorMap with truth data and plot the appropriate metrics.\n",
    "    Accumulates data in the rocs and scatters lists to facilitate subplotting.\n",
    "\n",
    "    :param tm: The TensorMap predictions to evaluate\n",
    "    :param y_predictions: The predictions\n",
    "    :param y_truth: The truth\n",
    "    :param title: A title for the plots\n",
    "    :param folder: The folder to save the plots at\n",
    "    :param test_paths: The tensor paths that were predicted\n",
    "    :param max_melt: For multi-dimensional prediction the maximum number of prediction to allow in the flattened array\n",
    "    :param protected: TensorMaps and tensors sensitive to bias\n",
    "    :param rocs: (output) List of Tuples which are inputs for ROC curve plotting to allow subplotting downstream\n",
    "    :param scatters: (output) List of Tuples which are inputs for scatter plots to allow subplotting downstream\n",
    "    :return: Dictionary of performance metrics with string keys for labels and float values\n",
    "    \"\"\"\n",
    "    performance_metrics = {}\n",
    "    if tm.is_categorical() and tm.axes() == 1:\n",
    "        logging.info(f\"For tm:{tm.name} with channel map:{tm.channel_map} examples:{y_predictions.shape[0]}\")\n",
    "        logging.info(f\"\\nSum Truth:{np.sum(y_truth, axis=0)} \\nSum pred :{np.sum(y_predictions, axis=0)}\")\n",
    "        performance_metrics.update(subplot_roc_per_class(y_predictions, y_truth, tm.channel_map, protected, \n",
    "                                                      title, folder))\n",
    "        rocs.append((y_predictions, y_truth, tm.channel_map))\n",
    "\n",
    "    return performance_metrics\n",
    "\n",
    "\n",
    "def get_fpr_tpr_roc_pred(y_pred, test_truth, labels):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for k in labels:\n",
    "        cur_idx = labels[k]\n",
    "        aser = roc_curve(test_truth[:, cur_idx], y_pred[:, cur_idx])\n",
    "        fpr[labels[k]], tpr[labels[k]], _ = aser\n",
    "        roc_auc[labels[k]] = auc(fpr[labels[k]], tpr[labels[k]])\n",
    "\n",
    "    return fpr, tpr, roc_auc\n",
    "def _hash_string_to_color(string):\n",
    "    \"\"\"Hash a string to color (using hashlib and not the built-in hash for consistency between runs)\"\"\"\n",
    "    return COLOR_ARRAY[int(hashlib.sha1(string.encode('utf-8')).hexdigest(), 16) % len(COLOR_ARRAY)]\n",
    "\n",
    "\n",
    "def _text_on_plot(axes, x, y, text, alpha=0.8, background='white'):\n",
    "    t = axes.text(x, y, text)\n",
    "    t.set_bbox({'facecolor': background, 'alpha': alpha, 'edgecolor': background})\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def new_predict_and_evaluate(model, test_data, test_labels, tensor_maps_in, tensor_maps_out, \n",
    "                             tensor_maps_protected, batch_size, hidden_layer, plot_path, \n",
    "                             test_paths, embed_visualization, alpha):\n",
    "    layer_names = [layer.name for layer in model.layers]\n",
    "    performance_metrics = {}\n",
    "    scatters = []\n",
    "    rocs = []\n",
    "    \n",
    "    protected_data = {tm: test_labels[tm.output_name()] for tm in tensor_maps_protected}\n",
    "    print(f'tm prot {len(protected_data)}')\n",
    "    \n",
    "    y_predictions = model.predict(test_data, batch_size=batch_size)\n",
    "    for y, tm in zip(y_predictions, tensor_maps_out):\n",
    "        if tm.output_name() not in layer_names:\n",
    "            continue\n",
    "        if not isinstance(y_predictions, list):  # When models have a single output model.predict returns a ndarray otherwise it returns a list\n",
    "            y = y_predictions\n",
    "        y_truth = np.array(test_labels[tm.output_name()])\n",
    "        performance_metrics.update(evaluate_predictions(tm, y, y_truth, protected_data, tm.name, plot_path, \n",
    "                                                        test_paths, rocs=rocs, scatters=scatters))\n",
    "        if tm.is_language():\n",
    "            sample_from_language_model(tensor_maps_in, tm, model, test_data, max_samples=16)\n",
    "\n",
    "    if len(rocs) > 1:\n",
    "        subplot_rocs(rocs, plot_path)\n",
    "    if len(scatters) > 1:\n",
    "        subplot_scatters(scatters, plot_path)\n",
    "\n",
    "    test_labels_1d = {tm: np.array(test_labels[tm.output_name()]) for tm in tensor_maps_out if tm.output_name() in test_labels}\n",
    "    if embed_visualization == \"tsne\":\n",
    "        _tsne_wrapper(model, hidden_layer, alpha, plot_path, test_paths, test_labels_1d, test_data=test_data, tensor_maps_in=tensor_maps_in, batch_size=batch_size)\n",
    "\n",
    "    return performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_roc_per_class(prediction, truth, labels, protected, title, prefix='./figures/'):\n",
    "    lw = 2\n",
    "    col = 0\n",
    "    row = 1\n",
    "    labels_to_areas = {}\n",
    "    true_sums = np.sum(truth, axis=0)\n",
    "    total_plots = len(protected) + 1\n",
    "    cols = max(2, int(math.ceil(math.sqrt(total_plots))))\n",
    "    rows = max(2, int(math.ceil(total_plots / cols)))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*SUBPLOT_SIZE, rows*SUBPLOT_SIZE))\n",
    "    fpr, tpr, roc_auc = get_fpr_tpr_roc_pred(prediction, truth, labels)\n",
    "    \n",
    "    for p in protected:\n",
    "        print(f'\\n name {p.name} truth shape {truth.shape} IN ROCCCC {p.name} and {p.shape} and {protected[p].shape}')\n",
    "        \n",
    "        axes[row, col].plot([0, 1], [0, 1], 'k:', lw=0.5)\n",
    "        axes[row, col].set_title(f'Protected {p.name}')\n",
    "        for key in labels:    \n",
    "            if p.is_categorical():\n",
    "                idx2key = {v: k for k, v in p.channel_map.items()}\n",
    "                protected_indexes = protected[p][:, 0] == 1\n",
    "                print(f'\\n\\n protected_indexes shape {protected_indexes.shape}')\n",
    "\n",
    "                pfpr, ptpr, proc_auc = get_fpr_tpr_roc_pred(prediction[protected_indexes], \n",
    "                                                            truth[protected_indexes], labels)\n",
    "                label_text = f'{key} roc={proc_auc[labels[key]]:.3f} n={np.sum(protected_indexes):.0f}'\n",
    "\n",
    "                color = _hash_string_to_color(p.name+key)\n",
    "                axes[row, col].plot(pfpr[labels[key]], ptpr[labels[key]], color=color, lw=lw, label=label_text)\n",
    "            elif p.is_continuous():\n",
    "                threshold = np.median(protected[p])\n",
    "                protected_indexes = (protected[p] > threshold)[:, 0]\n",
    "                pfpr, ptpr, proc_auc = get_fpr_tpr_roc_pred(prediction[protected_indexes], \n",
    "                                                                truth[protected_indexes], labels)\n",
    "                label_text = f'{key} roc={proc_auc[labels[key]]:.3f} Highest  n={np.sum(protected_indexes):.0f}'\n",
    "                color = _hash_string_to_color(p.name+key)\n",
    "                axes[row, col].plot(pfpr[labels[key]], ptpr[labels[key]], color=color, lw=lw, label=label_text)\n",
    "                print(f'\\n\\n median {threshold} protected_indexes shape {protected[p].shape}')                \n",
    "                axes[row, col].set_xlim([0.0, 1.0])\n",
    "        axes[row, col].set_ylim([-0.02, 1.03])\n",
    "        axes[row, col].set_ylabel(RECALL_LABEL)\n",
    "        axes[row, col].set_xlabel(FALLOUT_LABEL)\n",
    "        axes[row, col].legend(loc='lower right')\n",
    "        row += 1\n",
    "        if row == rows:\n",
    "            row = 0\n",
    "            col += 1\n",
    "            if col >= cols:\n",
    "                break\n",
    "                    \n",
    "    for key in labels:\n",
    "        labels_to_areas[key] = roc_auc[labels[key]]\n",
    "        if 'no_' in key and len(labels) == 2:\n",
    "            continue\n",
    "        color = _hash_string_to_color(key)\n",
    "        label_text = f'{key} area: {roc_auc[labels[key]]:.3f} n={true_sums[labels[key]]:.0f}'\n",
    "        axes[0, 0].plot(fpr[labels[key]], tpr[labels[key]], color=color, lw=lw, label=label_text)\n",
    "        logging.info(f'ROC Label {label_text} Truth shape {truth.shape}, true sums {true_sums}')\n",
    "\n",
    "    axes[0, 0].set_title(f'ROC {title} n={truth.shape[0]:.0f}\\n')\n",
    "    axes[0, 0].legend(loc='lower right')\n",
    "    figure_path = os.path.join(prefix, 'per_class_roc_' + title + IMAGE_EXT)\n",
    "    if not os.path.exists(os.path.dirname(figure_path)):\n",
    "        os.makedirs(os.path.dirname(figure_path))\n",
    "    plt.savefig(figure_path, bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    logging.info(f\"Saved ROC curve at: {figure_path} with {len(protected)} protected TensorMaps.\")\n",
    "    return labels_to_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(args.output_folder, args.id + '/')\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(generate_test, args.test_steps)\n",
    "new_predict_and_evaluate(model, test_data, test_labels, args.tensor_maps_in, args.tensor_maps_out, \n",
    "                      args.tensor_maps_protected, args.batch_size, args.hidden_layer, out_path, \n",
    "                      test_paths, args.embed_visualization, args.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
