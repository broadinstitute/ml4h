{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as et \n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIRECTORY = '/mnt/disks/sax-lax-40k/2019-11-08/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_copy_hd5_datasets(source_hd5, source_hd6, destination_hd5, group_path='/'):\n",
    "    for k in source_hd5[group_path]:\n",
    "        if isinstance(source_hd5[group_path][k], h5py.Dataset):\n",
    "            dice = np.random.rand()\n",
    "            if dice > 0.5 and group_path + k in source_hd6:\n",
    "                if source_hd6[group_path][k].chunks is None:\n",
    "                    destination_hd5.create_dataset(group_path + k, data=source_hd6[group_path][k])\n",
    "                else:\n",
    "                    destination_hd5.create_dataset(group_path + k, data=source_hd6[group_path][k], compression='gzip')\n",
    "            else:\n",
    "                if source_hd5[group_path][k].chunks is None:\n",
    "                    destination_hd5.create_dataset(group_path + k, data=source_hd5[group_path][k])\n",
    "                else:\n",
    "                    destination_hd5.create_dataset(group_path + k, data=source_hd5[group_path][k], compression='gzip')                \n",
    "        else:\n",
    "            #logging.debug(f\"copying group {group_path + k}\")\n",
    "            random_copy_hd5_datasets(source_hd5, source_hd6, destination_hd5, group_path=group_path + k + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(DATA_DIRECTORY)\n",
    "for i,file1 in enumerate(files):\n",
    "    file2 = files[i+1]\n",
    "    if file1[-4:] != '.hd5' or file2[-4:] != '.hd5':\n",
    "        continue\n",
    "    if i > 10:\n",
    "        break\n",
    "    with h5py.File(os.path.join(DATA_DIRECTORY, file1)) as hd5:\n",
    "        with h5py.File(os.path.join(DATA_DIRECTORY, file2)) as hd6:\n",
    "            with h5py.File(f'fake_{i}.hd5', 'w') as hdfake:\n",
    "                random_copy_hd5_datasets(hd5, hd6, hdfake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict = defaultdict(Counter)\n",
    "def return_rhythm_class(hd5):\n",
    "    if 'poor_data_quality' in hd5['categorical']:\n",
    "        return 'poor_data_quality'\n",
    "    for rhythm in ('Normal_sinus_rhythm', 'Sinus_bradycardia', 'Marked_sinus_bradycardia'):\n",
    "        if rhythm in hd5['categorical']:\n",
    "            return 'Sinus_rhythm'\n",
    "    if 'Atrial_fibrillation' in hd5['categorical']:\n",
    "        return 'Atrial_fibirillation'    \n",
    "    return 'Other_rhythm'\n",
    "\n",
    "def new_rhythm(hd5):\n",
    "    if 'poor_data_quality' in hd5['categorical']:\n",
    "        return 'poor_data_quality'\n",
    "    ecg_interpretation = str(hd5['ecg_rest_text'][0])\n",
    "    for afib in ['Atrial fibrillation']:\n",
    "        if afib in ecg_interpretation:\n",
    "            return 'Atrial_fibrillation'\n",
    "    for rhythm in ['sinus', 'Sinus']:\n",
    "        if rhythm in ecg_interpretation:\n",
    "            return 'Sinus_rhythm'\n",
    "    return 'Other_rhythm'\n",
    "\n",
    "channel_map={'Normal_sinus_rhythm': 0, 'Sinus_bradycardia': 1, 'Marked_sinus_bradycardia': 2, 'Other_sinus_rhythm': 3, 'Atrial_fibrillation': 4, 'Other_rhythm': 5}\n",
    "def semi_coarse_rhythm(hd5):\n",
    "#     if 'poor_data_quality' in hd5['categorical']:\n",
    "#         return 'poor_data_quality'\n",
    "    ecg_interpretation = str(hd5['ecg_rest_text'][0])\n",
    "    for channel in channel_map:\n",
    "        if channel in hd5['categorical']:\n",
    "            return channel\n",
    "    for afib in ['Atrial fibrillation']:\n",
    "        if afib in ecg_interpretation:\n",
    "            return 'Atrial_fibrillation'\n",
    "    for rhythm in ['sinus', 'Sinus']:\n",
    "        if rhythm in ecg_interpretation:\n",
    "            return 'Other_sinus_rhythm'\n",
    "    return 'Other_rhythm'\n",
    "\n",
    "num_files = 0\n",
    "a_fib_tab = np.zeros((6, 2))\n",
    "brady_tab = np.zeros((6, 2))\n",
    "for file in os.listdir(DATA_DIRECTORY):\n",
    "    if file[-4:] != '.hd5':\n",
    "        continue\n",
    "    num_files += 1\n",
    "    if num_files % 1000 == 0:\n",
    "        print('.')\n",
    "    with h5py.File(os.path.join(DATA_DIRECTORY, file)) as hd5:\n",
    "        summary_dict[semi_coarse_rhythm(hd5)].update(hd5['ecg_rest_text'][:])\n",
    "        a_fib = 1 if 'atrial_fibrillation_or_flutter' in hd5 and int(hd5['atrial_fibrillation_or_flutter'][0]) != 0 else 0\n",
    "        brady = 1 if 'bradyarrhythmia_general_inclusive_definition' in hd5 and int(hd5['bradyarrhythmia_general_inclusive_definition'][0]) != 0 else 0\n",
    "        a_fib_tab[channel_map[semi_coarse_rhythm(hd5)], a_fib] += 1\n",
    "        brady_tab[channel_map[semi_coarse_rhythm(hd5)], brady] += 1\n",
    "# with open('semi_coarse_rhythm_summary2.csv', mode='w') as file_:\n",
    "#     file_writer = csv.writer(file_, delimiter=',', quotechar='\\'', quoting=csv.QUOTE_MINIMAL)\n",
    "#     for key, counter in summary_dict.items():\n",
    "#         for text, count in counter.most_common():\n",
    "#             file_writer.writerow([key, text, count])\n",
    "print(a_fib_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.table import Table\n",
    "afibs = ['No EHR Bradyarrhythmia', 'EHR Bradyarrhythmia']  # ['No EHR aFib', 'EHR aFib']\n",
    "nrows = len(channel_map)\n",
    "ncols = len(afibs)\n",
    "def checkerboard_table(data, fmt='{:1.0f}', bkg_colors=['yellow', 'white']):\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    ax.set_axis_off()\n",
    "    tb = Table(ax, bbox=[0,0,1,1])\n",
    "\n",
    "    width, height = 1.0 / ncols, 1.0 / nrows\n",
    "    \n",
    "    # Add cells\n",
    "    for (i,j), val in np.ndenumerate(data):\n",
    "        # Index either the first or second item of bkg_colors based on a checker board pattern\n",
    "        idx = [j % 2, (j + 1) % 2][i % 2]\n",
    "        color = bkg_colors[idx]\n",
    "        tb.add_cell(i, j, width, height, text=fmt.format(val), loc='center', facecolor=color)\n",
    "\n",
    "    # Labels...\n",
    "    col_offset = height/2\n",
    "    row_offset = -width/6\n",
    "    font_size = 28\n",
    "    for count, string in enumerate(afibs):\n",
    "        ax.annotate('  '+string, xy=(count*width, 1), xycoords='axes fraction', ha='left', va='bottom', \n",
    "                    rotation=30, size=font_size)    \n",
    "    for count, string in enumerate(reversed(list(channel_map.keys()))):\n",
    "        ax.annotate('  '+string, xy=(row_offset, col_offset +count*height), xycoords='axes fraction', ha='right', \n",
    "                    va='center', size=font_size)      \n",
    "    \n",
    "    tb.auto_set_font_size(False)\n",
    "    tb.set_fontsize(font_size)\n",
    "    ax.add_table(tb)\n",
    "    return fig\n",
    "\n",
    "checkerboard_table(brady_tab)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
