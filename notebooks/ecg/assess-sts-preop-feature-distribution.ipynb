{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess feature distribution of STS pre-op across bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import socket\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ! pip install --user ~/ml\n",
    "# from ml4cvd.arguments import _get_tmap\n",
    "# from ml4cvd.TensorMap import TensorMap\n",
    "# from ml4cvd.definitions import TENSOR_EXT\n",
    "# from ml4cvd.tensor_maps_ecg import TMAPS, build_ecg_time_series_tensor_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTINUOUS_FEATURES = {\n",
    "    \"age\",\n",
    "    \"creatlst\",\n",
    "    \"hct\",\n",
    "    \"hdef\",\n",
    "    \"heightcm\",\n",
    "    \"platelets\",\n",
    "    \"wbc\",\n",
    "    \"weightkg\",\n",
    "    \"perfustm\",\n",
    "    \"xclamptm\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load STS data\n",
    "fpath_sts_data = os.path.expanduser(\"~/dropbox/sts_data/mgh-all-features-labels.csv\")\n",
    "df = pd.read_csv(fpath_sts_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bootstraps\n",
    "path_bootstraps = os.path.expanduser(\"~/dropbox/sts_data/bootstraps\")\n",
    "\n",
    "# Iterate through each bootstrap\n",
    "for bootstrap in range(10):\n",
    "      \n",
    "    # Init empty dict\n",
    "    stats = dict()   \n",
    "    \n",
    "    # Init empty list to store dfs\n",
    "    dfs = []\n",
    "    \n",
    "    # Iterate through data splits\n",
    "    for split in [\"train\", \"valid\", \"test\", \"all\"]:\n",
    "                \n",
    "        stats[split] = dict()\n",
    "        \n",
    "        if split is not \"all\":\n",
    "\n",
    "            # Get CSV of MRNs\n",
    "            fpath = os.path.join(path_bootstraps, str(bootstrap), split + \".csv\")\n",
    "            df_ = pd.read_csv(fpath)\n",
    "            \n",
    "            # Get intersect between parent DF and this subset of MRNs\n",
    "            df_merged = df.merge(right=df_, left_on=\"medrecn\", right_on=\"mrn\")\n",
    "                      \n",
    "            # Sort merged df by MRN and then surgdt\n",
    "            df_merged.sort_values(by=[\"medrecn\", \"surgdt\"], inplace=True)\n",
    "                       \n",
    "            # Drop duplicates\n",
    "            df_merged.drop_duplicates(subset=[\"medrecn\"], inplace=True)\n",
    "            \n",
    "            print(f\"Parsing bootstrap {bootstrap}, split {split}: {df_merged.shape}\")\n",
    "            \n",
    "            # Append this split's data to list of all dfs\n",
    "            dfs.append(df_merged.copy())\n",
    "\n",
    "        # If not working on a split, we have all data\n",
    "        else:\n",
    "            \n",
    "            # Convert list of dfs into one aggregated df\n",
    "            df_merged = pd.concat(dfs)\n",
    "            \n",
    "            # Sort merged df by MRN and then surgdt\n",
    "            df_merged.sort_values(by=[\"medrecn\", \"surgdt\"], inplace=True)\n",
    "                       \n",
    "            # Drop duplicates\n",
    "            df_merged.drop_duplicates(subset=[\"medrecn\"], inplace=True)\n",
    "            \n",
    "        # Iterate through each continuous feature\n",
    "        for feature in CONTINUOUS_FEATURES:\n",
    "            stats[split][f\"{feature}_median\"] = df_merged[feature].median()\n",
    "            stats[split][f\"{feature}_iqr\"] = df_merged[feature].quantile(0.75) - df_merged[feature].quantile(0.25)\n",
    "        \n",
    "    # Convert dicts into dataframe\n",
    "    df_stats = pd.DataFrame(stats)       \n",
    "    print(df_stats)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
