{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import h5py\n",
    "import argparse\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as et \n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Keras imports\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, AlphaDropout, BatchNormalization, Activation\n",
    "\n",
    "# ML4CVD Imports\n",
    "from ml4cvd.plots import plot_ecg\n",
    "from ml4cvd.arguments import parse_args\n",
    "from ml4cvd.recipes import train_multimodal_multitask\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIRECTORY = '/mnt/disks/sax-lax-40k-teacher/2019-11-21/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = Counter()\n",
    "with open('/home/sam/lvh_hold_out_no_poor_new.txt', 'r') as samples:\n",
    "    sample_list = list(csv.reader(samples, delimiter=','))\n",
    "    hold_outs = [s[0] for s in sample_list]\n",
    "    with open('/home/sam/ml/trained_models/ecg_rest_raw_myocardial_mass_noheritable/inference_ecg_rest_raw_myocardial_mass_noheritable.tsv', 'r') as lvms:\n",
    "        lol = list(csv.reader(lvms, delimiter='\\t'))\n",
    "        with open('/home/sam/inferred_lvm_on_hold_out.tsv', mode='w') as file_:\n",
    "            file_writer = csv.writer(file_, delimiter='\\t', quotechar='\\'', quoting=csv.QUOTE_MINIMAL)\n",
    "            file_writer.writerow(lol[0])\n",
    "            for row in lol[1:]:\n",
    "                if not os.path.exists(os.path.join(DATA_DIRECTORY, row[0] + '.hd5')):\n",
    "                    stats['missing'] += 1\n",
    "                    continue\n",
    "                if row[0] not in hold_outs:\n",
    "                    stats['not in hold out set'] += 1\n",
    "                    continue\n",
    "                with h5py.File(os.path.join(DATA_DIRECTORY, row[0] + '.hd5')) as hd5:\n",
    "                    skip = False\n",
    "                    if 'Poor data quality' in str(hd5['ecg_rest_text'][0]):\n",
    "                        stats['poor quality'] += 1\n",
    "                        skip = True\n",
    "                    if 'ecg_rest_text' not in hd5:\n",
    "                        stats['missing ecg'] += 1\n",
    "                        skip = True\n",
    "                    if not skip:\n",
    "                        stats['written'] += 1\n",
    "                        file_writer.writerow(row)\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = Counter()\n",
    "DATA_DIRECTORY = '/mnt/disks/sax-lax-40k/2019-11-08/'\n",
    "with open('/home/sam/lvh_hold_out.txt', 'r') as volumes:\n",
    "    lol = list(csv.reader(volumes, delimiter=','))\n",
    "    holdout = [row[0] + '.hd5' for row in lol]\n",
    "    with open('/home/sam/lvh_hold_out_no_poor_new.txt', 'w') as lvh:\n",
    "        for file in sorted(os.listdir(DATA_DIRECTORY)):\n",
    "            if file[-4:] != '.hd5':\n",
    "                continue\n",
    "            try:\n",
    "                with h5py.File(os.path.join(DATA_DIRECTORY, file)) as hd5:\n",
    "                    skip = False\n",
    "                    if 'ecg_rest_text' in hd5 and 'Poor data quality' in str(hd5['ecg_rest_text'][0]):\n",
    "                        stats['poor quality'] += 1\n",
    "                        skip = True\n",
    "                    if 'ecg_rest_text' not in hd5:\n",
    "                        stats['missing ecg'] += 1\n",
    "                        skip = True\n",
    "                    if 'systole_frame_b2' not in hd5:\n",
    "                        stats['missing MRI'] += 1\n",
    "                        skip = True \n",
    "                        \n",
    "                    if file in holdout:\n",
    "                        stats['in holdout'] += 1\n",
    "                        if not skip:\n",
    "                            lvh.write(file.replace('.hd5', '') + '\\n')\n",
    "                        #skip = True\n",
    "\n",
    "                    if not skip:\n",
    "                        stats['got it all'] += 1\n",
    "                        #lvh.write(file.replace('.hd5', '') + '\\n')\n",
    "            except:\n",
    "                stats[f'failed to open {file}'] += 1\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict = defaultdict(Counter)\n",
    "def return_rhythm_class(hd5):\n",
    "    if 'poor_data_quality' in hd5['categorical']:\n",
    "        return 'poor_data_quality'\n",
    "    for rhythm in ('Normal_sinus_rhythm', 'Sinus_bradycardia', 'Marked_sinus_bradycardia'):\n",
    "        if rhythm in hd5['categorical']:\n",
    "            return 'Sinus_rhythm'\n",
    "    if 'Atrial_fibrillation' in hd5['categorical']:\n",
    "        return 'Atrial_fibirillation'    \n",
    "    return 'Other_rhythm'\n",
    "\n",
    "def new_rhythm(hd5):\n",
    "    if 'poor_data_quality' in hd5['categorical']:\n",
    "        return 'poor_data_quality'\n",
    "    ecg_interpretation = str(hd5['ecg_rest_text'][0])\n",
    "    for afib in ['Atrial fibrillation']:\n",
    "        if afib in ecg_interpretation:\n",
    "            return 'Atrial_fibrillation'\n",
    "    for rhythm in ['sinus', 'Sinus']:\n",
    "        if rhythm in ecg_interpretation:\n",
    "            return 'Sinus_rhythm'\n",
    "    return 'Other_rhythm'\n",
    "\n",
    "channel_map={'Normal_sinus_rhythm': 0, 'Sinus_bradycardia': 1, 'Marked_sinus_bradycardia': 2, 'Other_sinus_rhythm': 3, 'Atrial_fibrillation': 4, 'Other_rhythm': 5}\n",
    "def semi_coarse_rhythm(hd5):\n",
    "#     if 'poor_data_quality' in hd5['categorical']:\n",
    "#         return 'poor_data_quality'\n",
    "    ecg_interpretation = str(hd5['ecg_rest_text'][0])\n",
    "    for channel in channel_map:\n",
    "        if channel in hd5['categorical']:\n",
    "            return channel\n",
    "    for afib in ['Atrial fibrillation']:\n",
    "        if afib in ecg_interpretation:\n",
    "            return 'Atrial_fibrillation'\n",
    "    for rhythm in ['sinus', 'Sinus']:\n",
    "        if rhythm in ecg_interpretation:\n",
    "            return 'Other_sinus_rhythm'\n",
    "    return 'Other_rhythm'\n",
    "\n",
    "num_files = 0\n",
    "a_fib_tab = np.zeros((6, 2))\n",
    "brady_tab = np.zeros((6, 2))\n",
    "for file in os.listdir(DATA_DIRECTORY):\n",
    "    if file[-4:] != '.hd5':\n",
    "        continue\n",
    "    num_files += 1\n",
    "    if num_files % 1000 == 0:\n",
    "        print('.')\n",
    "    with h5py.File(os.path.join(DATA_DIRECTORY, file)) as hd5:\n",
    "        summary_dict[semi_coarse_rhythm(hd5)].update(hd5['ecg_rest_text'][:])\n",
    "        a_fib = 1 if 'atrial_fibrillation_or_flutter' in hd5 and int(hd5['atrial_fibrillation_or_flutter'][0]) != 0 else 0\n",
    "        brady = 1 if 'bradyarrhythmia_general_inclusive_definition' in hd5 and int(hd5['bradyarrhythmia_general_inclusive_definition'][0]) != 0 else 0\n",
    "        a_fib_tab[channel_map[semi_coarse_rhythm(hd5)], a_fib] += 1\n",
    "        brady_tab[channel_map[semi_coarse_rhythm(hd5)], brady] += 1\n",
    "# with open('semi_coarse_rhythm_summary2.csv', mode='w') as file_:\n",
    "#     file_writer = csv.writer(file_, delimiter=',', quotechar='\\'', quoting=csv.QUOTE_MINIMAL)\n",
    "#     for key, counter in summary_dict.items():\n",
    "#         for text, count in counter.most_common():\n",
    "#             file_writer.writerow([key, text, count])\n",
    "print(a_fib_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.table import Table\n",
    "afibs = ['No EHR Bradyarrhythmia', 'EHR Bradyarrhythmia']  # ['No EHR aFib', 'EHR aFib']\n",
    "nrows = len(channel_map)\n",
    "ncols = len(afibs)\n",
    "def checkerboard_table(data, fmt='{:1.0f}', bkg_colors=['yellow', 'white']):\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    ax.set_axis_off()\n",
    "    tb = Table(ax, bbox=[0,0,1,1])\n",
    "\n",
    "    width, height = 1.0 / ncols, 1.0 / nrows\n",
    "    \n",
    "    # Add cells\n",
    "    for (i,j), val in np.ndenumerate(data):\n",
    "        # Index either the first or second item of bkg_colors based on a checker board pattern\n",
    "        idx = [j % 2, (j + 1) % 2][i % 2]\n",
    "        color = bkg_colors[idx]\n",
    "        tb.add_cell(i, j, width, height, text=fmt.format(val), loc='center', facecolor=color)\n",
    "\n",
    "    # Labels...\n",
    "    col_offset = height/2\n",
    "    row_offset = -width/6\n",
    "    font_size = 28\n",
    "    for count, string in enumerate(afibs):\n",
    "        ax.annotate('  '+string, xy=(count*width, 1), xycoords='axes fraction', ha='left', va='bottom', \n",
    "                    rotation=30, size=font_size)    \n",
    "    for count, string in enumerate(reversed(list(channel_map.keys()))):\n",
    "        ax.annotate('  '+string, xy=(row_offset, col_offset +count*height), xycoords='axes fraction', ha='right', \n",
    "                    va='center', size=font_size)      \n",
    "    \n",
    "    tb.auto_set_font_size(False)\n",
    "    tb.set_fontsize(font_size)\n",
    "    ax.add_table(tb)\n",
    "    return fig\n",
    "\n",
    "checkerboard_table(brady_tab)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
