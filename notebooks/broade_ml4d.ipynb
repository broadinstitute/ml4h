{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to ML4D BroadE!\n",
    "\n",
    "### Agenda\n",
    "10:00-10:05: Intro Videos, Demos and Downloads \n",
    "\n",
    "10:05-10:30: Run docker jupyter server and open broad.ipynb and run first cell\n",
    "\n",
    "10:30-10:45: Fundamental ML (linear and logistic regression, SGD, depth and interpretation)\n",
    "\n",
    "10:45-11:00: Train models on well-studied datasets (MNIST, CIFAR10)\n",
    "\n",
    "11:00-11:30: ML4CVD Abstractions: Tensorization, TensorMaps and the ModelFactory\n",
    "\n",
    "11:30-11:45: Coffee Break, Discussion and Data Exploration (groups coalesce: feature not bug)\n",
    "\n",
    "11:45-11:55: Neurologist pep Talk from Chris Anderson\n",
    "\n",
    "11:55-12:30: Defining TensorMaps on Qure.ai sets.\n",
    "\n",
    "12:15-12:30: Training models on the datasets\n",
    "\n",
    "12:30-12:45: Saliency Maps\n",
    "\n",
    "12:45-12:59: Discussion and TensorMaps on your data, Tensorboard, Hyperparameter optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Basic comfort with python, some linear algebra, some data science\n",
    "- Download & Install Docker: https://docs.docker.com/install/\n",
    "- Download ML4D_BroadE.zip from Google Drive: \n",
    "- Unzip ml-broade.zip\n",
    "- Open a Command line terminal and `cd` to the ml-broade directory\n",
    "- Build your docker! run `docker build -t ml4cvd-mkl .` (This will take a little while)\n",
    "- One docker is built run the jupyter server: `docker run -it -p 8888:8888 -u $(id -u):$(id -g) --cpus=4 --memory=8g -v $PWD:/tf -it ml4cvd-mkl:latest`\n",
    "- Download ml-broade-data folder (big or small depending on how much free space you have).\n",
    "- Once data is downloaded, kill the jupyter server hold `ctrl-c` in the terminal and restart with: `docker run -it -v $HOME/ml-broade-data/:/data -p 6006:6006 -p 8888:8888 -u $(id -u):$(id -g) --cpus=4 --memory=8g -v $PWD:/tf -it ml4cvd-mkl:latest` (edit the path `$HOME/ml-broade-data/` to point at your data folder download location.)\n",
    "- Click the trust button on your Jupyter notebook\n",
    "- Now we are ready to teach the machines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "from typing import List, Dict, Callable\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import csv\n",
    "import gzip\n",
    "import h5py\n",
    "import shutil\n",
    "import zipfile\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "from ml4cvd.defines import StorageType\n",
    "from ml4cvd.arguments import parse_args, TMAPS, _get_tmap\n",
    "from ml4cvd.TensorMap import TensorMap, Interpretation\n",
    "from ml4cvd.tensor_generators import test_train_valid_tensor_generators\n",
    "from ml4cvd.models import train_model_from_generators, make_multimodal_multitask_model, _inspect_model\n",
    "from ml4cvd.recipes import test_multimodal_multitask, train_multimodal_multitask, saliency_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ZIP_FOLDER = '/data/zips/' \n",
    "HD5_FOLDER = '/data/hd5s/'\n",
    "MODEL_FOLDER = './models/'\n",
    "EXCLUDE_SERIES = ['4cc', '_&_', '5mm', '3mm', 'helical']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python features we make lots of use of in this notebook:\n",
    "- F Strings\n",
    "- Callback Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "We explore machine learning on Bio medical data using Cloud computing, Python, Tensorflow, and the ML4CVD codebase.\n",
    "\n",
    "We will start with linear regression.  Our model is a vector, one weight for each input feature, and a single bias weight.\n",
    "\n",
    "\\begin{equation}\n",
    "y = xw + b\n",
    "\\end{equation}\n",
    "\n",
    "For notational convenience absorb the bias term into the weight vector by adding a 1 to the input data matrix $X$\n",
    "\n",
    "\\begin{equation}\n",
    "y = [\\textbf{1}, X][b, \\textbf{w}]^T\n",
    "\\end{equation}\n",
    "\n",
    "#### The Dense Layer is Matrix (Tensor) Multiplication\n",
    "![Matrix Multiplication](https://www.mathwarehouse.com/algebra/matrix/images/matrix-multiplication/how-to-multiply-2-matrices-demo.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression():\n",
    "    samples = 40\n",
    "    real_weight = 2.0\n",
    "    real_bias = 0.5\n",
    "    x = np.linspace(-1, 1, samples)\n",
    "    y = real_weight*x + real_bias + (np.random.randn(*x.shape) * 0.1)\n",
    "\n",
    "    linear_model = Sequential()\n",
    "    linear_model.add(Dense(1, input_dim=1))\n",
    "    linear_model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "    linear_model.summary()\n",
    "    linear_model.fit(x, y, batch_size=1, epochs=6)\n",
    "\n",
    "    learned_slope = linear_model.get_weights()[0][0][0]\n",
    "    learned_bias = linear_model.get_weights()[1][0]\n",
    "    print('Learned slope:',  learned_slope, 'real slope:', real_weight, 'learned bias:', learned_bias, 'real bias:', real_bias)\n",
    "\n",
    "    plt.plot(x, y)\n",
    "    plt.plot([-1,1], [-learned_slope+learned_bias, learned_slope+learned_bias], 'r')\n",
    "    plt.show()\n",
    "    print('Linear Regression complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Logistic Regression:\n",
    "We take the real-valued predictions from linear regression and squish them with a sigmoid.\n",
    "\n",
    "\\begin{equation}\n",
    "\\textbf{y} = \\sigma(X\\textbf{w} + b)\n",
    "\\end{equation}\n",
    "\n",
    "where \n",
    "\\begin{equation}\n",
    "\\sigma(x) = \\frac{e^x}{1+e^x} = \\frac{1}{1+e^{-x}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    a = []\n",
    "    for item in x:\n",
    "        a.append(np.exp(item)/(1+np.exp(item)))\n",
    "    return a\n",
    "\n",
    "x = np.arange(-10., 10., 0.2)\n",
    "sig = sigmoid(x)\n",
    "plt.plot(x,sig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(epochs = 600, num_labels = 10):\n",
    "    train, test, valid = load_data('mnist.pkl.gz')  \n",
    "    \n",
    "    train_y = make_one_hot(train[1], num_labels)\n",
    "    valid_y = make_one_hot(valid[1], num_labels)\n",
    "    test_y = make_one_hot(test[1], num_labels)\n",
    "\n",
    "    logistic_model = Sequential()\n",
    "    logistic_model.add(Dense(num_labels, activation='softmax', input_dim=784, name='mnist_templates'))\n",
    "    logistic_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    logistic_model.summary()\n",
    "    \n",
    "    templates = logistic_model.layers[0].get_weights()[0]\n",
    "    plot_templates(templates, 0)\n",
    "    print('weights shape:', templates.shape)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        trainidx = random.sample(range(0, train[0].shape[0]), 8192)\n",
    "        x_batch = train[0][trainidx,:]\n",
    "        y_batch = train_y[trainidx]\n",
    "        logistic_model.train_on_batch(x_batch, y_batch)\n",
    "        if e % 100 == 0:\n",
    "            plot_templates(logistic_model.layers[0].get_weights()[0], e)\n",
    "            print('Logistic Model test set loss and accuracy:', logistic_model.evaluate(test[0], test_y), 'at epoch', e)\n",
    "\n",
    "\n",
    "def plot_templates(templates, epoch):\n",
    "    n = 10\n",
    "    templates = templates.reshape((28,28,n))\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, 5, i+1)\t\t\n",
    "        plt.imshow(templates[:, :, i])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plot_name = \"./regression_example/mnist_templates_\"+str(epoch)+\".png\"\n",
    "    if not os.path.exists(os.path.dirname(plot_name)):\n",
    "        os.makedirs(os.path.dirname(plot_name))\t\t\n",
    "    plt.savefig(plot_name)\n",
    "\n",
    "\n",
    "def make_one_hot(y, num_labels):\n",
    "    ohy = np.zeros((len(y), num_labels))\n",
    "    for i in range(0, len(y)):\n",
    "        ohy[i][y[i]] = 1.0\n",
    "    return ohy\n",
    "\n",
    "\n",
    "def load_data(dataset):\n",
    "    ''' Loads the dataset\n",
    "    :param dataset: the path to the dataset (here MNIST)'''\n",
    "    data_dir, data_file = os.path.split(dataset)\n",
    "    if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "        # Check if dataset is in the data directory.\n",
    "        new_path = os.path.join(\"data\", dataset)\n",
    "        if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "            dataset = new_path\n",
    "\n",
    "    if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "        from urllib.request import urlretrieve\n",
    "        origin = ('http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz')\n",
    "        print('Downloading data from %s' % origin)\n",
    "        if not os.path.exists(os.path.dirname(dataset)):\n",
    "            os.makedirs(os.path.dirname(dataset))\t\n",
    "        urlretrieve(origin, dataset)\n",
    "\n",
    "    print('loading data...')\n",
    "    f = gzip.open(dataset, 'rb')\n",
    "    if sys.version_info[0] == 3:\n",
    "        u = pickle._Unpickler(f)\n",
    "        u.encoding = 'latin1'\n",
    "        train_set, valid_set, test_set = u.load()\n",
    "    else:\n",
    "        train_set, valid_set, test_set = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return train_set, valid_set, test_set\n",
    "\n",
    "def plot_mnist(sides):\n",
    "    train, _, _ = load_data('mnist.pkl.gz')\n",
    "    print(train[0].shape)\n",
    "    mnist_images = train[0].reshape((-1, 28, 28, 1))\n",
    "    sides = int(np.ceil(np.sqrt(min(sides, mnist_images.shape[0]))))\n",
    "    _, axes = plt.subplots(sides, sides, figsize=(16, 16))\n",
    "    for i in range(sides*sides):\n",
    "        axes[i // sides, i % sides].imshow(mnist_images[i, ..., 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look B4 U Learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy Loss:\n",
    "Our favorite loss function for categorical data.\n",
    "\\begin{equation}\n",
    "L(true, model) = -\\sum_{x\\in\\mathcal{X}} true(x)\\, \\log model(x)\n",
    "\\end{equation}\n",
    "\n",
    "Binary cross entropy with $N$ data points $x$ each with a binary label: \n",
    "\\begin{equation}\n",
    "true(x) \\in \\{0, 1\\} \\\\\n",
    "L(true, model) = -\\frac{1}{N}\\sum^N_{i=1} true(x_i)\\log(model(x_i)) + (1-true(x_i))log(1-model(x_i))\n",
    "\\end{equation}\n",
    "\n",
    "This is the Kullback Leibler divergence between the true distribution and the predicted. \n",
    "This function emerges in many fields as diverse as probability, information theory, and physics.\n",
    "What is the information difference between the truth and our model?  How much data do I lose by replacing the truth with the model's predictions. What is the temperature difference between my predictions and the truth?!\n",
    "\n",
    "Categorical cross entropy with $K$ different classes or labels: \n",
    "\\begin{equation}\n",
    "true(x) \\in \\{0, 1, 2, ..., K\\} \\\\\n",
    "L(true, model) = -\\frac{1}{N}\\sum^N_{i=1}\\sum^K_{j=1} y_{ik}\\log(q_k(x_i)))\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Models: \"Hidden\" Layers and The MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron():\n",
    "    train, test, valid = load_data('mnist.pkl.gz')\n",
    "\n",
    "    num_labels = 10\n",
    "    train_y = make_one_hot(train[1], num_labels)\n",
    "    valid_y = make_one_hot(valid[1], num_labels)\n",
    "    test_y = make_one_hot(test[1], num_labels)\n",
    "\n",
    "    mlp_model = Sequential()\n",
    "    mlp_model.add(Dense(500, activation='relu', input_dim=784))\n",
    "    mlp_model.add(Dense(num_labels, activation='softmax'))\n",
    "    mlp_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    mlp_model.summary()\n",
    "    mlp_model.fit(train[0], train_y, validation_data=(valid[0],valid_y), batch_size=32, epochs=3)\n",
    "    print('Multilayer Perceptron trained. Test set loss and accuracy:', mlp_model.evaluate(test[0], test_y))\n",
    "\n",
    "multilayer_perceptron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions Flip, Slide, Multiply, Add\n",
    "Convolutions look for their kernel in a larger signal.\n",
    "\n",
    "In convolution, you always and only find what you're looking with.\n",
    "\n",
    "Convolution and cross correlation are deeply related:\n",
    "\n",
    "\\begin{equation}\n",
    "f(t) \\circledast g(t) \\triangleq\\ \\int_{-\\infty}^\\infty f(\\tau) g(t - \\tau) \\, d\\tau. = \\int_{-\\infty}^\\infty f(t-\\tau) g(\\tau)\\, d\\tau.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "![title](https://upload.wikimedia.org/wikipedia/commons/2/21/Comparison_convolution_correlation.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_neural_network(filters=32, kernel_size=(3,3), padding='valid', num_labels = 10):\n",
    "    train, test, valid = load_data('mnist.pkl.gz')\n",
    "\n",
    "    train_y = make_one_hot(train[1], num_labels)\n",
    "    valid_y = make_one_hot(valid[1], num_labels)\n",
    "    test_y = make_one_hot(test[1], num_labels)\n",
    "    \n",
    "    print(train[0].shape)\n",
    "    mnist_images = train[0].reshape((-1, 28, 28, 1))\n",
    "    mnist_valid = valid[0].reshape((-1, 28, 28, 1))\n",
    "    mnist_test = test[0].reshape((-1, 28, 28, 1))\n",
    "\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(input_shape=(28, 28, 1), filters=filters, kernel_size=kernel_size, padding=padding, activation='relu'))\n",
    "    cnn_model.add(Conv2D(filters=filters, kernel_size=kernel_size, padding=padding, activation='relu'))\n",
    "    cnn_model.add(Conv2D(filters=filters, kernel_size=kernel_size, padding=padding, activation='relu'))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(16, activation='relu'))\n",
    "    cnn_model.add(Dense(num_labels, activation='softmax'))\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    cnn_model.summary()\n",
    "    cnn_model.fit(mnist_images, train_y, validation_data=(mnist_valid, valid_y), batch_size=32, epochs=3)\n",
    "    \n",
    "    print('Convolutional Neural Network trained. Test set loss and accuracy:', cnn_model.evaluate(mnist_test, test_y))\n",
    "\n",
    "convolutional_neural_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why (and When!) is Convolution Helpful?\n",
    "- Decouples input size from model size\n",
    "- Translationally Equivariant (Not Invariant), so we can find features wherever they might occur in the signal\n",
    "- Local structure is often informative\n",
    "- But not always! (eg Tabular data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML4CVD Cosmology:  Tensors all the way down.\n",
    "\n",
    "\n",
    "# ML4CVD Abstractions: Tensorization, the TensorMap, and the ModelFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorization\n",
    "Tensorization is the process of gathering any number of input files and consolidating them into compressed HD5 files.  We tend to make one HD5 file per sample in the study.  The files contain the raw data and labels we will use to train models.  It tends to be efficient to separate tensor construction from model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dicoms(dicom_folder, stats):\n",
    "    dcm_file = ''\n",
    "    my_stats = Counter()\n",
    "    series = defaultdict(list)\n",
    "    for root, _, files in os.walk(dicom_folder):\n",
    "        for name in files:\n",
    "            dcm_file = os.path.join(root, name)\n",
    "            if not dcm_file.endswith('.dcm'):\n",
    "                continue\n",
    "            try:\n",
    "                dcm = pydicom.read_file(dcm_file)\n",
    "                my_stats[f'Shape {dcm.pixel_array.shape}'] += 1\n",
    "                my_stats['count'] += 1\n",
    "                my_stats[f'Series Number {dcm.SeriesNumber}'] += 1\n",
    "                my_stats[f'Series Description {dcm.SeriesDescription}'] += 1\n",
    "                my_stats[f'Pixel spacing{dcm.PixelSpacing}'] += 1\n",
    "                series[dcm.SeriesDescription.lower().trim().replace(' ', '_').replace('/', '_')].append(dcm)\n",
    "            except:\n",
    "                my_stats['got an error'] += 1\n",
    "                break\n",
    "    print(f'\\n At DICOM {dcm_file}')\n",
    "    for k in my_stats:\n",
    "        print(f'{k} has {my_stats[k]}') \n",
    "    \n",
    "    try:\n",
    "        tensors = {}\n",
    "        for k in series:\n",
    "            tensors[k] = np.zeros((512, 512, len(series[k])))\n",
    "            for dcm in series[k]:\n",
    "                tensors[k][..., dcm.InstanceNumber-1] = dcm.pixel_array\n",
    "    except:\n",
    "        my_stats['got a tensorization error'] += 1\n",
    "            \n",
    "    stats.update(my_stats)\n",
    "    return tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorize_qure_ai_dicoms(zip_folder, dicom_folder, hd5_folder, delete_dicoms=True, limit_dicoms=-1):\n",
    "    raw_data = {}\n",
    "    stats = Counter()\n",
    "    if not os.path.exists(dicom_folder):\n",
    "        os.makedirs(dicom_folder)\n",
    "    if not os.path.exists(hd5_folder):\n",
    "        os.makedirs(hd5_folder)    \n",
    "    for z in os.listdir(zip_folder):\n",
    "        if os.path.exists(os.path.join(hd5_folder, z.replace('.zip', '.hd5'))):\n",
    "            continue\n",
    "        with zipfile.ZipFile(zip_folder + z, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(dicom_folder)\n",
    "            tensors = parse_dicoms(dicom_folder, stats)\n",
    "            with h5py.File(os.path.join(hd5_folder, z.replace('.zip', '.hd5')), 'w') as hd5:\n",
    "                for t in tensors:\n",
    "                    hd5.create_dataset(t, data=tensors[t], compression='gzip')\n",
    "        if delete_dicoms:\n",
    "            shutil.rmtree(dicom_folder)\n",
    "        if limit_dicoms > 0 and stats['count'] > limit_dicoms:\n",
    "            break\n",
    "\n",
    "    print('\\n\\n Full stats below:')\n",
    "    for k in stats:\n",
    "        print(f'{k} has {stats[k]}')\n",
    "\n",
    "tensorize_qure_ai_dicoms(ZIP_FOLDER, './dicoms/', './test/', limit_dicoms=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -5 ./reads.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorize_qure_ai_reads(read_file, hd5_folder):\n",
    "    stats = Counter()\n",
    "    with open(read_file, 'r') as my_csv:\n",
    "        lol = list(csv.reader(my_csv, delimiter=','))\n",
    "        header = [h.replace(':', '_').lower() for h in lol[0]]\n",
    "        print(f'header is {header}')\n",
    "        for row in lol[1:]:\n",
    "            try:\n",
    "                with h5py.File(f'{hd5_folder}{row[0]}.hd5', 'a') as hd5:\n",
    "                    for i, value in enumerate(row[2:]):\n",
    "                        hd5.create_dataset(header[i+2], data=[int(value)])\n",
    "            except:\n",
    "                print(f'Could not open {row[0]}')\n",
    "    for k in stats:\n",
    "        print(f'{k} has {stats[k]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the DICOM series we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorMaps\n",
    "The critical data structure in the ML4CVD codebase is the TensorMap.\n",
    "This abstraction provides a way to translate ***any*** kind of input data, into structured numeric tensors with clear semantics for interpretation and modeling.  TensorMaps guarantee a shape, a way to consturct tensors of that shape from the HD5 files created during tensorization and a meaning to the values in the tensor that the TensorMap yields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_image = TensorMap('mnist_image', Interpretation.CONTINUOUS, shape=(28, 28))\n",
    "mnist_image = TensorMap('mnist_image', Interpretation.CONTINUOUS, shape=(28, 28, 1))\n",
    "\n",
    "mnist_channel_map = {'zero': 0, 'one': 1, 'two': 2, 'three': 3, 'zero': 4, 'zero': 5, \n",
    "                     'six': 6, 'seven': 9, 'eight': 8, 'nine': 9}\n",
    "\n",
    "mnist_class = TensorMap('mnist_class', Interpretation.CATEGORICAL, shape=(10,), channel_map=mnist_channel_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_image = TensorMap('cifar_image', Interpretation.CONTINUOUS, shape=(32, 32, 3))\n",
    "\n",
    "cifar_channel_map = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, \n",
    "                     'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
    "\n",
    "cifar_class = TensorMap('cifar_class', Interpretation.CATEGORICAL, shape=(10,), channel_map=cifar_channel_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmaps_by_sample_id(tensor_folder: str, sample_id: str, tmaps: List[TensorMap]):\n",
    "    path = os.path.join(tensor_folder, sample_id + '.hd5')\n",
    "    result_dict = defaultdict(lambda: None)\n",
    "    if os.path.isfile(path):\n",
    "        with h5py.File(path, 'r') as hd5:\n",
    "            for tmap in tmaps:\n",
    "                try:\n",
    "                    result_dict[tmap] = tmap.normalize_and_validate(tmap.tensor_from_file(tmap, hd5))\n",
    "                except (IndexError, KeyError, ValueError, OSError, RuntimeError):\n",
    "                    continue\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_array_3d(a):\n",
    "    slice_axis = -1\n",
    "    sides = int(np.ceil(np.sqrt(a.shape[slice_axis])))\n",
    "    _, axes = plt.subplots(sides, sides, figsize=(16, 16))\n",
    "    print(a.shape)\n",
    "    vmin = np.min(a)\n",
    "    vmax = np.max(a)\n",
    "    for i in range(a.shape[slice_axis]):\n",
    "        axes[i//sides, i%sides].imshow(a[..., i], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        axes[i//sides, i%sides].set_yticklabels([])\n",
    "        axes[i//sides, i%sides].set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_map(exclude=EXCLUDE_SERIES):\n",
    "    def slice_from_hd5(tm, hd5, dependents={}):\n",
    "        for k in np.random.permutation(list(hd5.keys())):\n",
    "            if any(x in k for x in exclude):\n",
    "                continue\n",
    "            if isinstance(hd5[k], h5py.Dataset) and len(hd5[k].shape) == 3 and hd5[k].shape[-1] > 50:\n",
    "                random_index = np.random.randint(hd5[k].shape[-1]-tm.shape[-1])\n",
    "                random_slices = np.array(hd5[k][..., random_index:random_index+tm.shape[-1]], dtype=np.float32)\n",
    "                return random_slices\n",
    "        raise ValueError('No CT slices in HD5')\n",
    "    return slice_from_hd5\n",
    "   \n",
    "TMAPS['slice_map'] = TensorMap('slice_map', shape=(512, 512, 1), tensor_from_file=slice_map(), \n",
    "                               cacheable=False, normalization={'zero_mean_std1': True})\n",
    "TMAPS['slice_map5'] = TensorMap('slice_map5', shape=(512, 512, 5), tensor_from_file=slice_map(), \n",
    "                                cacheable=False, normalization={'zero_mean_std1': True})\n",
    "TMAPS['slice_map25'] = TensorMap('slice_map25', shape=(512, 512, 25), tensor_from_file=slice_map(), \n",
    "                                 cacheable=False, normalization={'zero_mean_std1': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tmaps_by_sample_id(HD5_FOLDER, 'CQ500-CT-222', [ _get_tmap('slice_map25')])\n",
    "for k in t:\n",
    "    print(k.name, 'has', t[k].shape)\n",
    "    plot_array_3d(t[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_voxels(exclude=EXCLUDE_SERIES):\n",
    "    def crop_voxels_from_hd5(tm, hd5, dependents={}):\n",
    "        for k in np.random.permutation(list(hd5.keys())):\n",
    "            if isinstance(hd5[k], h5py.Dataset) and len(hd5[k].shape) == 3:\n",
    "                if any(x in k for x in exclude):\n",
    "                    continue\n",
    "                if hd5[k].shape[-1] < 50:\n",
    "                    continue\n",
    "                x_index = np.random.randint(hd5[k].shape[0]-tm.shape[0])\n",
    "                y_index = np.random.randint(hd5[k].shape[1]-tm.shape[1])\n",
    "                middle_index = hd5[k].shape[-1] // 2\n",
    "                start_index = middle_index - (tm.shape[-1] // 2)\n",
    "                stop_index = middle_index + (tm.shape[-1] // 2) + tm.shape[-1]%2\n",
    "                z_index = np.random.randint(hd5[k].shape[2]-tm.shape[2])\n",
    "                random_slices = np.array(hd5[k][x_index:x_index+tm.shape[0], y_index:y_index+tm.shape[1], start_index:stop_index], dtype=np.float32)\n",
    "                return random_slices\n",
    "        raise ValueError('No CT slices in HD5')\n",
    "    return crop_voxels_from_hd5\n",
    "\n",
    "TMAPS['crop_thin_16'] = TensorMap('crop_thin_16', shape=(16, 16, 16), tensor_from_file=crop_voxels(), \n",
    "                                  cacheable=False, normalization={'zero_mean_std1': True})\n",
    "    \n",
    "TMAPS['crop_thin_64'] = TensorMap('crop_thin_64', shape=(64, 64, 64), tensor_from_file=crop_voxels(), \n",
    "                                  cacheable=False, normalization={'zero_mean_std1': True})\n",
    "\n",
    "TMAPS['crop_thin_316'] = TensorMap('crop_thin_316', shape=(316, 192, 64), tensor_from_file=crop_voxels(), \n",
    "                                   cacheable=False, normalization={'zero_mean_std1': True})\n",
    "\n",
    "TMAPS['crop_thin_372'] = TensorMap('crop_thin_372', shape=(372, 292, 121), tensor_from_file=crop_voxels(), \n",
    "                                   cacheable=False, normalization={'zero_mean_std1': True})\n",
    "\n",
    "TMAPS['crop_thin_256'] = TensorMap('crop_thin_256', shape=(256, 256, 128), tensor_from_file=crop_voxels(), \n",
    "                                   cacheable=False, normalization={'zero_mean_std1': True})\n",
    "\n",
    "TMAPS['crop_thin_396'] = TensorMap('crop_thin_396', shape=(396, 396, 144), tensor_from_file=crop_voxels(), \n",
    "                                   cacheable=False, normalization={'zero_mean_std1': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tmaps_by_sample_id(HD5_FOLDER, 'CQ500-CT-212', [ _get_tmap('crop_thin_316')])\n",
    "for k in t:\n",
    "    print(k.name, 'has', t[k].shape)\n",
    "    plot_array_3d(t[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thin_slice(exclude=EXCLUDE_SERIES):\n",
    "    def thin_slice_from_hd5(tm, hd5, dependents={}):\n",
    "        for k in np.random.permutation(list(hd5.keys())):\n",
    "            if any(x in k for x in exclude):\n",
    "                continue\n",
    "            if hd5[k].shape[-1] < 50:\n",
    "                continue\n",
    "            if isinstance(hd5[k], h5py.Dataset) and len(hd5[k].shape) == 3:\n",
    "                random_index = np.random.randint(hd5[k].shape[-1]-tm.shape[-1])\n",
    "                random_slices = np.array(hd5[k][..., random_index:random_index+tm.shape[-1]], dtype=np.float32)\n",
    "                random_slices = np.clip(random_slices, 3000, 10000)\n",
    "                return random_slices\n",
    "        raise ValueError('No CT slices in HD5')\n",
    "    return thin_slice_from_hd5\n",
    "    \n",
    "TMAPS['thin_slice_map16'] = TensorMap('thin_slice_map16', shape=(512, 512, 16), tensor_from_file=thin_slice([]), \n",
    "                                      cacheable=False, normalization={'zero_mean_std1': True})\n",
    "TMAPS['thin_slice_map50'] = TensorMap('thin_slice_map50', shape=(512, 512, 50), tensor_from_file=thin_slice([]), \n",
    "                                      cacheable=False, normalization={'zero_mean_std1': True})\n",
    "TMAPS['thin_slice_map200'] = TensorMap('thin_slice_map200', shape=(512, 512, 200), tensor_from_file=thin_slice(), \n",
    "                                       cacheable=False, normalization={'zero_mean_std1': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tmaps_by_sample_id(HD5_FOLDER, 'CQ500-CT-212', [ _get_tmap('thin_slice_map50')])\n",
    "for k in t:\n",
    "    print(k.name, 'has', t[k].shape)\n",
    "    plot_array_3d(t[k])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with something simple and obvious for a human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_count(exclude=EXCLUDE_SERIES):\n",
    "    def slice_count_hd5(tm, hd5, dependents={}):\n",
    "        for k in np.random.permutation(list(hd5.keys())):\n",
    "            if any(x in k for x in exclude):\n",
    "                continue\n",
    "            if isinstance(hd5[k], h5py.Dataset) and len(hd5[k].shape) == 3 and hd5[k].shape[-1] > 50:\n",
    "                random_index = np.random.randint(hd5[k].shape[-1]-tm.shape[-1])\n",
    "                random_slices = np.array(hd5[k][..., random_index:random_index+tm.shape[-1]], dtype=np.float32)\n",
    "                dependents[tm.dependent_map] = np.sum(random_slices > 800) / np.prod(random_slices.shape)\n",
    "                return random_slices\n",
    "        raise ValueError('No CT slices in HD5')\n",
    "    return slice_count_hd5\n",
    "\n",
    "TMAPS['slice_map_count'] = TensorMap('slice_map_count', shape=(1,), channel_map={'count': 0}, cacheable=False)\n",
    "TMAPS['slice_map_to_count'] = TensorMap('slice_map', shape=(512, 512, 2), dependent_map=TMAPS['slice_map_count'],\n",
    "                                        tensor_from_file=slice_count(), cacheable=False, \n",
    "                                        normalization={'zero_mean_std1': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMAPS['r1_fracture'] = TensorMap('r1_fracture', Interpretation.CATEGORICAL, \n",
    "                                 storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                                 channel_map={'no_r1_fracture': 0, 'r1_fracture': 1})\n",
    "TMAPS['r2_fracture'] = TensorMap('r2_fracture', Interpretation.CATEGORICAL, \n",
    "                                 storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                                 channel_map={'no_r2_fracture': 0, 'r2_fracture': 1})\n",
    "TMAPS['r3_fracture'] = TensorMap('r3_fracture', Interpretation.CATEGORICAL, \n",
    "                                 storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                                 channel_map={'no_r3_fracture': 0, 'r3_fracture': 1})\n",
    "TMAPS['r1_calvarialfracture'] = TensorMap('r1_calvarialfracture', Interpretation.CATEGORICAL, \n",
    "                                          storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                                          channel_map={'no_r1_calvarialfracture': 0, 'r1_calvarialfracture': 1})\n",
    "TMAPS['r2_calvarialfracture'] = TensorMap('r2_calvarialfracture', Interpretation.CATEGORICAL, \n",
    "                                          storage_type=StorageType.CATEGORICAL_INDEX, channel_map={'no_r2_calvarialfracture': 0, 'r2_calvarialfracture': 1})\n",
    "TMAPS['r3_calvarialfracture'] = TensorMap('r3_calvarialfracture', Interpretation.CATEGORICAL, \n",
    "                                          storage_type=StorageType.CATEGORICAL_INDEX, channel_map={'no_r3_calvarialfracture': 0, 'r3_calvarialfracture': 1})\n",
    "\n",
    "TMAPS['r1_masseffect'] = TensorMap('r1_masseffect', Interpretation.CATEGORICAL, \n",
    "                                   storage_type=StorageType.CATEGORICAL_INDEX, channel_map={'no_r1_masseffect': 0, 'r1_masseffect': 1})\n",
    "TMAPS['r2_masseffect'] = TensorMap('r2_masseffect', Interpretation.CATEGORICAL, \n",
    "                                   storage_type=StorageType.CATEGORICAL_INDEX, channel_map={'no_r2_masseffect': 0, 'r2_masseffect': 1})\n",
    "TMAPS['r3_masseffect'] = TensorMap('r3_masseffect', Interpretation.CATEGORICAL, \n",
    "                                   storage_type=StorageType.CATEGORICAL_INDEX, channel_map={'no_r3_masseffect': 0, 'r3_masseffect': 1})\n",
    "\n",
    "TMAPS['r1_ich'] = TensorMap('r1_ich', Interpretation.CATEGORICAL, storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                            channel_map={'no_r1_ich': 0, 'r1_ich': 1})\n",
    "TMAPS['r2_ich'] = TensorMap('r2_ich', Interpretation.CATEGORICAL, storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                            channel_map={'no_r2_ich': 0, 'r2_ich': 1})\n",
    "TMAPS['r3_ich'] = TensorMap('r3_ich', Interpretation.CATEGORICAL, storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                            channel_map={'no_r3_ich': 0, 'r3_ich': 1})\n",
    "\n",
    "TMAPS['r1_iph'] = TensorMap('r1_iph', Interpretation.CATEGORICAL, storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                            channel_map={'no_r1_iph': 0, 'r1_iph': 1})\n",
    "TMAPS['r2_iph'] = TensorMap('r2_iph', Interpretation.CATEGORICAL, storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                            channel_map={'no_r2_iph': 0, 'r2_iph': 1})\n",
    "TMAPS['r3_iph'] = TensorMap('r3_iph', Interpretation.CATEGORICAL, storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                            channel_map={'no_r3_iph': 0, 'r3_iph': 1})\n",
    "\n",
    "TMAPS['r1_midlineshift'] = TensorMap('r1_midlineshift', Interpretation.CATEGORICAL, \n",
    "                                     storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                                     channel_map={'no_r1_midlineshift': 0, 'r1_midlineshift': 1})\n",
    "TMAPS['r2_midlineshift'] = TensorMap('r2_midlineshift', Interpretation.CATEGORICAL, \n",
    "                                     storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                                     channel_map={'no_r2_midlineshift': 0, 'r2_midlineshift': 1})\n",
    "TMAPS['r3_midlineshift'] = TensorMap('r3_midlineshift', Interpretation.CATEGORICAL, \n",
    "                                     storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                                     channel_map={'no_r3_midlineshift': 0, 'r3_midlineshift': 1})\n",
    "\n",
    "TMAPS['r1_sah'] = TensorMap('r1_sah', Interpretation.CATEGORICAL, storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                            channel_map={'no_r1_sah': 0, 'r1_sah': 1})\n",
    "TMAPS['r2_sah'] = TensorMap('r2_sah', Interpretation.CATEGORICAL, storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                            channel_map={'no_r2_sah': 0, 'r2_sah': 1})\n",
    "TMAPS['r3_sah'] = TensorMap('r3_sah', Interpretation.CATEGORICAL, storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                            channel_map={'no_r3_sah': 0, 'r3_sah': 1})\n",
    "\n",
    "TMAPS['r1_sdh'] = TensorMap('r1_sdh', Interpretation.CATEGORICAL, storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                            channel_map={'no_r1_sdh': 0, 'r1_sdh': 1})\n",
    "TMAPS['r2_sdh'] = TensorMap('r2_sdh', Interpretation.CATEGORICAL, storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                            channel_map={'no_r2_sdh': 0, 'r2_sdh': 1})\n",
    "TMAPS['r3_sdh'] = TensorMap('r3_sdh', Interpretation.CATEGORICAL, storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                            channel_map={'no_r3_sdh': 0, 'r3_sdh': 1})\n",
    "\n",
    "TMAPS['r1_chronicbleed'] = TensorMap('r1_chronicbleed', Interpretation.CATEGORICAL, \n",
    "                                     storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                                     channel_map={'no_r1_chronicbleed': 0, 'r1_chronicbleed': 1})\n",
    "TMAPS['r2_chronicbleed'] = TensorMap('r2_chronicbleed', Interpretation.CATEGORICAL, \n",
    "                                     storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                                     channel_map={'no_r2_chronicbleed': 0, 'r2_chronicbleed': 1})\n",
    "TMAPS['r3_chronicbleed'] = TensorMap('r3_chronicbleed', Interpretation.CATEGORICAL, \n",
    "                                     storage_type=StorageType.CATEGORICAL_INDEX, \n",
    "                                     channel_map={'no_r3_chronicbleed': 0, 'r3_chronicbleed': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model Factory\n",
    "The function ***make_multimodal_multitask_model()*** takes lists of TensorMaps and connects them with intelligent goo.\n",
    "### Model Architectures\n",
    "- Classification\n",
    "- Regression\n",
    "- Multitask\n",
    "- Multimodal\n",
    "- Multimodal Multitask\n",
    "- Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification of CT Slice Command Line & Architecture\n",
    "Jupyter is great, but can complicate productionizing code. We try to mitigate this by interacting with the jupyter notebook as if it were a command line call to one of ML4CVD's modes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'crop_thin_64',\n",
    "            '--output_tensors', 'r1_masseffect',\n",
    "            '--dense_blocks', '12', '12', '8', '8',\n",
    "            '--num_workers', '0', '--cache_size', '0',\n",
    "           ]\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "_inspect_model(model, generate_train, generate_valid, 1, 1, True, './my_first_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![My First Model Architecture](./my_first_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'slice_map_to_count',\n",
    "            '--output_tensors', 'slice_map_count',\n",
    "            '--pool_x', '6', '--pool_y', '6',\n",
    "            '--id', 'slice_map_to_count',\n",
    "            '--output_folder', MODEL_FOLDER,\n",
    "            '--epochs', '2',\n",
    "            '--training_steps', '48', \n",
    "            '--validation_steps', '22', \n",
    "            '--valid_ratio', '0.3', \n",
    "            '--test_steps', '48', \n",
    "            '--test_ratio', '0.3', \n",
    "            '--test_modulo', '0', \n",
    "            '--batch_size', '4',\n",
    "            '--cache_size', '0',\n",
    "            '--num_workers', '0'\n",
    "           ]\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['test_scalar', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'slice_map_to_count',\n",
    "            '--output_tensors', 'slice_map_count', 'r1_midlineshift', 'r2_midlineshift', 'r3_midlineshift',\n",
    "            '--id', 'slice_map_to_count',\n",
    "            '--output_folder', MODEL_FOLDER,\n",
    "            '--model_file', f'{MODEL_FOLDER}/slice_map_to_count/slice_map_to_count.hd5',\n",
    "            '--epochs', '18',\n",
    "            '--training_steps', '48', \n",
    "            '--validation_steps', '22', \n",
    "            '--valid_ratio', '0.3', \n",
    "            '--test_steps', '48', \n",
    "            '--test_ratio', '0.3', \n",
    "            '--test_modulo', '0', \n",
    "            '--batch_size', '4',\n",
    "            '--cache_size', '0',\n",
    "            '--num_workers', '0'\n",
    "           ]\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "test_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitask Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'crop_thin_64',\n",
    "            '--output_tensors', 'r1_midlineshift', 'r2_midlineshift', 'r3_midlineshift',\n",
    "            '--num_workers', '0'\n",
    "           ]\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "_inspect_model(model, generate_train, generate_valid, 1, 1, True, './my_first_multitask_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![multitask](./my_first_multitask_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'crop_thin_16', 'crop_thin_64',\n",
    "            '--output_tensors', 'r1_midlineshift',\n",
    "            '--dense_blocks', '12', '12', '8', '8',\n",
    "            '--test_ratio', '0.3',\n",
    "            '--num_workers', '0',\n",
    "            '--cache_size', '0'\n",
    "           ]\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "_inspect_model(model, generate_train, generate_valid, 1, 1, True, './my_first_multimodal_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multimodal](./my_first_multimodal_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CT Slice AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'crop_thin_64',\n",
    "            '--output_tensors', 'crop_thin_64',\n",
    "            '--num_workers', '0'\n",
    "           ]\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "_inspect_model(model, generate_train, generate_valid, 1, 1, True, './my_ct_slice_autoencoder.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ct auto encoder](./my_ct_slice_autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'crop_thin_64',\n",
    "            '--output_tensors', 'crop_thin_64',\n",
    "            '--u_connect',\n",
    "            '--num_workers', '0'\n",
    "           ]\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "_inspect_model(model, generate_train, generate_valid, 1, 1, True, './my_ct_slice_unet_autoencoder.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![unet](./my_ct_slice_unet_autoencoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beware of the Irony of Command Line Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'crop_thin_64',\n",
    "            '--output_tensors', 'r1_calvarialfracture', 'r1_masseffect',\n",
    "            '--output_folder', MODEL_FOLDER,\n",
    "            '--activation', 'prelu',\n",
    "            '--dense_blocks', '32', '24', '16', '12', '8', '6',\n",
    "            '--dense_layers', '32', '32', '32',\n",
    "            '--block_size', '5',\n",
    "            '--pool_x', '2',\n",
    "            '--pool_y', '2',\n",
    "            '--id', 'middle_slices_16_r1_calvarialfracture_mass_effect',\n",
    "            '--epochs', '18',\n",
    "            '--training_steps', '48', \n",
    "            '--validation_steps', '22', \n",
    "            '--valid_ratio', '0.3', \n",
    "            '--test_steps', '2', \n",
    "            '--test_ratio', '0.1', \n",
    "            '--test_modulo', '0', \n",
    "            '--batch_size', '6',\n",
    "            '--cache_size', '0',\n",
    "            '--num_workers', '0'\n",
    "           ]\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "_inspect_model(model, generate_train, generate_valid, 1, 1, True, './my_hypertune.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hyper](./my_hypertune.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['plot_saliency', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'slice_map_to_count',\n",
    "            '--output_tensors', 'slice_map_count',\n",
    "            '--id', 'slice_map_to_count',\n",
    "            '--output_folder', MODEL_FOLDER,\n",
    "            '--model_file', f'{MODEL_FOLDER}/slice_map_to_count/slice_map_to_count.hd5',\n",
    "            '--epochs', '18',\n",
    "            '--training_steps', '48', \n",
    "            '--validation_steps', '22', \n",
    "            '--valid_ratio', '0.3', \n",
    "            '--test_steps', '4', \n",
    "            '--test_ratio', '0.3', \n",
    "            '--test_modulo', '0', \n",
    "            '--batch_size', '4',\n",
    "            '--cache_size', '0',\n",
    "            '--num_workers', '0'\n",
    "           ]\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "saliency_maps(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE of learned Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![t-SNE](./models/slice_map_to_count/tsne_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'crop_thin_64',\n",
    "            '--output_tensors', 'r1_calvarialfracture', 'r1_masseffect',\n",
    "            '--output_folder', MODEL_FOLDER,\n",
    "            '--dense_blocks', '32', '24',\n",
    "            '--pool_x', '4',\n",
    "            '--pool_y', '4',\n",
    "            '--id', 'middle_slices_16_r1_calvarialfracture_mass_effect',\n",
    "            '--epochs', '18',\n",
    "            '--training_steps', '48', \n",
    "            '--validation_steps', '22', \n",
    "            '--valid_ratio', '0.3', \n",
    "            '--test_steps', '2', \n",
    "            '--test_ratio', '0.1', \n",
    "            '--test_modulo', '0', \n",
    "            '--batch_size', '6',\n",
    "            '--cache_size', '0',\n",
    "            '--num_workers', '0'\n",
    "           ]\n",
    "args = parse_args()\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
