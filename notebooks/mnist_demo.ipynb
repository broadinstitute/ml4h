{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "from typing import List, Dict, Callable\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import csv\n",
    "import gzip\n",
    "import h5py\n",
    "import shutil\n",
    "import zipfile\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "from ml4cvd.defines import StorageType\n",
    "from ml4cvd.arguments import parse_args, TMAPS, _get_tmap\n",
    "from ml4cvd.TensorMap import TensorMap, Interpretation\n",
    "from ml4cvd.tensor_generators import test_train_valid_tensor_generators\n",
    "from ml4cvd.models import train_model_from_generators, make_multimodal_multitask_model, _inspect_model\n",
    "from ml4cvd.recipes import test_multimodal_multitask, train_multimodal_multitask, saliency_maps\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "HD5_FOLDER = './mnist_hd5s/'\n",
    "OUTPUT_FOLDER = './runs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    ''' Loads the dataset\n",
    "    :param dataset: the path to the dataset (here MNIST)'''\n",
    "    data_dir, data_file = os.path.split(dataset)\n",
    "    if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "        # Check if dataset is in the data directory.\n",
    "        new_path = os.path.join(\"data\", dataset)\n",
    "        if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "            dataset = new_path\n",
    "\n",
    "    if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "        from urllib.request import urlretrieve\n",
    "        origin = ('http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz')\n",
    "        print('Downloading data from %s' % origin)\n",
    "        if not os.path.exists(os.path.dirname(dataset)):\n",
    "            os.makedirs(os.path.dirname(dataset))\t\n",
    "        urlretrieve(origin, dataset)\n",
    "\n",
    "    print('loading data...')\n",
    "    f = gzip.open(dataset, 'rb')\n",
    "    if sys.version_info[0] == 3:\n",
    "        u = pickle._Unpickler(f)\n",
    "        u.encoding = 'latin1'\n",
    "        train_set, valid_set, test_set = u.load()\n",
    "    else:\n",
    "        train_set, valid_set, test_set = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist(sides):\n",
    "    train, _, _ = load_data('mnist.pkl.gz')\n",
    "    print(train[0].shape)\n",
    "    mnist_images = train[0].reshape((-1, 28, 28, 1))\n",
    "    sides = int(np.ceil(np.sqrt(min(sides, mnist_images.shape[0]))))\n",
    "    _, axes = plt.subplots(sides, sides, figsize=(16, 16))\n",
    "    for i in range(sides*sides):\n",
    "        axes[i // sides, i % sides].imshow(mnist_images[i, ..., 0], cmap='gray')\n",
    "        axes[i // sides, i % sides].set_xticks(())\n",
    "        axes[i // sides, i % sides].set_yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4QAAAN3CAYAAABqSJSMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3df6ifBd3/8euaH2az8JgrpjX8UahRMA/KbIm51aaELbDsB0OdYphgC4kaUqxQSls5BWdagrjyBykxllaIRtMTMhXXMiibWYJDG5bL6aamuHN9/5X7y9zZ2885n3PO6/H4+/Piet93t7v29Arutuu6BgAAgDwzBn0AAAAAgyEIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABC9fbnx23b+v9RAcA+dV3XDvqGFN7NAIzF3t7NvhACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQKjeoA8AAIDJ4MQTTyztVqxYUdotX768tGuaprnllltKu+uuu66027JlS2nH5OcLIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQKi267qx/7htx/5jGJADDjigtBsaGurzJeNjxYoVpd1BBx1UfuZxxx1X2n31q18t7dasWVPaLVu2rLT73//+V9qtXr26tLv88stLu6mk67p20Dek8G6G/9/w8HBpt3HjxtLu4IMPLu0G4cUXXyztZs+e3edLmGh7ezf7QggAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABCqN+gDmFhHHHFEaTdz5szS7uSTTy7tmqZpTjnllNLukEMOKe3OOuus0i7BM888U9qtXbu2tPvsZz9b2u3atau0+/Of/1zajYyMlHYAjM1JJ51U2q1fv760GxoaKu26rivtqu+tpmma119/vbSbPXt2abdgwYLSbsuWLaVd9X8+9p8vhAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKHaruvG/uO2HfuPGVfDw8Ol3caNG0u7oaGh0o7JY3R0tLy94IILSrvdu3eXn1mxffv20u6FF14o7Z544onSLkHXde2gb0jh3cxEOuigg0q7E044obS77bbbSru5c+eWdm1b+6Nrf/4+/WZbtmwp7ZqmaX70ox+VdnfccUdpV/3fzapVq0q7H/zgB6Ude7e3d7MvhAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKF6gz6Amm3btpV2O3bsKO2GhoZKuwSPPPJIabdz587S7hOf+ERp9/rrr5d2TdM0t956a3kLwPRx4403lnbLli3r8yXTwwknnFDevutd7yrtRkZGSrtFixaVdvPmzSvtmDi+EAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAITqDfoAav773/+WditXriztli5dWtr96U9/Ku2apmnWrl1b3lY89thjpd1pp51W2r388sul3Uc+8pHS7pJLLintAJheTjzxxPL205/+dGnXtm35mRUjIyOl3a9//evSbs2aNaXdv/71r9Kuaep/x3rhhRdKu09+8pOl3UT/Z8/+84UQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAgVNt13dh/3LZj/zHTysEHH1za7dq1q/zMG2+8sbT78pe/XNqdc845pd0vfvGL0g6ms67r2kHfkMK7Odfw8HBpt3HjxvIzq38fqLrnnntKu2XLlpV2CxcuLO3mzZtX2t10002lXdM0zX/+85/ytmLPnj2l3SuvvFLaVf+z2LJlS2mXYG/vZl8IAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUL1BH8DU8NJLL034M1988cUJfd6FF15Y2t15552l3ejoaGkHwPRy7LHHlnYrV64s7YaGhkq7pmma559/vrTbvn17affzn/+8tNu9e3dp99vf/nZCdwlmzZpV2n3jG98o7c4+++zSLpkvhAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKF6gz4A9uayyy4r7U488cTSbuHChaXdkiVLSrv77ruvtANgcjrwwANLuzVr1pR2Z5xxRmm3a9eu0q5pmmb58uWl3ebNm0u7WbNmlXZMfUccccSgT4jhCyEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAECotuu6sf+4bcf+YxiQD37wg6Xdli1bSrudO3eWdvfff39pt3nz5tLu+uuvL+2apmn2588JaJqm6bquHfQNKbybJ48FCxaUdg8++GCfL3lrixcvLm9HRkb6eAlTyZ49e0q76t8hHnroodLu4x//eGmXYG/vZl8IAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQvUGfQD02z//+c/S7vzzzy/t1q1bV9qde+65E7p75zvfWdo1TdPccsstpd327dvLzwSYaq655prSrm3b0m5kZGRCd2SbMaP2HWl0dLTPl9BvvhACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACE6g36AJgsNmzYUNo9+eSTpd0111xT2i1evLi0u/LKK0u7pmmaI488srS74oorSrtnn322tAPoh6VLl5Z2w8PDpV3XdaXd3XffXdpBxejoaGlX/b/vxx57rLRj//lCCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEKo36ANgqvvLX/5S2n3xi18s7T7zmc+UduvWrSvtmqZpLrrootLumGOOKe1OO+200g6gH2bNmlXazZw5s7T797//XdrdeeedpR3Tw4EHHljaXXbZZf09ZB82btxY2n3rW9/q8yXsjS+EAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoXqDPgBS7dy5s7S79dZbS7ubbrqptGuapun1an9UnHrqqaXdokWLSrsHHnigtAMYpNdee6202759e58vYaIdeOCB5e2qVatKu5UrV5Z2zzzzTGl39dVXl3a7d+8u7dh/vhACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAACheoM+AKa6efPmlXaf//znS7v58+eXdr3exP/j/vjjj5d2f/jDH/p8CcDkdffddw/6BN6m4eHh0m7lypXlZ37pS18q7e66667S7qyzzirtmPx8IQQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAjVG/QB0G/HHXdcabdixYrS7nOf+1xpd9hhh5V2g7Bnz57Sbvv27aXd6OhoaQfQD23bTujuzDPPLO0uueSS0o69+/rXv17afec73ynthoaGSrumaZrbb7+9tFu+fHn5mUxPvhACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACE6g36AKa3ww47rLxdtmxZabdixYrS7qijjirtporNmzeXt1dccUVpd/fdd5efCTAoXddN6K76rly7dm1pd/PNN5d2TdM0O3bsKO0WLFhQ2p177rml3fHHH1/azZ07t7Tbtm1baXfvvfeWdk3TNDfccEN5C2/mCyEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAECo3qAPYGLNmTOntPvwhz9c2v34xz8u7ZqmaT70oQ+Vt1PBI488UtpdddVVpd1dd91V2jVN04yOjpa3ALy1Aw44oLS7+OKLS7uzzjqrtGuapnnppZdKu2OOOab8zIm0adOm0u7+++8v7b773e+WdtBPvhACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEaruuG/uP23bsP2ZMDj300NLuxhtvLO2Gh4dLuw984AOl3VSyadOm0u7qq68u7e69997S7tVXXy3tYCJ1XdcO+oYU3s39N3fu3NLul7/8ZWk3f/780q6qbev/eO7P3xv7YceOHaXdHXfcUdpdcsklpR1MBXt7N/tCCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEKrtum7sP27bsf94ivroRz9a2q1cubK0O+mkk0q797///aXdVPLKK6+UdmvXri3trrzyytLu5ZdfLu1gOuu6rh30DSkS3s1TxeGHH17aXXTRRaXdqlWrSru2rf/juT9/b3yza6+9trT7yU9+Utr94x//KO1gOtvbu9kXQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFBt13Vj/3Hbjv3HU9Tq1atLu5UrV/b5kvHx+OOPl3a/+c1vSrs33nijtGuaprn66qtLu507d5afCfRH13XtoG9IkfBuBuDt29u72RdCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAgVNt13dh/3LZj/zEAsbquawd9QwrvZgDGYm/vZl8IAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABC9fbz9883TfP0eBwCwLRx5KAPCOPdDMC+7PXd3HZdN5GHAAAAMEn4r4wCAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAITq7c+P27btxusQAKaPruvaQd+QwrsZgLHY27vZF0IAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUL1BHwDwfy1evLi0u/3220u7hQsXlnZPPPFEaQcAb9eqVatKu8svv7y0mzGj9h1p0aJFpd3IyEhpx/7zhRAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACBUb9AHTDannnpqaTd79uzSbsOGDaUdTGfz588v7R599NE+XwIA4+f8888vby+99NLSbnR0tPzMiq7rJvR57D9fCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEL1Bn3AZLNo0aLS7phjjintNmzYUNrBVDBjRu3fOR199NGl3ZFHHlnatW1b2gHA21F9bzVN07zjHe/o4yUk84UQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAgVG/QB0w2y5cvL+0eeuihPl8CU9/hhx9e2l144YWl3W233Vbabd26tbQDgKZpmiVLlpR2X/va1/p8yb5V33lLly4t7Z577rnSjonjCyEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAECo3qAPmGxmzNDI0C833XTThD7vySefnNDnATC9nHLKKaXdunXrSruhoaHS7u246qqrSrunn366z5cwWagfAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUL1BHzAe5s2bV97OmTOnj5dAtqGhoQl93u9+97sJfR4A08t5551X2r3vfe/r8yX79sADD5R2t9xyS38PYcrzhRAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAjVG/QB4+GMM84ob2fNmtXHS2B6mDNnTml39NFH9/mSt/bss89O6PMAmJze8573lHYXXHBBaTc6Olra7dy5s7Rrmqb5/ve/X97Cm/lCCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEKo36APGw3HHHTfhz/zrX/864c+EibJmzZrSbs6cOaXd3//+99Ju165dpR0Ak9NRRx1V2q1fv76/h4yT6667rry9//77+3gJyXwhBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACNUb9AHTxaOPPjroE5hiDj744NLuU5/6VGl3zjnnlHZN0zSnn356eVvxve99r7TbuXNnny8BYJCq77x58+b1+ZK39vvf/760u/baa/t8Cew/XwgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABC9QZ9wHRx6KGHDvqEcXX88ceXdm3blp+5ZMmS0m7u3Lml3cyZM0u7s88+u7SbMaP272NeffXV0u6RRx4p7ZqmaV577bXSrter/RHzxz/+sbQDYHI688wzS7vVq1f3+ZK39uCDD5Z25513Xmn34osvlnbQT74QAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhOoN+oDx8Oqrr5a3XdeVdj/96U9Lu29/+9ul3USbN29eade2bfmZb7zxRmn3yiuvlHaPP/54aXfzzTeXdps3by7tRkZGSrvnnnuutGuapnnmmWdKu1mzZpV2W7duLe0AGF9HHXVUabd+/fr+HjJOnnrqqdLu7bxjYdB8IQQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAjVG/QB4+Hiiy8ub59++unS7uSTTy4/cyrYtm1baferX/2q/My//e1vpd3DDz9cfuZ09pWvfKW8fe9731vaPfXUU+VnAjD5XHrppaXd6Ohony8ZH6tXrx70CTDhfCEEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAI1Rv0AZPND3/4w0GfAONi8eLFE/7M9evXT/gzAXhrw8PD5e3pp5/ex0vGz1133VXaPfHEE32+BCY/XwgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQvUEfAExfGzZsGPQJAPwf9913X3n77ne/u4+X7NvDDz9c2p1//vn9PQSmMV8IAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQvUGfQAAABNn9uzZ5e3o6GgfL9m3G264obTbvXt3ny+B6csXQgAAgFCCEAAAIJQgBAAACCUIAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFC9QR8ATH5t25Z2xx57bGn38MMPl3YASdatW1fazZgxdb4HbNq0adAnwLQ3df5EAAAAoK8EIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKF6gz4AmPy6rivtZszw75wA9mV4eLi0W7JkSWk3Ojpa2jVN07z++uul3fXXX1/aPffcc6UdMHb+tgYAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABCqN+gDgOnrYx/7WGn3s5/9rL+HAExihxxySGl32GGH9fmSfXv22WdLu29+85t9vgToF18IAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEIJQgAAgFCCEAAAIJQgBAAACCUIAQAAQvUGfQAw+bVtO+gTAAAYB74QAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhOoN+gBgYtxzzz3l7Re+8IU+XgLAm23durW027RpU2l3yimnlHbA9OQLIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEjbig0sAAAGQSURBVIQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEKrtum7sP27bsf8YgFhd17WDviGFdzMAY7G3d7MvhAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoQQhAABAKEEIAAAQShACAACEEoQAAAChBCEAAEAoQQgAABBKEAIAAIQShAAAAKEEIQAAQChBCAAAEEoQAgAAhBKEAAAAoXr7+fvnm6Z5ejwOAWDaOHLQB4TxbgZgX/b6bm67rpvIQwAAAJgk/FdGAQAAQglCAACAUIIQAAAglCAEAAAIJQgBAABCCUIAAIBQghAAACCUIAQAAAglCAEAAEL9P70Nii7Llo8sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x1152 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mnist(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mnist(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorization\n",
    "It is often helpful to separate data preparation from model training.  In ML4CVD we call the final data preparation process tensorization.  Tensorization involves gathering all input files (XMLS, CSVs, DICOMs, PNGs, etc) and consolidating them into compressed HD5 files.  We tend to make one HD5 file per individual in the cohort we are studying.  The files contain the raw data and labels (inputs and outputs) we will use to train models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_as_hd5(hd5_folder):\n",
    "    train, _, _ = load_data('mnist.pkl.gz')\n",
    "    mnist_images = train[0].reshape((-1, 28, 28, 1))\n",
    "    if not os.path.exists(hd5_folder):\n",
    "        os.makedirs(hd5_folder)\n",
    "    for i, mnist_image in enumerate(mnist_images):\n",
    "        with h5py.File(os.path.join(hd5_folder, f'{i}.hd5'), 'w') as hd5:\n",
    "            hd5.create_dataset('mnist_image', data=mnist_image)\n",
    "            hd5.create_dataset('mnist_label', data=[train[1][i]])\n",
    "        if (i+1) % 5000 == 0:\n",
    "            print(f'Wrote {i+1} MNIST images and labels as HD5 files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "Wrote 4999 MNIST images and labels as HD5 files\n",
      "Wrote 9999 MNIST images and labels as HD5 files\n",
      "Wrote 14999 MNIST images and labels as HD5 files\n",
      "Wrote 19999 MNIST images and labels as HD5 files\n",
      "Wrote 24999 MNIST images and labels as HD5 files\n",
      "Wrote 29999 MNIST images and labels as HD5 files\n",
      "Wrote 34999 MNIST images and labels as HD5 files\n",
      "Wrote 39999 MNIST images and labels as HD5 files\n",
      "Wrote 44999 MNIST images and labels as HD5 files\n",
      "Wrote 49999 MNIST images and labels as HD5 files\n"
     ]
    }
   ],
   "source": [
    "mnist_as_hd5(HD5_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorMaps\n",
    "The central data structure in the ML4CVD codebase is the TensorMap.\n",
    "This abstraction provides a way to translate ***any*** kind of input data, into structured numeric tensors with clear semantics for interpretation and modeling.  TensorMaps guarantee a shape, a way to construct tensors of that shape from the HD5 files created during tensorization and a meaning to the values in the tensor that the TensorMap yields.  The most important method of each TensorMap is their ***tensor_from_file*** function.  This callback function takes the TensorMap, an HD5 file handle, and an optional dictionary as input arguments and it returns a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_image_from_hd5(tm, hd5, dependents={}):\n",
    "     return np.array(hd5['mnist_image'])\n",
    "\n",
    "def mnist_label_from_hd5(tm, hd5, dependents={}):\n",
    "    one_hot = np.zeros(tm.shape, dtype=np.float32)\n",
    "    one_hot[int(hd5['mnist_label'][0])] = 1.0\n",
    "    return one_hot\n",
    "    \n",
    "TMAPS['mnist_image'] = TensorMap('mnist_image', shape=(28, 28, 1), tensor_from_file=mnist_image_from_hd5)\n",
    "TMAPS['mnist_label'] = TensorMap('mnist_label', Interpretation.CATEGORICAL, tensor_from_file=mnist_label_from_hd5,\n",
    "                                 channel_map={f'digit_{i}': i for i in range(10)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line Friendly Jupyter Notebooks\n",
    "By directly setting the `sys.argv` array in our jupyter notebooks we make the process of translating from notebook to command line straightforward.  For example, the cell below can be replicated on the command line by running:\n",
    "```\n",
    "./scripts/tf.sh $HOME/ml/ml4cvd/recipes.py --mode train --tensors ./mnist_hd5s/ \\\n",
    "    --input_tensors mnist_image --output_tensors mnist_label \\\n",
    "    --batch_size 64 --test_steps 64 --epochs 24 \\\n",
    "    --output_folder ./runs/ --id learn_mnist\n",
    "```\n",
    "The script `tf.sh` starts the appropriate docker container and then calls python on the provided arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 17:00:11,151 - logger:25 - INFO - Logging configuration was loaded. Log messages can be found at ./runs/learn_mnist/log_2020-05-22_17-00_0.log.\n",
      "2020-05-22 17:00:11,152 - arguments:372 - INFO - Command Line was: \n",
      "./scripts/tf.sh train --tensors ./mnist_hd5s/ --input_tensors mnist_image --output_tensors mnist_label --batch_size 64 --test_steps 64 --epochs 24 --output_folder ./runs/ --id learn_mnist\n",
      "\n",
      "2020-05-22 17:00:11,154 - arguments:373 - INFO - Total TensorMaps: 558 Arguments are Namespace(activation='relu', aligned_dimension=16, alpha=0.5, anneal_max=2.0, anneal_rate=0.0, anneal_shift=0.0, app_csv=None, b_slice_force=None, balance_csvs=[], batch_size=64, bigquery_credentials_file='/mnt/ml4cvd/projects/jamesp/bigquery/bigquery-viewer-credentials.json', bigquery_dataset='broad-ml4cvd.ukbb7089_r10data', block_size=3, bottleneck_type=<BottleneckType.FlattenRestructure: 1>, cache_size=875000000.0, categorical_field_ids=[], continuous_field_ids=[], continuous_file=None, continuous_file_column=None, continuous_file_discretization_bounds=[], continuous_file_normalize=False, conv_dilate=False, conv_dropout=0.0, conv_layers=[32], conv_normalize=None, conv_regularize=None, conv_type='conv', conv_x=3, conv_y=3, conv_z=2, debug=False, dense_blocks=[32, 24, 16], dense_layers=[16, 64], dicom_series='cine_segmented_sax_b6', dicoms='./dicoms/', dropout=0.0, eager=False, epochs=24, freeze_model_layers=False, hidden_layer='embed', id='learn_mnist', imputation_method_for_continuous_fields='random', include_array=False, include_instance=False, include_missing_continuous_channel=False, input_tensors=['mnist_image'], inspect_model=False, inspect_show_labels=True, join_tensors=['partners_ecg_patientid_clean'], label_weights=None, language_layer='ecg_rest_text', language_prefix=None, learning_rate=0.0002, learning_rate_schedule=None, logging_level='INFO', max_models=16, max_parameters=9000000, max_patients=999999, max_pools=[], max_sample_id=7000000, max_samples=None, max_slices=999999, min_sample_id=0, min_samples=3, min_values=10, mixup_alpha=0, mlp_concat=False, mode='mlp', model_file=None, model_files=[], model_layers=None, mri_field_ids=['20208', '20209'], num_workers=4, optimizer='radam', output_folder='./runs/', output_tensors=['mnist_label'], padding='same', patience=8, phecode_definitions='/mnt/ml4cvd/projects/jamesp/data/phecode_definitions1.2.csv', phenos_folder='gs://ml4cvd/phenotypes/', plot_mode='clinical', pool_type='max', pool_x=2, pool_y=2, pool_z=1, random_seed=12878, reference_end_time_tensor=None, reference_join_tensors=None, reference_label=None, reference_name='Reference', reference_start_time_tensor=None, reference_tensors=None, res_layers=[], sample_csv=None, sample_weight=None, t=48, tensor_maps_in=[TensorMap(mnist_image, (28, 28, 1), continuous)], tensor_maps_out=[TensorMap(mnist_label, (10,), categorical)], tensors='./mnist_hd5s/', tensors_name='Tensors', test_csv=None, test_ratio=0.1, test_steps=64, time_tensor='partners_ecg_datetime', train_csv=None, training_steps=72, tsv_style='standard', u_connect=defaultdict(<class 'set'>, {}), valid_csv=None, valid_ratio=0.2, validation_steps=18, write_pngs=False, x=256, xml_field_ids=['20205', '6025'], xml_folder='/mnt/disks/ecg-rest-xml/', y=256, z=48, zip_folder='/mnt/disks/sax-mri-zip/', zoom_height=96, zoom_width=96, zoom_x=50, zoom_y=35)\n",
      "2020-05-22 17:00:14,519 - tensor_generators:622 - INFO - Found 34927 train, 10085 validation, and 4988 testing tensors at: ./mnist_hd5s/\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_mnist_image_continuous (I [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 32)   320         input_mnist_image_continuous[0][0\n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 28, 28, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 14, 14, 32)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 32)   9248        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 14, 14, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 14, 14, 64)   0           max_pooling2d[0][0]              \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 32)   18464       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 14, 14, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 96)   0           max_pooling2d[0][0]              \n",
      "                                                                 activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 32)   27680       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 14, 14, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 32)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 24)     6936        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 7, 7, 24)     0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 7, 7, 56)     0           max_pooling2d_1[0][0]            \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 7, 7, 24)     12120       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 7, 7, 24)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 7, 7, 80)     0           max_pooling2d_1[0][0]            \n",
      "                                                                 activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 24)     17304       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 24)     0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 24)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 3, 3, 16)     3472        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 3, 3, 16)     0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 40)     0           max_pooling2d_2[0][0]            \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 3, 3, 16)     5776        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 3, 3, 16)     0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 56)     0           max_pooling2d_2[0][0]            \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 3, 3, 16)     8080        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 3, 3, 16)     0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 144)          0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           2320        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embed (Dense)                   (None, 64)           1088        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64)           0           embed[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_mnist_label_categorical  (None, 10)           650         activation_11[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 113,458\n",
      "Trainable params: 113,458\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 17:00:15,540 - tensor_generators:149 - INFO - Started 3 train workers with cache size 0.875GB.\n",
      "2020-05-22 17:00:15,915 - tensor_generators:149 - INFO - Started 1 validation workers with cache size 0.875GB.\n",
      "Train for 72 steps, validate for 18 steps\n",
      "Epoch 1/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.2996 - categorical_accuracy: 0.1092 - digit_0_precision: 0.0000e+00 - digit_1_precision: 0.0000e+00 - digit_2_precision: 0.0000e+00 - digit_3_precision: 0.0000e+00 - digit_4_precision: 0.0000e+00 - digit_5_precision: 0.0000e+00 - digit_6_precision: 0.0000e+00 - digit_7_precision: 0.0000e+00 - digit_8_precision: 0.0000e+00 - digit_9_precision: 0.0000e+00 - digit_0_recall: 0.0000e+00 - digit_1_recall: 0.0000e+00 - digit_2_recall: 0.0000e+00 - digit_3_recall: 0.0000e+00 - digit_4_recall: 0.0000e+00 - digit_5_recall: 0.0000e+00 - digit_6_recall: 0.0000e+00 - digit_7_recall: 0.0000e+00 - digit_8_recall: 0.0000e+00 - digit_9_recall: 0.0000e+00\n",
      "Epoch 00001: val_loss improved from inf to 2.29164, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 14s 194ms/step - loss: 2.2996 - categorical_accuracy: 0.1087 - digit_0_precision: 0.0000e+00 - digit_1_precision: 0.0000e+00 - digit_2_precision: 0.0000e+00 - digit_3_precision: 0.0000e+00 - digit_4_precision: 0.0000e+00 - digit_5_precision: 0.0000e+00 - digit_6_precision: 0.0000e+00 - digit_7_precision: 0.0000e+00 - digit_8_precision: 0.0000e+00 - digit_9_precision: 0.0000e+00 - digit_0_recall: 0.0000e+00 - digit_1_recall: 0.0000e+00 - digit_2_recall: 0.0000e+00 - digit_3_recall: 0.0000e+00 - digit_4_recall: 0.0000e+00 - digit_5_recall: 0.0000e+00 - digit_6_recall: 0.0000e+00 - digit_7_recall: 0.0000e+00 - digit_8_recall: 0.0000e+00 - digit_9_recall: 0.0000e+00 - val_loss: 2.2916 - val_categorical_accuracy: 0.1033 - val_digit_0_precision: 0.0000e+00 - val_digit_1_precision: 0.0000e+00 - val_digit_2_precision: 0.0000e+00 - val_digit_3_precision: 0.0000e+00 - val_digit_4_precision: 0.0000e+00 - val_digit_5_precision: 0.0000e+00 - val_digit_6_precision: 0.0000e+00 - val_digit_7_precision: 0.0000e+00 - val_digit_8_precision: 0.0000e+00 - val_digit_9_precision: 0.0000e+00 - val_digit_0_recall: 0.0000e+00 - val_digit_1_recall: 0.0000e+00 - val_digit_2_recall: 0.0000e+00 - val_digit_3_recall: 0.0000e+00 - val_digit_4_recall: 0.0000e+00 - val_digit_5_recall: 0.0000e+00 - val_digit_6_recall: 0.0000e+00 - val_digit_7_recall: 0.0000e+00 - val_digit_8_recall: 0.0000e+00 - val_digit_9_recall: 0.0000e+00\n",
      "Epoch 2/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 2.2655 - categorical_accuracy: 0.1706 - digit_0_precision: 0.0000e+00 - digit_1_precision: 0.0000e+00 - digit_2_precision: 0.0000e+00 - digit_3_precision: 0.0000e+00 - digit_4_precision: 0.0000e+00 - digit_5_precision: 0.0000e+00 - digit_6_precision: 0.0000e+00 - digit_7_precision: 0.0000e+00 - digit_8_precision: 0.0000e+00 - digit_9_precision: 0.0000e+00 - digit_0_recall: 0.0000e+00 - digit_1_recall: 0.0000e+00 - digit_2_recall: 0.0000e+00 - digit_3_recall: 0.0000e+00 - digit_4_recall: 0.0000e+00 - digit_5_recall: 0.0000e+00 - digit_6_recall: 0.0000e+00 - digit_7_recall: 0.0000e+00 - digit_8_recall: 0.0000e+00 - digit_9_recall: 0.0000e+00\n",
      "Epoch 00002: val_loss improved from 2.29164 to 2.19203, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 2.2648 - categorical_accuracy: 0.1704 - digit_0_precision: 0.0000e+00 - digit_1_precision: 0.0000e+00 - digit_2_precision: 0.0000e+00 - digit_3_precision: 0.0000e+00 - digit_4_precision: 0.0000e+00 - digit_5_precision: 0.0000e+00 - digit_6_precision: 0.0000e+00 - digit_7_precision: 0.0000e+00 - digit_8_precision: 0.0000e+00 - digit_9_precision: 0.0000e+00 - digit_0_recall: 0.0000e+00 - digit_1_recall: 0.0000e+00 - digit_2_recall: 0.0000e+00 - digit_3_recall: 0.0000e+00 - digit_4_recall: 0.0000e+00 - digit_5_recall: 0.0000e+00 - digit_6_recall: 0.0000e+00 - digit_7_recall: 0.0000e+00 - digit_8_recall: 0.0000e+00 - digit_9_recall: 0.0000e+00 - val_loss: 2.1920 - val_categorical_accuracy: 0.2361 - val_digit_0_precision: 0.0000e+00 - val_digit_1_precision: 0.0000e+00 - val_digit_2_precision: 0.0000e+00 - val_digit_3_precision: 0.0000e+00 - val_digit_4_precision: 0.0000e+00 - val_digit_5_precision: 0.0000e+00 - val_digit_6_precision: 0.0000e+00 - val_digit_7_precision: 0.0000e+00 - val_digit_8_precision: 0.0000e+00 - val_digit_9_precision: 0.0000e+00 - val_digit_0_recall: 0.0000e+00 - val_digit_1_recall: 0.0000e+00 - val_digit_2_recall: 0.0000e+00 - val_digit_3_recall: 0.0000e+00 - val_digit_4_recall: 0.0000e+00 - val_digit_5_recall: 0.0000e+00 - val_digit_6_recall: 0.0000e+00 - val_digit_7_recall: 0.0000e+00 - val_digit_8_recall: 0.0000e+00 - val_digit_9_recall: 0.0000e+00\n",
      "Epoch 3/24\n",
      "70/72 [============================>.] - ETA: 0s - loss: 1.9027 - categorical_accuracy: 0.3772 - digit_0_precision: 0.2571 - digit_1_precision: 0.4221 - digit_2_precision: 0.0000e+00 - digit_3_precision: 0.0000e+00 - digit_4_precision: 0.0000e+00 - digit_5_precision: 0.0000e+00 - digit_6_precision: 0.0571 - digit_7_precision: 0.0000e+00 - digit_8_precision: 0.0000e+00 - digit_9_precision: 0.0000e+00 - digit_0_recall: 0.1416 - digit_1_recall: 0.3550 - digit_2_recall: 0.0000e+00 - digit_3_recall: 0.0000e+00 - digit_4_recall: 0.0000e+00 - digit_5_recall: 0.0000e+00 - digit_6_recall: 0.0119 - digit_7_recall: 0.0000e+00 - digit_8_recall: 0.0000e+00 - digit_9_recall: 0.0000e+00    \n",
      "Epoch 00003: val_loss improved from 2.19203 to 1.41321, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 4s 57ms/step - loss: 1.8922 - categorical_accuracy: 0.3811 - digit_0_precision: 0.2778 - digit_1_precision: 0.4382 - digit_2_precision: 0.0000e+00 - digit_3_precision: 0.0000e+00 - digit_4_precision: 0.0000e+00 - digit_5_precision: 0.0000e+00 - digit_6_precision: 0.0694 - digit_7_precision: 0.0000e+00 - digit_8_precision: 0.0000e+00 - digit_9_precision: 0.0000e+00 - digit_0_recall: 0.1503 - digit_1_recall: 0.3729 - digit_2_recall: 0.0000e+00 - digit_3_recall: 0.0000e+00 - digit_4_recall: 0.0000e+00 - digit_5_recall: 0.0000e+00 - digit_6_recall: 0.0255 - digit_7_recall: 0.0000e+00 - digit_8_recall: 0.0000e+00 - digit_9_recall: 0.0000e+00 - val_loss: 1.4132 - val_categorical_accuracy: 0.5434 - val_digit_0_precision: 0.9861 - val_digit_1_precision: 0.9401 - val_digit_2_precision: 0.0000e+00 - val_digit_3_precision: 0.0000e+00 - val_digit_4_precision: 0.0000e+00 - val_digit_5_precision: 0.0000e+00 - val_digit_6_precision: 0.7222 - val_digit_7_precision: 0.1667 - val_digit_8_precision: 0.0000e+00 - val_digit_9_precision: 0.0000e+00 - val_digit_0_recall: 0.7334 - val_digit_1_recall: 0.9634 - val_digit_2_recall: 0.0000e+00 - val_digit_3_recall: 0.0000e+00 - val_digit_4_recall: 0.0000e+00 - val_digit_5_recall: 0.0000e+00 - val_digit_6_recall: 0.2159 - val_digit_7_recall: 0.0265 - val_digit_8_recall: 0.0000e+00 - val_digit_9_recall: 0.0000e+00\n",
      "Epoch 4/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.9720 - categorical_accuracy: 0.6857 - digit_0_precision: 0.9421 - digit_1_precision: 0.9396 - digit_2_precision: 0.6862 - digit_3_precision: 0.8336 - digit_4_precision: 0.2624 - digit_5_precision: 0.4012 - digit_6_precision: 0.8311 - digit_7_precision: 0.7341 - digit_8_precision: 0.4277 - digit_9_precision: 0.5583 - digit_0_recall: 0.8141 - digit_1_recall: 0.9245 - digit_2_recall: 0.4233 - digit_3_recall: 0.4218 - digit_4_recall: 0.0944 - digit_5_recall: 0.1556 - digit_6_recall: 0.6506 - digit_7_recall: 0.4132 - digit_8_recall: 0.2462 - digit_9_recall: 0.2651\n",
      "Epoch 00004: val_loss improved from 1.41321 to 0.70360, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.9681 - categorical_accuracy: 0.6868 - digit_0_precision: 0.9429 - digit_1_precision: 0.9404 - digit_2_precision: 0.6906 - digit_3_precision: 0.8339 - digit_4_precision: 0.2588 - digit_5_precision: 0.4075 - digit_6_precision: 0.8312 - digit_7_precision: 0.7378 - digit_8_precision: 0.4337 - digit_9_precision: 0.5644 - digit_0_recall: 0.8166 - digit_1_recall: 0.9255 - digit_2_recall: 0.4278 - digit_3_recall: 0.4279 - digit_4_recall: 0.0930 - digit_5_recall: 0.1618 - digit_6_recall: 0.6531 - digit_7_recall: 0.4178 - digit_8_recall: 0.2532 - digit_9_recall: 0.2631 - val_loss: 0.7036 - val_categorical_accuracy: 0.7786 - val_digit_0_precision: 0.9448 - val_digit_1_precision: 1.0000 - val_digit_2_precision: 0.9565 - val_digit_3_precision: 0.9212 - val_digit_4_precision: 0.5556 - val_digit_5_precision: 0.7528 - val_digit_6_precision: 0.8714 - val_digit_7_precision: 0.8630 - val_digit_8_precision: 0.7201 - val_digit_9_precision: 0.7758 - val_digit_0_recall: 0.8467 - val_digit_1_recall: 0.9571 - val_digit_2_recall: 0.8255 - val_digit_3_recall: 0.7755 - val_digit_4_recall: 0.1500 - val_digit_5_recall: 0.4074 - val_digit_6_recall: 0.8589 - val_digit_7_recall: 0.5666 - val_digit_8_recall: 0.8066 - val_digit_9_recall: 0.4496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.5614 - categorical_accuracy: 0.8250 - digit_0_precision: 0.9475 - digit_1_precision: 0.9631 - digit_2_precision: 0.9451 - digit_3_precision: 0.9316 - digit_4_precision: 0.8891 - digit_5_precision: 0.8124 - digit_6_precision: 0.9469 - digit_7_precision: 0.8841 - digit_8_precision: 0.8506 - digit_9_precision: 0.7599 - digit_0_recall: 0.8513 - digit_1_recall: 0.9438 - digit_2_recall: 0.8449 - digit_3_recall: 0.7435 - digit_4_recall: 0.5452 - digit_5_recall: 0.5633 - digit_6_recall: 0.8898 - digit_7_recall: 0.7001 - digit_8_recall: 0.6945 - digit_9_recall: 0.6127\n",
      "Epoch 00005: val_loss improved from 0.70360 to 0.42737, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 4s 56ms/step - loss: 0.5590 - categorical_accuracy: 0.8260 - digit_0_precision: 0.9468 - digit_1_precision: 0.9636 - digit_2_precision: 0.9459 - digit_3_precision: 0.9326 - digit_4_precision: 0.8867 - digit_5_precision: 0.8150 - digit_6_precision: 0.9477 - digit_7_precision: 0.8858 - digit_8_precision: 0.8527 - digit_9_precision: 0.7612 - digit_0_recall: 0.8534 - digit_1_recall: 0.9446 - digit_2_recall: 0.8471 - digit_3_recall: 0.7436 - digit_4_recall: 0.5492 - digit_5_recall: 0.5659 - digit_6_recall: 0.8867 - digit_7_recall: 0.7025 - digit_8_recall: 0.6948 - digit_9_recall: 0.6134 - val_loss: 0.4274 - val_categorical_accuracy: 0.8802 - val_digit_0_precision: 0.9630 - val_digit_1_precision: 0.9671 - val_digit_2_precision: 0.9838 - val_digit_3_precision: 0.8956 - val_digit_4_precision: 0.9589 - val_digit_5_precision: 0.8843 - val_digit_6_precision: 0.9577 - val_digit_7_precision: 0.9907 - val_digit_8_precision: 0.8855 - val_digit_9_precision: 0.7736 - val_digit_0_recall: 0.9319 - val_digit_1_recall: 0.9627 - val_digit_2_recall: 0.8286 - val_digit_3_recall: 0.6946 - val_digit_4_recall: 0.7669 - val_digit_5_recall: 0.6086 - val_digit_6_recall: 0.9291 - val_digit_7_recall: 0.7549 - val_digit_8_recall: 0.8225 - val_digit_9_recall: 0.8795\n",
      "Epoch 6/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4634 - categorical_accuracy: 0.8565 - digit_0_precision: 0.9422 - digit_1_precision: 0.9545 - digit_2_precision: 0.9187 - digit_3_precision: 0.9104 - digit_4_precision: 0.9364 - digit_5_precision: 0.8165 - digit_6_precision: 0.9374 - digit_7_precision: 0.9496 - digit_8_precision: 0.8590 - digit_9_precision: 0.8314 - digit_0_recall: 0.9099 - digit_1_recall: 0.9442 - digit_2_recall: 0.8806 - digit_3_recall: 0.7494 - digit_4_recall: 0.7567 - digit_5_recall: 0.7133 - digit_6_recall: 0.9179 - digit_7_recall: 0.8066 - digit_8_recall: 0.7384 - digit_9_recall: 0.7384 ETA: 1s - loss: 0.4679 - categorical_accuracy: 0.8573 - digit_0_precision: 0.9409 - digit_1_precision: 0.9594 - digit_2_precision: 0.9215 - digit_3_precision: 0.9128 - digit_4_precision: 0.9368 - digit_5_precision: 0.8262 - digit_6_precision: 0.9356 - digit_7_precision: 0.9527 - digit_8_precision: 0.8429 - digit_9_precision: 0.8318 - digit_0_recall: 0.9108 - digit_1_recall: 0.9433 - digit_2_recall: 0.8784 - digit_3_recall: 0.7599 - digit_4_recall: 0.7383 - digit_5_recall: 0.7036 - digit_6_recall: 0.9181 - digit_7_recall: 0.7962 - digit_8_recall: 0.7312  - ETA: 0s - loss: 0.4658 - categorical_accuracy: 0.8546 - digit_0_precision: 0.9406 - digit_1_precision: 0.9568 - digit_2_precision: 0.9182 - digit_3_precision: 0.9114 - digit_4_precision: 0.9346 - digit_5_precision: 0.8256 - digit_6_precision: 0.9356 - digit_7_precision: 0.9554 - digit_8_precision: 0.8590 - digit_9_precision: 0.8265 - digit_0_recall: 0.9072 - digit_1_recall: 0.9426 - digit_2_recall: 0.8772 - digit_3_recall: 0.7475 - digit_4_recall: 0.7513 - digit_5_recall: 0.7231 - digit_6_recall: 0.9212 - digit_7_recall: 0.8034 - digit_8_recall: 0.7329 - digit_9_recall: 0.\n",
      "Epoch 00006: val_loss improved from 0.42737 to 0.41381, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 4s 58ms/step - loss: 0.4630 - categorical_accuracy: 0.8566 - digit_0_precision: 0.9407 - digit_1_precision: 0.9551 - digit_2_precision: 0.9175 - digit_3_precision: 0.9116 - digit_4_precision: 0.9373 - digit_5_precision: 0.8190 - digit_6_precision: 0.9383 - digit_7_precision: 0.9503 - digit_8_precision: 0.8586 - digit_9_precision: 0.8303 - digit_0_recall: 0.9059 - digit_1_recall: 0.9450 - digit_2_recall: 0.8800 - digit_3_recall: 0.7528 - digit_4_recall: 0.7581 - digit_5_recall: 0.7138 - digit_6_recall: 0.9173 - digit_7_recall: 0.8070 - digit_8_recall: 0.7397 - digit_9_recall: 0.7365 - val_loss: 0.4138 - val_categorical_accuracy: 0.8793 - val_digit_0_precision: 1.0000 - val_digit_1_precision: 1.0000 - val_digit_2_precision: 0.9738 - val_digit_3_precision: 0.8390 - val_digit_4_precision: 0.9282 - val_digit_5_precision: 0.9194 - val_digit_6_precision: 0.9185 - val_digit_7_precision: 0.9938 - val_digit_8_precision: 0.7995 - val_digit_9_precision: 0.8349 - val_digit_0_recall: 0.8537 - val_digit_1_recall: 0.9596 - val_digit_2_recall: 0.8583 - val_digit_3_recall: 0.9642 - val_digit_4_recall: 0.7583 - val_digit_5_recall: 0.7499 - val_digit_6_recall: 0.9347 - val_digit_7_recall: 0.7220 - val_digit_8_recall: 0.8704 - val_digit_9_recall: 0.7806\n",
      "Epoch 7/24\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.3683 - categorical_accuracy: 0.8895 - digit_0_precision: 0.9749 - digit_1_precision: 0.9780 - digit_2_precision: 0.9204 - digit_3_precision: 0.9328 - digit_4_precision: 0.8894 - digit_5_precision: 0.9081 - digit_6_precision: 0.9387 - digit_7_precision: 0.9434 - digit_8_precision: 0.8864 - digit_9_precision: 0.8604 - digit_0_recall: 0.9444 - digit_1_recall: 0.9556 - digit_2_recall: 0.8852 - digit_3_recall: 0.8429 - digit_4_recall: 0.7919 - digit_5_recall: 0.8108 - digit_6_recall: 0.9177 - digit_7_recall: 0.8117 - digit_8_recall: 0.8271 - digit_9_recall: 0.7897\n",
      "Epoch 00007: val_loss improved from 0.41381 to 0.32609, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.3678 - categorical_accuracy: 0.8900 - digit_0_precision: 0.9756 - digit_1_precision: 0.9736 - digit_2_precision: 0.9226 - digit_3_precision: 0.9316 - digit_4_precision: 0.8886 - digit_5_precision: 0.9106 - digit_6_precision: 0.9404 - digit_7_precision: 0.9450 - digit_8_precision: 0.8895 - digit_9_precision: 0.8626 - digit_0_recall: 0.9436 - digit_1_recall: 0.9568 - digit_2_recall: 0.8883 - digit_3_recall: 0.8445 - digit_4_recall: 0.7977 - digit_5_recall: 0.8143 - digit_6_recall: 0.9200 - digit_7_recall: 0.8089 - digit_8_recall: 0.8265 - digit_9_recall: 0.7868 - val_loss: 0.3261 - val_categorical_accuracy: 0.8932 - val_digit_0_precision: 0.9583 - val_digit_1_precision: 0.9463 - val_digit_2_precision: 1.0000 - val_digit_3_precision: 0.8774 - val_digit_4_precision: 0.8333 - val_digit_5_precision: 0.9418 - val_digit_6_precision: 0.9187 - val_digit_7_precision: 0.9257 - val_digit_8_precision: 0.9074 - val_digit_9_precision: 0.9343 - val_digit_0_recall: 0.9522 - val_digit_1_recall: 0.9902 - val_digit_2_recall: 0.8672 - val_digit_3_recall: 0.8730 - val_digit_4_recall: 0.9187 - val_digit_5_recall: 0.8452 - val_digit_6_recall: 0.9138 - val_digit_7_recall: 0.8908 - val_digit_8_recall: 0.7450 - val_digit_9_recall: 0.7430\n",
      "Epoch 8/24\n",
      "51/72 [====================>.........] - ETA: 0s - loss: 0.3465 - categorical_accuracy: 0.8940 - digit_0_precision: 0.9653 - digit_1_precision: 0.9504 - digit_2_precision: 0.9309 - digit_3_precision: 0.9365 - digit_4_precision: 0.9177 - digit_5_precision: 0.9036 - digit_6_precision: 0.9493 - digit_7_precision: 0.9424 - digit_8_precision: 0.8830 - digit_9_precision: 0.8860 - digit_0_recall: 0.9522 - digit_1_recall: 0.9559 - digit_2_recall: 0.8753 - digit_3_recall: 0.8520 - digit_4_recall: 0.8424 - digit_5_recall: 0.8152 - digit_6_recall: 0.9169 - digit_7_recall: 0.8549 - digit_8_recall: 0.8065 - digit_9_recall: 0.80382020-05-22 17:00:55,927 - tensor_generators:189 - INFO - \n",
      "!!!!>~~~~~~~~~~~~ train_worker completed true epoch 1 ~~~~~~~~~~~~<!!!!\n",
      "Aggregated information string:\n",
      "\tGenerator looped & shuffled over 34927 paths. Epoch: 1\n",
      "\t34931 tensors were presented.\n",
      "\t0 paths were skipped because they previously failed.\n",
      "\tNo errors raised.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 17:00:55,929 - tensor_generators:200 - INFO - Categorical \n",
      "mnist_label has 34927 total examples.\n",
      "\tLabel digit_0 3425 examples, 9.81% of total.\n",
      "\tLabel digit_1 3958 examples, 11.33% of total.\n",
      "\tLabel digit_2 3404 examples, 9.75% of total.\n",
      "\tLabel digit_3 3577 examples, 10.24% of total.\n",
      "\tLabel digit_4 3403 examples, 9.74% of total.\n",
      "\tLabel digit_5 3117 examples, 8.92% of total.\n",
      "\tLabel digit_6 3480 examples, 9.96% of total.\n",
      "\tLabel digit_7 3664 examples, 10.49% of total.\n",
      "\tLabel digit_8 3395 examples, 9.72% of total.\n",
      "\tLabel digit_9 3504 examples, 10.03% of total.\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3385 - categorical_accuracy: 0.8963 - digit_0_precision: 0.9702 - digit_1_precision: 0.9576 - digit_2_precision: 0.9349 - digit_3_precision: 0.9277 - digit_4_precision: 0.9187 - digit_5_precision: 0.9146 - digit_6_precision: 0.9480 - digit_7_precision: 0.9451 - digit_8_precision: 0.8937 - digit_9_precision: 0.8863 - digit_0_recall: 0.9558 - digit_1_recall: 0.9551 - digit_2_recall: 0.8762 - digit_3_recall: 0.8481 - digit_4_recall: 0.8535 - digit_5_recall: 0.8131 - digit_6_recall: 0.9235 - digit_7_recall: 0.8547 - digit_8_recall: 0.8174 - digit_9_recall: 0.8118\n",
      "Epoch 00008: val_loss improved from 0.32609 to 0.30337, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.3382 - categorical_accuracy: 0.8965 - digit_0_precision: 0.9679 - digit_1_precision: 0.9582 - digit_2_precision: 0.9358 - digit_3_precision: 0.9264 - digit_4_precision: 0.9178 - digit_5_precision: 0.9158 - digit_6_precision: 0.9488 - digit_7_precision: 0.9447 - digit_8_precision: 0.8952 - digit_9_precision: 0.8878 - digit_0_recall: 0.9564 - digit_1_recall: 0.9557 - digit_2_recall: 0.8744 - digit_3_recall: 0.8502 - digit_4_recall: 0.8555 - digit_5_recall: 0.8087 - digit_6_recall: 0.9232 - digit_7_recall: 0.8555 - digit_8_recall: 0.8172 - digit_9_recall: 0.8105 - val_loss: 0.3034 - val_categorical_accuracy: 0.9158 - val_digit_0_precision: 0.9512 - val_digit_1_precision: 1.0000 - val_digit_2_precision: 0.9625 - val_digit_3_precision: 0.9416 - val_digit_4_precision: 0.9578 - val_digit_5_precision: 0.8804 - val_digit_6_precision: 0.9828 - val_digit_7_precision: 0.8777 - val_digit_8_precision: 0.8276 - val_digit_9_precision: 0.8790 - val_digit_0_recall: 0.9071 - val_digit_1_recall: 0.9682 - val_digit_2_recall: 0.8557 - val_digit_3_recall: 0.9196 - val_digit_4_recall: 0.8643 - val_digit_5_recall: 0.8496 - val_digit_6_recall: 0.9392 - val_digit_7_recall: 0.9446 - val_digit_8_recall: 0.8068 - val_digit_9_recall: 0.8970\n",
      "Epoch 9/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2812 - categorical_accuracy: 0.9179 - digit_0_precision: 0.9679 - digit_1_precision: 0.9838 - digit_2_precision: 0.9304 - digit_3_precision: 0.9601 - digit_4_precision: 0.9316 - digit_5_precision: 0.9043 - digit_6_precision: 0.9681 - digit_7_precision: 0.9403 - digit_8_precision: 0.9037 - digit_9_precision: 0.8946 - digit_0_recall: 0.9434 - digit_1_recall: 0.9885 - digit_2_recall: 0.9092 - digit_3_recall: 0.8682 - digit_4_recall: 0.8925 - digit_5_recall: 0.8667 - digit_6_recall: 0.9327 - digit_7_recall: 0.8541 - digit_8_recall: 0.8413 - digit_9_recall: 0.85232020-05-22 17:00:59,548 - tensor_generators:189 - INFO - \n",
      "!!!!>~~~~~~~~~~~~ validation_worker completed true epoch 1 ~~~~~~~~~~~~<!!!!\n",
      "Aggregated information string:\n",
      "\tGenerator looped & shuffled over 10085 paths. Epoch: 1\n",
      "\t10085 tensors were presented.\n",
      "\t0 paths were skipped because they previously failed.\n",
      "\tNo errors raised.\n",
      "2020-05-22 17:00:59,551 - tensor_generators:200 - INFO - Categorical \n",
      "mnist_label has 5042 total examples.\n",
      "\tLabel digit_0 535 examples, 10.61% of total.\n",
      "\tLabel digit_1 564 examples, 11.19% of total.\n",
      "\tLabel digit_2 536 examples, 10.63% of total.\n",
      "\tLabel digit_3 529 examples, 10.49% of total.\n",
      "\tLabel digit_4 476 examples, 9.44% of total.\n",
      "\tLabel digit_5 432 examples, 8.57% of total.\n",
      "\tLabel digit_6 506 examples, 10.04% of total.\n",
      "\tLabel digit_7 487 examples, 9.66% of total.\n",
      "\tLabel digit_8 462 examples, 9.16% of total.\n",
      "\tLabel digit_9 515 examples, 10.21% of total.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.30337 to 0.29728, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.2799 - categorical_accuracy: 0.9184 - digit_0_precision: 0.9683 - digit_1_precision: 0.9840 - digit_2_precision: 0.9298 - digit_3_precision: 0.9607 - digit_4_precision: 0.9326 - digit_5_precision: 0.9056 - digit_6_precision: 0.9686 - digit_7_precision: 0.9411 - digit_8_precision: 0.9051 - digit_9_precision: 0.8961 - digit_0_recall: 0.9442 - digit_1_recall: 0.9886 - digit_2_recall: 0.9089 - digit_3_recall: 0.8701 - digit_4_recall: 0.8940 - digit_5_recall: 0.8639 - digit_6_recall: 0.9336 - digit_7_recall: 0.8544 - digit_8_recall: 0.8435 - digit_9_recall: 0.8544 - val_loss: 0.2973 - val_categorical_accuracy: 0.9089 - val_digit_0_precision: 1.0000 - val_digit_1_precision: 0.9494 - val_digit_2_precision: 0.9610 - val_digit_3_precision: 0.9056 - val_digit_4_precision: 0.9784 - val_digit_5_precision: 0.9007 - val_digit_6_precision: 0.8883 - val_digit_7_precision: 0.9093 - val_digit_8_precision: 0.7960 - val_digit_9_precision: 0.9741 - val_digit_0_recall: 0.8955 - val_digit_1_recall: 0.9716 - val_digit_2_recall: 0.9230 - val_digit_3_recall: 0.8290 - val_digit_4_recall: 0.8523 - val_digit_5_recall: 0.8610 - val_digit_6_recall: 0.9411 - val_digit_7_recall: 0.8940 - val_digit_8_recall: 0.8986 - val_digit_9_recall: 0.7954\n",
      "Epoch 10/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2789 - categorical_accuracy: 0.9131 - digit_0_precision: 0.9780 - digit_1_precision: 0.9728 - digit_2_precision: 0.9258 - digit_3_precision: 0.9167 - digit_4_precision: 0.9245 - digit_5_precision: 0.9038 - digit_6_precision: 0.9544 - digit_7_precision: 0.9510 - digit_8_precision: 0.8967 - digit_9_precision: 0.8958 - digit_0_recall: 0.9424 - digit_1_recall: 0.9594 - digit_2_recall: 0.8967 - digit_3_recall: 0.8559 - digit_4_recall: 0.8887 - digit_5_recall: 0.8116 - digit_6_recall: 0.9500 - digit_7_recall: 0.8900 - digit_8_recall: 0.8639 - digit_9_recall: 0.8541\n",
      "Epoch 00010: val_loss improved from 0.29728 to 0.21381, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.2757 - categorical_accuracy: 0.9143 - digit_0_precision: 0.9783 - digit_1_precision: 0.9732 - digit_2_precision: 0.9268 - digit_3_precision: 0.9179 - digit_4_precision: 0.9255 - digit_5_precision: 0.9051 - digit_6_precision: 0.9551 - digit_7_precision: 0.9517 - digit_8_precision: 0.8981 - digit_9_precision: 0.8973 - digit_0_recall: 0.9432 - digit_1_recall: 0.9600 - digit_2_recall: 0.8981 - digit_3_recall: 0.8579 - digit_4_recall: 0.8903 - digit_5_recall: 0.8142 - digit_6_recall: 0.9507 - digit_7_recall: 0.8916 - digit_8_recall: 0.8658 - digit_9_recall: 0.8561 - val_loss: 0.2138 - val_categorical_accuracy: 0.9340 - val_digit_0_precision: 0.9444 - val_digit_1_precision: 0.9679 - val_digit_2_precision: 0.9545 - val_digit_3_precision: 0.9728 - val_digit_4_precision: 0.9335 - val_digit_5_precision: 0.9186 - val_digit_6_precision: 0.9699 - val_digit_7_precision: 0.9778 - val_digit_8_precision: 1.0000 - val_digit_9_precision: 0.8850 - val_digit_0_recall: 0.9157 - val_digit_1_recall: 0.9861 - val_digit_2_recall: 0.8973 - val_digit_3_recall: 0.9013 - val_digit_4_recall: 0.9203 - val_digit_5_recall: 0.9321 - val_digit_6_recall: 0.9468 - val_digit_7_recall: 0.9171 - val_digit_8_recall: 0.8860 - val_digit_9_recall: 0.8716\n",
      "Epoch 11/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2426 - categorical_accuracy: 0.9316 - digit_0_precision: 0.9746 - digit_1_precision: 0.9827 - digit_2_precision: 0.9476 - digit_3_precision: 0.9389 - digit_4_precision: 0.9549 - digit_5_precision: 0.9273 - digit_6_precision: 0.9711 - digit_7_precision: 0.9612 - digit_8_precision: 0.9142 - digit_9_precision: 0.9097 - digit_0_recall: 0.9569 - digit_1_recall: 0.9692 - digit_2_recall: 0.9142 - digit_3_recall: 0.8448 - digit_4_recall: 0.9017 - digit_5_recall: 0.9165 - digit_6_recall: 0.9579 - digit_7_recall: 0.9171 - digit_8_recall: 0.8641 - digit_9_recall: 0.8987\n",
      "Epoch 00011: val_loss did not improve from 0.21381\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.2425 - categorical_accuracy: 0.9319 - digit_0_precision: 0.9749 - digit_1_precision: 0.9829 - digit_2_precision: 0.9467 - digit_3_precision: 0.9367 - digit_4_precision: 0.9556 - digit_5_precision: 0.9283 - digit_6_precision: 0.9715 - digit_7_precision: 0.9618 - digit_8_precision: 0.9154 - digit_9_precision: 0.9109 - digit_0_recall: 0.9575 - digit_1_recall: 0.9682 - digit_2_recall: 0.9154 - digit_3_recall: 0.8453 - digit_4_recall: 0.9030 - digit_5_recall: 0.9130 - digit_6_recall: 0.9584 - digit_7_recall: 0.9183 - digit_8_recall: 0.8660 - digit_9_recall: 0.9001 - val_loss: 0.2439 - val_categorical_accuracy: 0.9253 - val_digit_0_precision: 1.0000 - val_digit_1_precision: 0.9680 - val_digit_2_precision: 0.8883 - val_digit_3_precision: 0.9463 - val_digit_4_precision: 0.8837 - val_digit_5_precision: 0.9537 - val_digit_6_precision: 0.9722 - val_digit_7_precision: 0.9741 - val_digit_8_precision: 0.9099 - val_digit_9_precision: 0.7912 - val_digit_0_recall: 0.9187 - val_digit_1_recall: 0.9670 - val_digit_2_recall: 0.9722 - val_digit_3_recall: 0.8814 - val_digit_4_recall: 0.8735 - val_digit_5_recall: 0.7929 - val_digit_6_recall: 0.9469 - val_digit_7_recall: 0.8237 - val_digit_8_recall: 0.8492 - val_digit_9_recall: 0.7925\n",
      "Epoch 12/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2120 - categorical_accuracy: 0.9346 - digit_0_precision: 0.9561 - digit_1_precision: 0.9788 - digit_2_precision: 0.9567 - digit_3_precision: 0.9357 - digit_4_precision: 0.9579 - digit_5_precision: 0.9483 - digit_6_precision: 0.9548 - digit_7_precision: 0.9580 - digit_8_precision: 0.9468 - digit_9_precision: 0.9219 - digit_0_recall: 0.9241 - digit_1_recall: 0.9805 - digit_2_recall: 0.9102 - digit_3_recall: 0.9088 - digit_4_recall: 0.9150 - digit_5_recall: 0.8906 - digit_6_recall: 0.9554 - digit_7_recall: 0.9162 - digit_8_recall: 0.9011 - digit_9_recall: 0.9117\n",
      "Epoch 00012: val_loss did not improve from 0.21381\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.2130 - categorical_accuracy: 0.9340 - digit_0_precision: 0.9567 - digit_1_precision: 0.9771 - digit_2_precision: 0.9573 - digit_3_precision: 0.9366 - digit_4_precision: 0.9562 - digit_5_precision: 0.9491 - digit_6_precision: 0.9514 - digit_7_precision: 0.9552 - digit_8_precision: 0.9476 - digit_9_precision: 0.9196 - digit_0_recall: 0.9251 - digit_1_recall: 0.9788 - digit_2_recall: 0.9099 - digit_3_recall: 0.9100 - digit_4_recall: 0.9139 - digit_5_recall: 0.8902 - digit_6_recall: 0.9560 - digit_7_recall: 0.9154 - digit_8_recall: 0.8985 - digit_9_recall: 0.9074 - val_loss: 0.2312 - val_categorical_accuracy: 0.9288 - val_digit_0_precision: 0.9685 - val_digit_1_precision: 0.9624 - val_digit_2_precision: 0.8488 - val_digit_3_precision: 0.9753 - val_digit_4_precision: 0.8691 - val_digit_5_precision: 0.9313 - val_digit_6_precision: 0.9222 - val_digit_7_precision: 1.0000 - val_digit_8_precision: 0.9569 - val_digit_9_precision: 0.9638 - val_digit_0_recall: 0.9772 - val_digit_1_recall: 0.9750 - val_digit_2_recall: 0.9051 - val_digit_3_recall: 0.8617 - val_digit_4_recall: 0.9458 - val_digit_5_recall: 0.8944 - val_digit_6_recall: 1.0000 - val_digit_7_recall: 0.8828 - val_digit_8_recall: 0.8894 - val_digit_9_recall: 0.8012\n",
      "Epoch 13/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2211 - categorical_accuracy: 0.9371 - digit_0_precision: 0.9607 - digit_1_precision: 0.9779 - digit_2_precision: 0.9463 - digit_3_precision: 0.9507 - digit_4_precision: 0.9067 - digit_5_precision: 0.9341 - digit_6_precision: 0.9700 - digit_7_precision: 0.9388 - digit_8_precision: 0.9399 - digit_9_precision: 0.9185 - digit_0_recall: 0.9684 - digit_1_recall: 0.9640 - digit_2_recall: 0.9267 - digit_3_recall: 0.9302 - digit_4_recall: 0.8653 - digit_5_recall: 0.9144 - digit_6_recall: 0.9498 - digit_7_recall: 0.8878 - digit_8_recall: 0.9031 - digit_9_recall: 0.8718\n",
      "Epoch 00013: val_loss did not improve from 0.21381\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.2209 - categorical_accuracy: 0.9371 - digit_0_precision: 0.9612 - digit_1_precision: 0.9782 - digit_2_precision: 0.9451 - digit_3_precision: 0.9514 - digit_4_precision: 0.9080 - digit_5_precision: 0.9350 - digit_6_precision: 0.9704 - digit_7_precision: 0.9374 - digit_8_precision: 0.9380 - digit_9_precision: 0.9161 - digit_0_recall: 0.9688 - digit_1_recall: 0.9645 - digit_2_recall: 0.9277 - digit_3_recall: 0.9296 - digit_4_recall: 0.8672 - digit_5_recall: 0.9140 - digit_6_recall: 0.9505 - digit_7_recall: 0.8871 - digit_8_recall: 0.9045 - digit_9_recall: 0.8701 - val_loss: 0.2510 - val_categorical_accuracy: 0.9227 - val_digit_0_precision: 1.0000 - val_digit_1_precision: 1.0000 - val_digit_2_precision: 0.9627 - val_digit_3_precision: 0.9828 - val_digit_4_precision: 0.8948 - val_digit_5_precision: 0.9861 - val_digit_6_precision: 0.9087 - val_digit_7_precision: 0.9545 - val_digit_8_precision: 0.8290 - val_digit_9_precision: 0.9201 - val_digit_0_recall: 0.8781 - val_digit_1_recall: 0.9680 - val_digit_2_recall: 0.9438 - val_digit_3_recall: 0.7946 - val_digit_4_recall: 0.9931 - val_digit_5_recall: 0.7678 - val_digit_6_recall: 0.9810 - val_digit_7_recall: 0.9077 - val_digit_8_recall: 0.9151 - val_digit_9_recall: 0.9126\n",
      "Epoch 14/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2018 - categorical_accuracy: 0.9360 - digit_0_precision: 0.9782 - digit_1_precision: 0.9789 - digit_2_precision: 0.9673 - digit_3_precision: 0.9452 - digit_4_precision: 0.9469 - digit_5_precision: 0.9272 - digit_6_precision: 0.9537 - digit_7_precision: 0.9516 - digit_8_precision: 0.9256 - digit_9_precision: 0.9175 - digit_0_recall: 0.9501 - digit_1_recall: 0.9761 - digit_2_recall: 0.9227 - digit_3_recall: 0.9011 - digit_4_recall: 0.9350 - digit_5_recall: 0.9008 - digit_6_recall: 0.9625 - digit_7_recall: 0.9263 - digit_8_recall: 0.8926 - digit_9_recall: 0.8910\n",
      "Epoch 00014: val_loss improved from 0.21381 to 0.15011, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 3s 40ms/step - loss: 0.2014 - categorical_accuracy: 0.9355 - digit_0_precision: 0.9765 - digit_1_precision: 0.9792 - digit_2_precision: 0.9618 - digit_3_precision: 0.9460 - digit_4_precision: 0.9476 - digit_5_precision: 0.9282 - digit_6_precision: 0.9544 - digit_7_precision: 0.9523 - digit_8_precision: 0.9266 - digit_9_precision: 0.9186 - digit_0_recall: 0.9508 - digit_1_recall: 0.9765 - digit_2_recall: 0.9237 - digit_3_recall: 0.8921 - digit_4_recall: 0.9359 - digit_5_recall: 0.9001 - digit_6_recall: 0.9630 - digit_7_recall: 0.9274 - digit_8_recall: 0.8913 - digit_9_recall: 0.8910 - val_loss: 0.1501 - val_categorical_accuracy: 0.9531 - val_digit_0_precision: 1.0000 - val_digit_1_precision: 0.9688 - val_digit_2_precision: 0.9444 - val_digit_3_precision: 0.9438 - val_digit_4_precision: 0.9393 - val_digit_5_precision: 0.9477 - val_digit_6_precision: 0.9745 - val_digit_7_precision: 1.0000 - val_digit_8_precision: 0.9532 - val_digit_9_precision: 0.9247 - val_digit_0_recall: 0.9443 - val_digit_1_recall: 0.9861 - val_digit_2_recall: 0.9087 - val_digit_3_recall: 0.9389 - val_digit_4_recall: 0.9111 - val_digit_5_recall: 0.9567 - val_digit_6_recall: 0.9483 - val_digit_7_recall: 0.9303 - val_digit_8_recall: 0.8761 - val_digit_9_recall: 0.9519\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/72 [============================>.] - ETA: 0s - loss: 0.2093 - categorical_accuracy: 0.9379 - digit_0_precision: 0.9736 - digit_1_precision: 0.9777 - digit_2_precision: 0.9453 - digit_3_precision: 0.9518 - digit_4_precision: 0.9481 - digit_5_precision: 0.9438 - digit_6_precision: 0.9565 - digit_7_precision: 0.9579 - digit_8_precision: 0.9420 - digit_9_precision: 0.8836 - digit_0_recall: 0.9596 - digit_1_recall: 0.9681 - digit_2_recall: 0.9146 - digit_3_recall: 0.9055 - digit_4_recall: 0.9312 - digit_5_recall: 0.9045 - digit_6_recall: 0.9544 - digit_7_recall: 0.9033 - digit_8_recall: 0.9004 - digit_9_recall: 0.8789\n",
      "Epoch 00015: val_loss did not improve from 0.15011\n",
      "72/72 [==============================] - 3s 39ms/step - loss: 0.2104 - categorical_accuracy: 0.9371 - digit_0_precision: 0.9720 - digit_1_precision: 0.9764 - digit_2_precision: 0.9461 - digit_3_precision: 0.9525 - digit_4_precision: 0.9488 - digit_5_precision: 0.9400 - digit_6_precision: 0.9571 - digit_7_precision: 0.9569 - digit_8_precision: 0.9428 - digit_9_precision: 0.8852 - digit_0_recall: 0.9602 - digit_1_recall: 0.9686 - digit_2_recall: 0.9132 - digit_3_recall: 0.9045 - digit_4_recall: 0.9321 - digit_5_recall: 0.9031 - digit_6_recall: 0.9481 - digit_7_recall: 0.9047 - digit_8_recall: 0.8972 - digit_9_recall: 0.8806 - val_loss: 0.1881 - val_categorical_accuracy: 0.9479 - val_digit_0_precision: 0.9846 - val_digit_1_precision: 0.9780 - val_digit_2_precision: 1.0000 - val_digit_3_precision: 0.8966 - val_digit_4_precision: 0.9390 - val_digit_5_precision: 0.9629 - val_digit_6_precision: 1.0000 - val_digit_7_precision: 0.8606 - val_digit_8_precision: 0.9550 - val_digit_9_precision: 0.9688 - val_digit_0_recall: 0.9704 - val_digit_1_recall: 0.9752 - val_digit_2_recall: 0.8835 - val_digit_3_recall: 0.9821 - val_digit_4_recall: 0.9869 - val_digit_5_recall: 0.8870 - val_digit_6_recall: 0.9327 - val_digit_7_recall: 0.8989 - val_digit_8_recall: 0.9039 - val_digit_9_recall: 0.9308\n",
      "Epoch 16/24\n",
      "19/72 [======>.......................] - ETA: 1s - loss: 0.1895 - categorical_accuracy: 0.9416 - digit_0_precision: 0.9832 - digit_1_precision: 1.0000 - digit_2_precision: 0.9039 - digit_3_precision: 0.9104 - digit_4_precision: 0.9596 - digit_5_precision: 0.9490 - digit_6_precision: 0.9722 - digit_7_precision: 0.9866 - digit_8_precision: 0.9459 - digit_9_precision: 0.8883 - digit_0_recall: 0.9763 - digit_1_recall: 0.9644 - digit_2_recall: 0.9144 - digit_3_recall: 0.9126 - digit_4_recall: 0.9448 - digit_5_recall: 0.8768 - digit_6_recall: 0.9620 - digit_7_recall: 0.9505 - digit_8_recall: 0.9072 - digit_9_recall: 0.86582020-05-22 17:01:16,386 - tensor_generators:189 - INFO - \n",
      "!!!!>~~~~~~~~~~~~ train_worker completed true epoch 2 ~~~~~~~~~~~~<!!!!\n",
      "Aggregated information string:\n",
      "\tGenerator looped & shuffled over 34927 paths. Epoch: 2\n",
      "\t17464 tensors were presented.\n",
      "\t0 paths were skipped because they previously failed.\n",
      "\tNo errors raised.\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1874 - categorical_accuracy: 0.9419 - digit_0_precision: 0.9627 - digit_1_precision: 0.9843 - digit_2_precision: 0.9444 - digit_3_precision: 0.9124 - digit_4_precision: 0.9475 - digit_5_precision: 0.9650 - digit_6_precision: 0.9770 - digit_7_precision: 0.9657 - digit_8_precision: 0.9567 - digit_9_precision: 0.8967 - digit_0_recall: 0.9637 - digit_1_recall: 0.9677 - digit_2_recall: 0.9259 - digit_3_recall: 0.9172 - digit_4_recall: 0.9385 - digit_5_recall: 0.9015 - digit_6_recall: 0.9609 - digit_7_recall: 0.9304 - digit_8_recall: 0.9226 - digit_9_recall: 0.86092020-05-22 17:01:18,281 - tensor_generators:189 - INFO - \n",
      "!!!!>~~~~~~~~~~~~ validation_worker completed true epoch 2 ~~~~~~~~~~~~<!!!!\n",
      "Aggregated information string:\n",
      "\tGenerator looped & shuffled over 10085 paths. Epoch: 2\n",
      "\t5043 tensors were presented.\n",
      "\t0 paths were skipped because they previously failed.\n",
      "\tNo errors raised.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.15011\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.1874 - categorical_accuracy: 0.9416 - digit_0_precision: 0.9632 - digit_1_precision: 0.9830 - digit_2_precision: 0.9451 - digit_3_precision: 0.9137 - digit_4_precision: 0.9463 - digit_5_precision: 0.9655 - digit_6_precision: 0.9773 - digit_7_precision: 0.9662 - digit_8_precision: 0.9573 - digit_9_precision: 0.8969 - digit_0_recall: 0.9642 - digit_1_recall: 0.9682 - digit_2_recall: 0.9270 - digit_3_recall: 0.9163 - digit_4_recall: 0.9393 - digit_5_recall: 0.9029 - digit_6_recall: 0.9614 - digit_7_recall: 0.9279 - digit_8_recall: 0.9190 - digit_9_recall: 0.8615 - val_loss: 0.2051 - val_categorical_accuracy: 0.9375 - val_digit_0_precision: 0.9921 - val_digit_1_precision: 0.9921 - val_digit_2_precision: 0.8329 - val_digit_3_precision: 0.9769 - val_digit_4_precision: 0.9921 - val_digit_5_precision: 0.9412 - val_digit_6_precision: 0.9209 - val_digit_7_precision: 0.9739 - val_digit_8_precision: 0.9907 - val_digit_9_precision: 0.9545 - val_digit_0_recall: 0.9308 - val_digit_1_recall: 0.9290 - val_digit_2_recall: 0.9870 - val_digit_3_recall: 0.9264 - val_digit_4_recall: 0.9312 - val_digit_5_recall: 0.9841 - val_digit_6_recall: 1.0000 - val_digit_7_recall: 0.9273 - val_digit_8_recall: 0.6681 - val_digit_9_recall: 0.9271\n",
      "Epoch 17/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1823 - categorical_accuracy: 0.9434 - digit_0_precision: 0.9757 - digit_1_precision: 0.9793 - digit_2_precision: 0.9367 - digit_3_precision: 0.9451 - digit_4_precision: 0.9639 - digit_5_precision: 0.9372 - digit_6_precision: 0.9781 - digit_7_precision: 0.9661 - digit_8_precision: 0.9425 - digit_9_precision: 0.9200 - digit_0_recall: 0.9745 - digit_1_recall: 0.9689 - digit_2_recall: 0.9263 - digit_3_recall: 0.9299 - digit_4_recall: 0.9439 - digit_5_recall: 0.9170 - digit_6_recall: 0.9632 - digit_7_recall: 0.9339 - digit_8_recall: 0.8736 - digit_9_recall: 0.9235\n",
      "Epoch 00017: val_loss improved from 0.15011 to 0.14112, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 3s 38ms/step - loss: 0.1818 - categorical_accuracy: 0.9438 - digit_0_precision: 0.9760 - digit_1_precision: 0.9795 - digit_2_precision: 0.9376 - digit_3_precision: 0.9459 - digit_4_precision: 0.9644 - digit_5_precision: 0.9352 - digit_6_precision: 0.9784 - digit_7_precision: 0.9665 - digit_8_precision: 0.9433 - digit_9_precision: 0.9188 - digit_0_recall: 0.9749 - digit_1_recall: 0.9693 - digit_2_recall: 0.9273 - digit_3_recall: 0.9278 - digit_4_recall: 0.9447 - digit_5_recall: 0.9182 - digit_6_recall: 0.9637 - digit_7_recall: 0.9331 - digit_8_recall: 0.8754 - digit_9_recall: 0.9246 - val_loss: 0.1411 - val_categorical_accuracy: 0.9609 - val_digit_0_precision: 0.9870 - val_digit_1_precision: 1.0000 - val_digit_2_precision: 0.9458 - val_digit_3_precision: 1.0000 - val_digit_4_precision: 0.9833 - val_digit_5_precision: 0.9745 - val_digit_6_precision: 0.9601 - val_digit_7_precision: 0.9660 - val_digit_8_precision: 0.9828 - val_digit_9_precision: 0.9838 - val_digit_0_recall: 0.9472 - val_digit_1_recall: 0.9875 - val_digit_2_recall: 0.9727 - val_digit_3_recall: 0.9575 - val_digit_4_recall: 0.9764 - val_digit_5_recall: 0.9296 - val_digit_6_recall: 0.9869 - val_digit_7_recall: 0.9799 - val_digit_8_recall: 0.9100 - val_digit_9_recall: 0.9112\n",
      "Epoch 18/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1703 - categorical_accuracy: 0.9459 - digit_0_precision: 0.9630 - digit_1_precision: 0.9909 - digit_2_precision: 0.9544 - digit_3_precision: 0.9510 - digit_4_precision: 0.9560 - digit_5_precision: 0.9292 - digit_6_precision: 0.9656 - digit_7_precision: 0.9611 - digit_8_precision: 0.9525 - digit_9_precision: 0.9243 - digit_0_recall: 0.9436 - digit_1_recall: 0.9786 - digit_2_recall: 0.9289 - digit_3_recall: 0.9138 - digit_4_recall: 0.9481 - digit_5_recall: 0.9191 - digit_6_recall: 0.9614 - digit_7_recall: 0.9235 - digit_8_recall: 0.9076 - digit_9_recall: 0.9106\n",
      "Epoch 00018: val_loss improved from 0.14112 to 0.10986, saving model to ./runs/learn_mnist/learn_mnist.h5\n",
      "72/72 [==============================] - 3s 37ms/step - loss: 0.1710 - categorical_accuracy: 0.9455 - digit_0_precision: 0.9635 - digit_1_precision: 0.9910 - digit_2_precision: 0.9550 - digit_3_precision: 0.9517 - digit_4_precision: 0.9566 - digit_5_precision: 0.9267 - digit_6_precision: 0.9661 - digit_7_precision: 0.9617 - digit_8_precision: 0.9531 - digit_9_precision: 0.9212 - digit_0_recall: 0.9444 - digit_1_recall: 0.9789 - digit_2_recall: 0.9299 - digit_3_recall: 0.9150 - digit_4_recall: 0.9433 - digit_5_recall: 0.9183 - digit_6_recall: 0.9573 - digit_7_recall: 0.9222 - digit_8_recall: 0.9089 - digit_9_recall: 0.9118 - val_loss: 0.1099 - val_categorical_accuracy: 0.9653 - val_digit_0_precision: 0.9815 - val_digit_1_precision: 0.9828 - val_digit_2_precision: 0.9938 - val_digit_3_precision: 0.9522 - val_digit_4_precision: 0.9455 - val_digit_5_precision: 0.9889 - val_digit_6_precision: 0.9749 - val_digit_7_precision: 0.9889 - val_digit_8_precision: 0.9450 - val_digit_9_precision: 0.9588 - val_digit_0_recall: 0.9568 - val_digit_1_recall: 0.9861 - val_digit_2_recall: 0.9444 - val_digit_3_recall: 0.9665 - val_digit_4_recall: 0.9740 - val_digit_5_recall: 0.9490 - val_digit_6_recall: 0.9699 - val_digit_7_recall: 0.9431 - val_digit_8_recall: 0.9869 - val_digit_9_recall: 0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1576 - categorical_accuracy: 0.9496 - digit_0_precision: 0.9720 - digit_1_precision: 0.9792 - digit_2_precision: 0.9623 - digit_3_precision: 0.9628 - digit_4_precision: 0.9559 - digit_5_precision: 0.9635 - digit_6_precision: 0.9684 - digit_7_precision: 0.9556 - digit_8_precision: 0.9570 - digit_9_precision: 0.9175 - digit_0_recall: 0.9661 - digit_1_recall: 0.9669 - digit_2_recall: 0.9621 - digit_3_recall: 0.9275 - digit_4_recall: 0.9206 - digit_5_recall: 0.9235 - digit_6_recall: 0.9666 - digit_7_recall: 0.9329 - digit_8_recall: 0.9350 - digit_9_recall: 0.9145\n",
      "Epoch 00019: val_loss did not improve from 0.10986\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.1571 - categorical_accuracy: 0.9497 - digit_0_precision: 0.9724 - digit_1_precision: 0.9794 - digit_2_precision: 0.9605 - digit_3_precision: 0.9610 - digit_4_precision: 0.9565 - digit_5_precision: 0.9640 - digit_6_precision: 0.9674 - digit_7_precision: 0.9562 - digit_8_precision: 0.9576 - digit_9_precision: 0.9186 - digit_0_recall: 0.9666 - digit_1_recall: 0.9657 - digit_2_recall: 0.9604 - digit_3_recall: 0.9285 - digit_4_recall: 0.9217 - digit_5_recall: 0.9246 - digit_6_recall: 0.9671 - digit_7_recall: 0.9315 - digit_8_recall: 0.9343 - digit_9_recall: 0.9157 - val_loss: 0.1627 - val_categorical_accuracy: 0.9601 - val_digit_0_precision: 0.9907 - val_digit_1_precision: 1.0000 - val_digit_2_precision: 0.9880 - val_digit_3_precision: 0.9339 - val_digit_4_precision: 0.9662 - val_digit_5_precision: 0.9334 - val_digit_6_precision: 0.9796 - val_digit_7_precision: 1.0000 - val_digit_8_precision: 0.9556 - val_digit_9_precision: 0.9418 - val_digit_0_recall: 0.9949 - val_digit_1_recall: 0.9806 - val_digit_2_recall: 0.8960 - val_digit_3_recall: 0.9647 - val_digit_4_recall: 0.9722 - val_digit_5_recall: 0.9519 - val_digit_6_recall: 0.9657 - val_digit_7_recall: 0.8828 - val_digit_8_recall: 0.9551 - val_digit_9_recall: 0.9387\n",
      "Epoch 20/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1407 - categorical_accuracy: 0.9595 - digit_0_precision: 0.9597 - digit_1_precision: 0.9873 - digit_2_precision: 0.9709 - digit_3_precision: 0.9644 - digit_4_precision: 0.9532 - digit_5_precision: 0.9357 - digit_6_precision: 0.9663 - digit_7_precision: 0.9690 - digit_8_precision: 0.9277 - digit_9_precision: 0.9558 - digit_0_recall: 0.9574 - digit_1_recall: 0.9812 - digit_2_recall: 0.9466 - digit_3_recall: 0.9477 - digit_4_recall: 0.9460 - digit_5_recall: 0.9163 - digit_6_recall: 0.9631 - digit_7_recall: 0.9571 - digit_8_recall: 0.9251 - digit_9_recall: 0.9335\n",
      "Epoch 00020: val_loss did not improve from 0.10986\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.1416 - categorical_accuracy: 0.9594 - digit_0_precision: 0.9603 - digit_1_precision: 0.9864 - digit_2_precision: 0.9694 - digit_3_precision: 0.9649 - digit_4_precision: 0.9539 - digit_5_precision: 0.9366 - digit_6_precision: 0.9668 - digit_7_precision: 0.9695 - digit_8_precision: 0.9217 - digit_9_precision: 0.9564 - digit_0_recall: 0.9580 - digit_1_recall: 0.9804 - digit_2_recall: 0.9473 - digit_3_recall: 0.9484 - digit_4_recall: 0.9468 - digit_5_recall: 0.9174 - digit_6_recall: 0.9636 - digit_7_recall: 0.9553 - digit_8_recall: 0.9261 - digit_9_recall: 0.9332 - val_loss: 0.1160 - val_categorical_accuracy: 0.9635 - val_digit_0_precision: 0.9658 - val_digit_1_precision: 1.0000 - val_digit_2_precision: 0.9666 - val_digit_3_precision: 0.9653 - val_digit_4_precision: 0.9749 - val_digit_5_precision: 0.9623 - val_digit_6_precision: 0.9537 - val_digit_7_precision: 0.9545 - val_digit_8_precision: 0.9938 - val_digit_9_precision: 0.9869 - val_digit_0_recall: 0.9949 - val_digit_1_recall: 0.9861 - val_digit_2_recall: 0.9500 - val_digit_3_recall: 0.9944 - val_digit_4_recall: 0.9931 - val_digit_5_recall: 0.9292 - val_digit_6_recall: 0.9691 - val_digit_7_recall: 0.9448 - val_digit_8_recall: 0.9039 - val_digit_9_recall: 0.9344\n",
      "Epoch 21/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1511 - categorical_accuracy: 0.9494 - digit_0_precision: 0.9593 - digit_1_precision: 0.9830 - digit_2_precision: 0.9587 - digit_3_precision: 0.9643 - digit_4_precision: 0.9566 - digit_5_precision: 0.9632 - digit_6_precision: 0.9685 - digit_7_precision: 0.9557 - digit_8_precision: 0.9381 - digit_9_precision: 0.9308 - digit_0_recall: 0.9567 - digit_1_recall: 0.9732 - digit_2_recall: 0.9477 - digit_3_recall: 0.9036 - digit_4_recall: 0.9090 - digit_5_recall: 0.9481 - digit_6_recall: 0.9646 - digit_7_recall: 0.9405 - digit_8_recall: 0.9173 - digit_9_recall: 0.9150\n",
      "Epoch 00021: val_loss did not improve from 0.10986\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.1500 - categorical_accuracy: 0.9501 - digit_0_precision: 0.9599 - digit_1_precision: 0.9833 - digit_2_precision: 0.9593 - digit_3_precision: 0.9648 - digit_4_precision: 0.9572 - digit_5_precision: 0.9637 - digit_6_precision: 0.9690 - digit_7_precision: 0.9563 - digit_8_precision: 0.9389 - digit_9_precision: 0.9318 - digit_0_recall: 0.9573 - digit_1_recall: 0.9736 - digit_2_recall: 0.9484 - digit_3_recall: 0.9049 - digit_4_recall: 0.9103 - digit_5_recall: 0.9461 - digit_6_recall: 0.9651 - digit_7_recall: 0.9414 - digit_8_recall: 0.9185 - digit_9_recall: 0.9162 - val_loss: 0.1913 - val_categorical_accuracy: 0.9314 - val_digit_0_precision: 0.9861 - val_digit_1_precision: 0.9463 - val_digit_2_precision: 0.9907 - val_digit_3_precision: 0.9827 - val_digit_4_precision: 0.7619 - val_digit_5_precision: 0.9828 - val_digit_6_precision: 0.9545 - val_digit_7_precision: 0.9883 - val_digit_8_precision: 0.9075 - val_digit_9_precision: 0.9772 - val_digit_0_recall: 0.9689 - val_digit_1_recall: 0.9819 - val_digit_2_recall: 0.8744 - val_digit_3_recall: 0.9569 - val_digit_4_recall: 0.9735 - val_digit_5_recall: 0.9147 - val_digit_6_recall: 0.9931 - val_digit_7_recall: 0.9134 - val_digit_8_recall: 0.8768 - val_digit_9_recall: 0.7582\n",
      "Epoch 22/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1645 - categorical_accuracy: 0.9533 - digit_0_precision: 0.9758 - digit_1_precision: 0.9770 - digit_2_precision: 0.9523 - digit_3_precision: 0.9626 - digit_4_precision: 0.9453 - digit_5_precision: 0.9224 - digit_6_precision: 0.9786 - digit_7_precision: 0.9748 - digit_8_precision: 0.9530 - digit_9_precision: 0.9508 - digit_0_recall: 0.9724 - digit_1_recall: 0.9824 - digit_2_recall: 0.9471 - digit_3_recall: 0.9309 - digit_4_recall: 0.9426 - digit_5_recall: 0.9119 - digit_6_recall: 0.9615 - digit_7_recall: 0.9392 - digit_8_recall: 0.9459 - digit_9_recall: 0.9157\n",
      "Epoch 00022: val_loss did not improve from 0.10986\n",
      "72/72 [==============================] - 3s 35ms/step - loss: 0.1635 - categorical_accuracy: 0.9533 - digit_0_precision: 0.9761 - digit_1_precision: 0.9773 - digit_2_precision: 0.9529 - digit_3_precision: 0.9631 - digit_4_precision: 0.9461 - digit_5_precision: 0.9234 - digit_6_precision: 0.9789 - digit_7_precision: 0.9723 - digit_8_precision: 0.9536 - digit_9_precision: 0.9515 - digit_0_recall: 0.9728 - digit_1_recall: 0.9826 - digit_2_recall: 0.9478 - digit_3_recall: 0.9318 - digit_4_recall: 0.9434 - digit_5_recall: 0.9132 - digit_6_recall: 0.9604 - digit_7_recall: 0.9401 - digit_8_recall: 0.9467 - digit_9_recall: 0.9100 - val_loss: 0.1454 - val_categorical_accuracy: 0.9505 - val_digit_0_precision: 0.9620 - val_digit_1_precision: 0.9759 - val_digit_2_precision: 0.9861 - val_digit_3_precision: 0.9403 - val_digit_4_precision: 0.9196 - val_digit_5_precision: 0.9244 - val_digit_6_precision: 0.9803 - val_digit_7_precision: 0.8708 - val_digit_8_precision: 0.9921 - val_digit_9_precision: 0.9676 - val_digit_0_recall: 0.9720 - val_digit_1_recall: 0.9861 - val_digit_2_recall: 0.9388 - val_digit_3_recall: 0.9653 - val_digit_4_recall: 0.9710 - val_digit_5_recall: 0.8685 - val_digit_6_recall: 0.9396 - val_digit_7_recall: 0.9819 - val_digit_8_recall: 0.8297 - val_digit_9_recall: 0.8582\n",
      "Epoch 23/24\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 0.1400 - categorical_accuracy: 0.9613 - digit_0_precision: 0.9769 - digit_1_precision: 0.9886 - digit_2_precision: 0.9609 - digit_3_precision: 0.9734 - digit_4_precision: 0.9802 - digit_5_precision: 0.9557 - digit_6_precision: 0.9762 - digit_7_precision: 0.9583 - digit_8_precision: 0.9493 - digit_9_precision: 0.9576 - digit_0_recall: 0.9860 - digit_1_recall: 0.9863 - digit_2_recall: 0.9531 - digit_3_recall: 0.9428 - digit_4_recall: 0.9418 - digit_5_recall: 0.9440 - digit_6_recall: 0.9842 - digit_7_recall: 0.9394 - digit_8_recall: 0.9159 - digit_9_recall: 0.92972020-05-22 17:01:36,222 - tensor_generators:189 - INFO - \n",
      "!!!!>~~~~~~~~~~~~ train_worker completed true epoch 3 ~~~~~~~~~~~~<!!!!\n",
      "Aggregated information string:\n",
      "\tGenerator looped & shuffled over 34927 paths. Epoch: 3\n",
      "\t11642 tensors were presented.\n",
      "\t0 paths were skipped because they previously failed.\n",
      "\tNo errors raised.\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1374 - categorical_accuracy: 0.9617 - digit_0_precision: 0.9795 - digit_1_precision: 0.9898 - digit_2_precision: 0.9633 - digit_3_precision: 0.9728 - digit_4_precision: 0.9769 - digit_5_precision: 0.9560 - digit_6_precision: 0.9789 - digit_7_precision: 0.9602 - digit_8_precision: 0.9499 - digit_9_precision: 0.9580 - digit_0_recall: 0.9762 - digit_1_recall: 0.9826 - digit_2_recall: 0.9528 - digit_3_recall: 0.9445 - digit_4_recall: 0.9448 - digit_5_recall: 0.9503 - digit_6_recall: 0.9844 - digit_7_recall: 0.9462 - digit_8_recall: 0.9206 - digit_9_recall: 0.92862020-05-22 17:01:36,549 - tensor_generators:189 - INFO - \n",
      "!!!!>~~~~~~~~~~~~ validation_worker completed true epoch 3 ~~~~~~~~~~~~<!!!!\n",
      "Aggregated information string:\n",
      "\tGenerator looped & shuffled over 10085 paths. Epoch: 3\n",
      "\t3362 tensors were presented.\n",
      "\t0 paths were skipped because they previously failed.\n",
      "\tNo errors raised.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.10986\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.1364 - categorical_accuracy: 0.9620 - digit_0_precision: 0.9798 - digit_1_precision: 0.9900 - digit_2_precision: 0.9638 - digit_3_precision: 0.9732 - digit_4_precision: 0.9773 - digit_5_precision: 0.9566 - digit_6_precision: 0.9791 - digit_7_precision: 0.9595 - digit_8_precision: 0.9506 - digit_9_precision: 0.9586 - digit_0_recall: 0.9765 - digit_1_recall: 0.9829 - digit_2_recall: 0.9517 - digit_3_recall: 0.9453 - digit_4_recall: 0.9456 - digit_5_recall: 0.9510 - digit_6_recall: 0.9846 - digit_7_recall: 0.9470 - digit_8_recall: 0.9217 - digit_9_recall: 0.9296 - val_loss: 0.1433 - val_categorical_accuracy: 0.9566 - val_digit_0_precision: 0.9806 - val_digit_1_precision: 0.9735 - val_digit_2_precision: 1.0000 - val_digit_3_precision: 0.9722 - val_digit_4_precision: 0.9194 - val_digit_5_precision: 0.9278 - val_digit_6_precision: 0.9921 - val_digit_7_precision: 0.9534 - val_digit_8_precision: 1.0000 - val_digit_9_precision: 0.9457 - val_digit_0_recall: 0.9574 - val_digit_1_recall: 1.0000 - val_digit_2_recall: 0.9116 - val_digit_3_recall: 0.9291 - val_digit_4_recall: 1.0000 - val_digit_5_recall: 0.9523 - val_digit_6_recall: 0.9728 - val_digit_7_recall: 0.9869 - val_digit_8_recall: 0.8632 - val_digit_9_recall: 0.8781\n",
      "Epoch 24/24\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.1218 - categorical_accuracy: 0.9608 - digit_0_precision: 0.9745 - digit_1_precision: 0.9821 - digit_2_precision: 0.9556 - digit_3_precision: 0.9683 - digit_4_precision: 0.9742 - digit_5_precision: 0.9721 - digit_6_precision: 0.9770 - digit_7_precision: 0.9732 - digit_8_precision: 0.9443 - digit_9_precision: 0.9641 - digit_0_recall: 0.9786 - digit_1_recall: 0.9809 - digit_2_recall: 0.9550 - digit_3_recall: 0.9493 - digit_4_recall: 0.9537 - digit_5_recall: 0.9535 - digit_6_recall: 0.9627 - digit_7_recall: 0.9535 - digit_8_recall: 0.9457 - digit_9_recall: 0.9295\n",
      "Epoch 00024: val_loss did not improve from 0.10986\n",
      "72/72 [==============================] - 3s 36ms/step - loss: 0.1211 - categorical_accuracy: 0.9612 - digit_0_precision: 0.9748 - digit_1_precision: 0.9824 - digit_2_precision: 0.9562 - digit_3_precision: 0.9670 - digit_4_precision: 0.9746 - digit_5_precision: 0.9724 - digit_6_precision: 0.9773 - digit_7_precision: 0.9735 - digit_8_precision: 0.9451 - digit_9_precision: 0.9646 - digit_0_recall: 0.9789 - digit_1_recall: 0.9811 - digit_2_recall: 0.9544 - digit_3_recall: 0.9500 - digit_4_recall: 0.9543 - digit_5_recall: 0.9541 - digit_6_recall: 0.9633 - digit_7_recall: 0.9541 - digit_8_recall: 0.9442 - digit_9_recall: 0.9304 - val_loss: 0.1359 - val_categorical_accuracy: 0.9575 - val_digit_0_precision: 1.0000 - val_digit_1_precision: 0.9465 - val_digit_2_precision: 1.0000 - val_digit_3_precision: 0.9695 - val_digit_4_precision: 1.0000 - val_digit_5_precision: 0.9171 - val_digit_6_precision: 0.9758 - val_digit_7_precision: 0.9907 - val_digit_8_precision: 0.9551 - val_digit_9_precision: 0.8121 - val_digit_0_recall: 0.9410 - val_digit_1_recall: 0.9907 - val_digit_2_recall: 0.9587 - val_digit_3_recall: 0.9634 - val_digit_4_recall: 0.9313 - val_digit_5_recall: 0.9383 - val_digit_6_recall: 0.9679 - val_digit_7_recall: 0.9679 - val_digit_8_recall: 0.9436 - val_digit_9_recall: 0.8906\n",
      "2020-05-22 17:01:39,325 - tensor_generators:226 - INFO - Stopped 4 workers.\n",
      "2020-05-22 17:01:39,328 - tensor_generators:226 - INFO - Stopped 2 workers.\n",
      "2020-05-22 17:01:39,329 - models:1092 - INFO - Model weights saved at: ./runs/learn_mnist/learn_mnist.h5\n",
      "2020-05-22 17:01:45,077 - plots:203 - INFO - Saved learning curves at:./runs/learn_mnist/metric_history_learn_mnist.png\n",
      "2020-05-22 17:01:45,241 - tensor_generators:149 - INFO - Started 3 test workers with cache size 0.0GB.\n",
      "2020-05-22 17:01:47,258 - tensor_generators:492 - INFO - Made a big batch of tensors with key:input_mnist_image_continuous and shape:(4096, 28, 28, 1).\n",
      "2020-05-22 17:01:47,260 - tensor_generators:492 - INFO - Made a big batch of tensors with key:output_mnist_label_categorical and shape:(4096, 10).\n",
      "2020-05-22 17:01:47,549 - tensor_generators:423 - WARNING - Test worker test_worker_0 completed a full epoch. Test results may be double counting samples.\n",
      "2020-05-22 17:01:47,610 - tensor_generators:423 - WARNING - Test worker test_worker_2 completed a full epoch. Test results may be double counting samples.\n",
      "2020-05-22 17:01:47,691 - tensor_generators:423 - WARNING - Test worker test_worker_1 completed a full epoch. Test results may be double counting samples.\n",
      "2020-05-22 17:01:48,127 - tensor_generators:423 - WARNING - Test worker test_worker_3 completed a full epoch. Test results may be double counting samples.\n",
      "2020-05-22 17:01:48,950 - plots:98 - INFO - For tm:mnist_label with channel map:{'digit_0': 0, 'digit_1': 1, 'digit_2': 2, 'digit_3': 3, 'digit_4': 4, 'digit_5': 5, 'digit_6': 6, 'digit_7': 7, 'digit_8': 8, 'digit_9': 9} examples:4096\n",
      "2020-05-22 17:01:48,953 - plots:99 - INFO - \n",
      "Sum Truth:[381. 478. 441. 415. 394. 383. 389. 416. 407. 392.] \n",
      "Sum pred :[359.30188 489.0348  416.965   435.38837 372.03302 392.648   377.84662\n",
      " 398.4692  398.46082 455.83762]\n",
      "2020-05-22 17:01:48,983 - plots:1645 - INFO - prAUC Label digit_0 mean precision:0.998 n=381\n",
      "2020-05-22 17:01:48,990 - plots:1645 - INFO - prAUC Label digit_1 mean precision:0.994 n=478\n",
      "2020-05-22 17:01:48,996 - plots:1645 - INFO - prAUC Label digit_2 mean precision:0.990 n=441\n",
      "2020-05-22 17:01:49,003 - plots:1645 - INFO - prAUC Label digit_3 mean precision:0.987 n=415\n",
      "2020-05-22 17:01:49,009 - plots:1645 - INFO - prAUC Label digit_4 mean precision:0.994 n=394\n",
      "2020-05-22 17:01:49,015 - plots:1645 - INFO - prAUC Label digit_5 mean precision:0.990 n=383\n",
      "2020-05-22 17:01:49,021 - plots:1645 - INFO - prAUC Label digit_6 mean precision:0.997 n=389\n",
      "2020-05-22 17:01:49,027 - plots:1645 - INFO - prAUC Label digit_7 mean precision:0.988 n=416\n",
      "2020-05-22 17:01:49,033 - plots:1645 - INFO - prAUC Label digit_8 mean precision:0.985 n=407\n",
      "2020-05-22 17:01:49,039 - plots:1645 - INFO - prAUC Label digit_9 mean precision:0.991 n=392\n",
      "2020-05-22 17:01:49,333 - plots:1660 - INFO - Saved Precision Recall curve at: ./runs/learn_mnist/precision_recall_mnist_label.png\n",
      "2020-05-22 17:01:49,605 - plots:326 - INFO - Try to save calibrations plot at: ./runs/learn_mnist/calibrations_mnist_label.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 17:01:50,043 - plots:1500 - INFO - ROC Label digit_0 area: 1.000 n=381 Truth shape (4096, 10), true sums [381. 478. 441. 415. 394. 383. 389. 416. 407. 392.]\n",
      "2020-05-22 17:01:50,045 - plots:1500 - INFO - ROC Label digit_1 area: 0.999 n=478 Truth shape (4096, 10), true sums [381. 478. 441. 415. 394. 383. 389. 416. 407. 392.]\n",
      "2020-05-22 17:01:50,048 - plots:1500 - INFO - ROC Label digit_2 area: 0.998 n=441 Truth shape (4096, 10), true sums [381. 478. 441. 415. 394. 383. 389. 416. 407. 392.]\n",
      "2020-05-22 17:01:50,052 - plots:1500 - INFO - ROC Label digit_3 area: 0.998 n=415 Truth shape (4096, 10), true sums [381. 478. 441. 415. 394. 383. 389. 416. 407. 392.]\n",
      "2020-05-22 17:01:50,055 - plots:1500 - INFO - ROC Label digit_4 area: 0.999 n=394 Truth shape (4096, 10), true sums [381. 478. 441. 415. 394. 383. 389. 416. 407. 392.]\n",
      "2020-05-22 17:01:50,058 - plots:1500 - INFO - ROC Label digit_5 area: 0.999 n=383 Truth shape (4096, 10), true sums [381. 478. 441. 415. 394. 383. 389. 416. 407. 392.]\n",
      "2020-05-22 17:01:50,061 - plots:1500 - INFO - ROC Label digit_6 area: 1.000 n=389 Truth shape (4096, 10), true sums [381. 478. 441. 415. 394. 383. 389. 416. 407. 392.]\n",
      "2020-05-22 17:01:50,064 - plots:1500 - INFO - ROC Label digit_7 area: 0.999 n=416 Truth shape (4096, 10), true sums [381. 478. 441. 415. 394. 383. 389. 416. 407. 392.]\n",
      "2020-05-22 17:01:50,067 - plots:1500 - INFO - ROC Label digit_8 area: 0.998 n=407 Truth shape (4096, 10), true sums [381. 478. 441. 415. 394. 383. 389. 416. 407. 392.]\n",
      "2020-05-22 17:01:50,069 - plots:1500 - INFO - ROC Label digit_9 area: 0.999 n=392 Truth shape (4096, 10), true sums [381. 478. 441. 415. 394. 383. 389. 416. 407. 392.]\n",
      "2020-05-22 17:01:50,495 - plots:1515 - INFO - Saved ROC curve at: ./runs/learn_mnist/per_class_roc_mnist_label.png\n",
      "2020-05-22 17:02:45,114 - plots:1786 - INFO - Saved T-SNE plot at: ./runs/learn_mnist/tsne_plot.png\n",
      "2020-05-22 17:02:45,116 - tensor_generators:226 - INFO - Stopped 4 workers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'digit_0': 0.9997965261071841,\n",
       " 'digit_1': 0.9988117293587849,\n",
       " 'digit_2': 0.9981170762878795,\n",
       " 'digit_3': 0.9980099697895085,\n",
       " 'digit_4': 0.999308920682194,\n",
       " 'digit_5': 0.9985816540431298,\n",
       " 'digit_6': 0.999658119183952,\n",
       " 'digit_7': 0.998583821070234,\n",
       " 'digit_8': 0.998107795071742,\n",
       " 'digit_9': 0.9987630581390223}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'mnist_image',\n",
    "            '--output_tensors', 'mnist_label',\n",
    "            '--batch_size', '64',\n",
    "            '--test_steps', '64',\n",
    "            '--epochs', '24',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'learn_mnist'\n",
    "           ]\n",
    "args = parse_args()\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating ML Models in ML4CVD\n",
    "Each ML4CVD training run creates several plots to give insight into model performance and learning dynamics.  The plots created will depend on the TensorMaps used but in general will include a metric history showing learning curves of each metric tracked during training, performance plots like ROC and Precision Recall curves for classifiers or scatter plots for regressors, calibration plots, and a t-SNE plot showing a 2D representation of the learned embedding of the trained model.\n",
    "![./runs/learn_mnist/calibrations_mnist_label.png](./runs/learn_mnist/metric_history_learn_mnist.png)\n",
    "![./runs/learn_mnist/calibrations_mnist_label.png](./runs/learn_mnist/precision_recall_mnist_label.png)\n",
    "![./runs/learn_mnist/calibrations_mnist_label.png](./runs/learn_mnist/per_class_roc_mnist_label.png)\n",
    "![./runs/learn_mnist/calibrations_mnist_label.png](./runs/learn_mnist/calibrations_mnist_label.png)\n",
    "![./runs/learn_mnist/calibrations_mnist_label.png](./runs/learn_mnist/tsne_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_label_as_time_to_event(tm, hd5, dependents={}):\n",
    "    tensor = np.zeros(tm.shape, dtype=np.float32)\n",
    "    label = float(hd5['mnist_label'][0])\n",
    "    tensor[0] = 1.0 if np.random.rand() > (label / 10) else 0.0\n",
    "    tensor[1] = np.random.randint(1, 3650)\n",
    "    return tensor\n",
    "    \n",
    "TMAPS['mnist_time_to_event'] = TensorMap('mnist_time_to_event', Interpretation.TIME_TO_EVENT, \n",
    "                                         tensor_from_file=mnist_label_as_time_to_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 19:58:32,299 - logger:25 - INFO - Logging configuration was loaded. Log messages can be found at ./runs/mnist_time_to_event/log_2020-05-22_19-58_0.log.\n",
      "2020-05-22 19:58:32,301 - arguments:372 - INFO - Command Line was: \n",
      "./scripts/tf.sh train --tensors ./mnist_hd5s/ --input_tensors mnist_image --output_tensors mnist_time_to_event --training_steps 64 --validation_steps 24 --test_steps 30 --batch_size 32 --epochs 1 --eager --output_folder ./runs/ --id mnist_time_to_event\n",
      "\n",
      "2020-05-22 19:58:32,302 - arguments:373 - INFO - Total TensorMaps: 559 Arguments are Namespace(activation='relu', aligned_dimension=16, alpha=0.5, anneal_max=2.0, anneal_rate=0.0, anneal_shift=0.0, app_csv=None, b_slice_force=None, balance_csvs=[], batch_size=32, bigquery_credentials_file='/mnt/ml4cvd/projects/jamesp/bigquery/bigquery-viewer-credentials.json', bigquery_dataset='broad-ml4cvd.ukbb7089_r10data', block_size=3, bottleneck_type=<BottleneckType.FlattenRestructure: 1>, cache_size=875000000.0, categorical_field_ids=[], continuous_field_ids=[], continuous_file=None, continuous_file_column=None, continuous_file_discretization_bounds=[], continuous_file_normalize=False, conv_dilate=False, conv_dropout=0.0, conv_layers=[32], conv_normalize=None, conv_regularize=None, conv_type='conv', conv_x=3, conv_y=3, conv_z=2, debug=False, dense_blocks=[32, 24, 16], dense_layers=[16, 64], dicom_series='cine_segmented_sax_b6', dicoms='./dicoms/', dropout=0.0, eager=True, epochs=1, freeze_model_layers=False, hidden_layer='embed', id='mnist_time_to_event', imputation_method_for_continuous_fields='random', include_array=False, include_instance=False, include_missing_continuous_channel=False, input_tensors=['mnist_image'], inspect_model=False, inspect_show_labels=True, join_tensors=['partners_ecg_patientid_clean'], label_weights=None, language_layer='ecg_rest_text', language_prefix=None, learning_rate=0.0002, learning_rate_schedule=None, logging_level='INFO', max_models=16, max_parameters=9000000, max_patients=999999, max_pools=[], max_sample_id=7000000, max_samples=None, max_slices=999999, min_sample_id=0, min_samples=3, min_values=10, mixup_alpha=0, mlp_concat=False, mode='mlp', model_file=None, model_files=[], model_layers=None, mri_field_ids=['20208', '20209'], num_workers=4, optimizer='radam', output_folder='./runs/', output_tensors=['mnist_time_to_event'], padding='same', patience=8, phecode_definitions='/mnt/ml4cvd/projects/jamesp/data/phecode_definitions1.2.csv', phenos_folder='gs://ml4cvd/phenotypes/', plot_mode='clinical', pool_type='max', pool_x=2, pool_y=2, pool_z=1, random_seed=12878, reference_end_time_tensor=None, reference_join_tensors=None, reference_label=None, reference_name='Reference', reference_start_time_tensor=None, reference_tensors=None, res_layers=[], sample_csv=None, sample_weight=None, t=48, tensor_maps_in=[TensorMap(mnist_image, (28, 28, 1), continuous)], tensor_maps_out=[TensorMap(mnist_time_to_event, (2,), time_to_event)], tensors='./mnist_hd5s/', tensors_name='Tensors', test_csv=None, test_ratio=0.1, test_steps=30, time_tensor='partners_ecg_datetime', train_csv=None, training_steps=64, tsv_style='standard', u_connect=defaultdict(<class 'set'>, {}), valid_csv=None, valid_ratio=0.2, validation_steps=24, write_pngs=False, x=256, xml_field_ids=['20205', '6025'], xml_folder='/mnt/disks/ecg-rest-xml/', y=256, z=48, zip_folder='/mnt/disks/sax-mri-zip/', zoom_height=96, zoom_width=96, zoom_x=50, zoom_y=35)\n",
      "2020-05-22 19:58:35,494 - tensor_generators:622 - INFO - Found 34927 train, 10085 validation, and 4988 testing tensors at: ./mnist_hd5s/\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_mnist_image_continuous (I [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 32)   320         input_mnist_image_continuous[0][0\n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 28, 28, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 14, 14, 32)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 32)   9248        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 14, 14, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 14, 14, 64)   0           max_pooling2d[0][0]              \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 32)   18464       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 14, 14, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 14, 14, 96)   0           max_pooling2d[0][0]              \n",
      "                                                                 activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 32)   27680       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 14, 14, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 32)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 24)     6936        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 7, 7, 24)     0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 7, 7, 56)     0           max_pooling2d_1[0][0]            \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 7, 7, 24)     12120       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 7, 7, 24)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 7, 7, 80)     0           max_pooling2d_1[0][0]            \n",
      "                                                                 activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 24)     17304       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 24)     0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 24)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 3, 3, 16)     3472        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 3, 3, 16)     0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 40)     0           max_pooling2d_2[0][0]            \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 3, 3, 16)     5776        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 3, 3, 16)     0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 56)     0           max_pooling2d_2[0][0]            \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 3, 3, 16)     8080        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 3, 3, 16)     0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 144)          0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           2320        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embed (Dense)                   (None, 64)           1088        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64)           0           embed[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_mnist_time_to_event_time (None, 2)            130         activation_11[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 112,938\n",
      "Trainable params: 112,938\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 19:58:35,954 - tensor_generators:149 - INFO - Started 3 train workers with cache size 0.875GB.\n",
      "2020-05-22 19:58:36,245 - tensor_generators:149 - INFO - Started 1 validation workers with cache size 0.875GB.\n",
      "Train for 64 steps, validate for 24 steps\n",
      "63/64 [============================>.] - ETA: 0s - loss: 1.4123\n",
      "Epoch 00001: val_loss improved from inf to 1.38372, saving model to ./runs/mnist_time_to_event/mnist_time_to_event.h5\n",
      "64/64 [==============================] - 14s 218ms/step - loss: 1.4114 - val_loss: 1.3837\n",
      "2020-05-22 19:58:50,438 - tensor_generators:226 - INFO - Stopped 4 workers.\n",
      "2020-05-22 19:58:50,444 - tensor_generators:226 - INFO - Stopped 2 workers.\n",
      "2020-05-22 19:58:50,445 - models:1092 - INFO - Model weights saved at: ./runs/mnist_time_to_event/mnist_time_to_event.h5\n",
      "2020-05-22 19:58:51,356 - plots:203 - INFO - Saved learning curves at:./runs/mnist_time_to_event/metric_history_mnist_time_to_event.png\n",
      "2020-05-22 19:58:51,530 - tensor_generators:149 - INFO - Started 3 test workers with cache size 0.0GB.\n",
      "2020-05-22 19:58:51,941 - tensor_generators:492 - INFO - Made a big batch of tensors with key:input_mnist_image_continuous and shape:(960, 28, 28, 1).\n",
      "2020-05-22 19:58:51,943 - tensor_generators:492 - INFO - Made a big batch of tensors with key:output_mnist_time_to_event_time_to_event and shape:(960, 2).\n",
      "2020-05-22 19:58:53,032 - plots:137 - INFO - ['C-Index: 0.56', 'Concordant Pairs: 139355.00', 'Discordant Pairs: 110389.00', 'Tied Predicted Risk: 0.00', 'Tied Event Time: 425.00']\n",
      "2020-05-22 19:58:53,061 - plots:1504 - INFO - ROC Label mnist_time_to_event_C_Index_0.56_vs_ROC area: 0.670 n=519 Truth shape (960, 1), true sums [519.]\n",
      "2020-05-22 19:58:53,378 - plots:1519 - INFO - Saved ROC curve at: ./runs/mnist_time_to_event/per_class_roc_mnist_time_to_event_C_Index_0.56.png\n",
      "2020-05-22 19:58:53,379 - plots:140 - INFO - ytru (960, 2) ypred (960, 2)\n",
      "2020-05-22 19:58:53,430 - plots:227 - INFO - Try to save calibration plot at: ./runs/mnist_time_to_event/calibration_mnist_time_to_event.png\n",
      "2020-05-22 19:58:53,751 - plots:500 - INFO - First day 9.0 Last day, day 1859.0, censored 214.0\n",
      "2020-05-22 19:58:53,788 - plots:529 - INFO - Try to save survival plot at: ./runs/mnist_time_to_event/survivorship_fu_1825_mnist_time_to_event.png\n",
      "2020-05-22 19:59:07,278 - plots:1790 - INFO - Saved T-SNE plot at: ./runs/mnist_time_to_event/tsne_plot.png\n",
      "2020-05-22 19:59:07,279 - tensor_generators:226 - INFO - Stopped 4 workers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mnist_time_to_event_C_Index_0.56_vs_ROC': 0.6698211718855814}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'mnist_image',\n",
    "            '--output_tensors', 'mnist_time_to_event',\n",
    "            '--training_steps', '64',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '30',\n",
    "            '--batch_size', '32',\n",
    "            '--epochs', '1',\n",
    "            '--eager',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'mnist_time_to_event'\n",
    "           ]\n",
    "args = parse_args()\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![./runs/mnist_time_to_event/survivorship_fu_1825_mnist_time_to_event.png](./runs/mnist_time_to_event/survivorship_fu_1825_mnist_time_to_event.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_invert_label_as_time_to_event(tm, hd5, dependents={}):\n",
    "    tensor = np.zeros(tm.shape, dtype=np.float32)\n",
    "    label = float(hd5['mnist_label'][0])\n",
    "    if label > 6:\n",
    "        tensor[0] = 1.0 if np.random.rand() > 0.95 else 0.0\n",
    "    elif label > 3:\n",
    "        tensor[0] = 1.0 if np.random.rand() > 0.5 else 0.0\n",
    "    elif label > 1:\n",
    "        tensor[0] = 1.0 if np.random.rand() > 0.1 else 0.0    \n",
    "    else:\n",
    "        tensor[0] = 1.0 if np.random.rand() > 0.01 else 0.0\n",
    "    tensor[1] = 1+label* np.random.randint(1, 365)\n",
    "    return tensor\n",
    "    \n",
    "TMAPS['mnist_time_to_event_invert'] = TensorMap('mnist_time_to_event_invert', Interpretation.TIME_TO_EVENT, \n",
    "                                         tensor_from_file=mnist_invert_label_as_time_to_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'mnist_image',\n",
    "            '--output_tensors', 'mnist_time_to_event_invert',\n",
    "            '--training_steps', '64',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '32',\n",
    "            '--batch_size', '64',\n",
    "            '--epochs', '32',\n",
    "            '--eager',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'mnist_time_to_event_invert'\n",
    "           ]\n",
    "args = parse_args()\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_oscillate_label_as_time_to_event(tm, hd5, dependents={}):\n",
    "    tensor = np.zeros(tm.shape, dtype=np.float32)\n",
    "    label = float(hd5['mnist_label'][0])\n",
    "    if label % 2 == 0:\n",
    "        tensor[0] = 1.0 if np.random.rand() > 0.98 else 0.0\n",
    "        tensor[1] = 1+label* np.random.randint(1, 3650)\n",
    "    else:\n",
    "        tensor[0] = 1.0 if np.random.rand() > 0.02 else 0.0\n",
    "        tensor[1] = 1+label* np.random.randint(1, 365)\n",
    "    return tensor\n",
    "    \n",
    "TMAPS['mnist_oscillate_label_as_time_to_event'] = TensorMap('mnist_oscillate_label_as_time_to_event', Interpretation.TIME_TO_EVENT, \n",
    "                                         tensor_from_file=mnist_oscillate_label_as_time_to_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'mnist_image',\n",
    "            '--output_tensors', 'mnist_oscillate_label_as_time_to_event',\n",
    "            '--training_steps', '64',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '32',\n",
    "            '--batch_size', '64',\n",
    "            '--epochs', '28',\n",
    "            '--eager',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'mnist_oscillate_label_as_time_to_event'\n",
    "           ]\n",
    "args = parse_args()\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
