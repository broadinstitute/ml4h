{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model MNIST with ML4Health, and then use MNIST for Synthetic Survival Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "from typing import List, Dict, Callable\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import csv\n",
    "import gzip\n",
    "import h5py\n",
    "import shutil\n",
    "import zipfile\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "from ml4h.defines import StorageType\n",
    "from ml4h.arguments import parse_args\n",
    "from ml4h.TensorMap import TensorMap, Interpretation\n",
    "from ml4h.tensor_generators import test_train_valid_tensor_generators\n",
    "from ml4h.models import train_model_from_generators, make_multimodal_multitask_model, _inspect_model\n",
    "from ml4h.recipes import test_multimodal_multitask, train_multimodal_multitask, saliency_maps\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "HD5_FOLDER = './mnist_hd5s/'\n",
    "OUTPUT_FOLDER = './runs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    ''' Loads the dataset\n",
    "    :param dataset: the path to the dataset (here MNIST)'''\n",
    "    data_dir, data_file = os.path.split(dataset)\n",
    "    if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "        # Check if dataset is in the data directory.\n",
    "        new_path = os.path.join(\"data\", dataset)\n",
    "        if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "            dataset = new_path\n",
    "\n",
    "    if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "        from urllib.request import urlretrieve\n",
    "        origin = ('http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz')\n",
    "        print('Downloading data from %s' % origin)\n",
    "        if not os.path.exists(os.path.dirname(dataset)):\n",
    "            os.makedirs(os.path.dirname(dataset))\t\n",
    "        urlretrieve(origin, dataset)\n",
    "\n",
    "    print('loading data...')\n",
    "    f = gzip.open(dataset, 'rb')\n",
    "    if sys.version_info[0] == 3:\n",
    "        u = pickle._Unpickler(f)\n",
    "        u.encoding = 'latin1'\n",
    "        train_set, valid_set, test_set = u.load()\n",
    "    else:\n",
    "        train_set, valid_set, test_set = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist(sides):\n",
    "    train, _, _ = load_data('mnist.pkl.gz')\n",
    "    print(train[0].shape)\n",
    "    mnist_images = train[0].reshape((-1, 28, 28, 1))\n",
    "    sides = int(np.ceil(np.sqrt(min(sides, mnist_images.shape[0]))))\n",
    "    _, axes = plt.subplots(sides, sides, figsize=(16, 16))\n",
    "    for i in range(sides*sides):\n",
    "        axes[i // sides, i % sides].imshow(mnist_images[i, ..., 0], cmap='gray')\n",
    "        axes[i // sides, i % sides].set_xticks(())\n",
    "        axes[i // sides, i % sides].set_yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mnist(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mnist(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorization\n",
    "It is often helpful to separate data preparation from model training.  In ml4h we call the final data preparation process tensorization.  Tensorization involves gathering all input files (XMLS, CSVs, DICOMs, PNGs, etc) and consolidating them into compressed HD5 files.  We tend to make one HD5 file per individual in the cohort we are studying.  The files contain the raw data and labels (inputs and outputs) we will use to train models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_as_hd5(hd5_folder):\n",
    "    train, _, _ = load_data('mnist.pkl.gz')\n",
    "    mnist_images = train[0].reshape((-1, 28, 28, 1))\n",
    "    if not os.path.exists(hd5_folder):\n",
    "        os.makedirs(hd5_folder)\n",
    "    for i, mnist_image in enumerate(mnist_images):\n",
    "        with h5py.File(os.path.join(hd5_folder, f'{i}.hd5'), 'w') as hd5:\n",
    "            hd5.create_dataset('mnist_image', data=mnist_image)\n",
    "            hd5.create_dataset('mnist_label', data=[train[1][i]])\n",
    "        if (i+1) % 5000 == 0:\n",
    "            print(f'Wrote {i+1} MNIST images and labels as HD5 files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "Wrote 5000 MNIST images and labels as HD5 files\n",
      "Wrote 10000 MNIST images and labels as HD5 files\n",
      "Wrote 15000 MNIST images and labels as HD5 files\n",
      "Wrote 20000 MNIST images and labels as HD5 files\n",
      "Wrote 25000 MNIST images and labels as HD5 files\n",
      "Wrote 30000 MNIST images and labels as HD5 files\n",
      "Wrote 35000 MNIST images and labels as HD5 files\n",
      "Wrote 40000 MNIST images and labels as HD5 files\n",
      "Wrote 45000 MNIST images and labels as HD5 files\n",
      "Wrote 50000 MNIST images and labels as HD5 files\n"
     ]
    }
   ],
   "source": [
    "mnist_as_hd5(HD5_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorMaps\n",
    "The central data structure in the ml4h codebase is the TensorMap.\n",
    "This abstraction provides a way to translate ***any*** kind of input data, into structured numeric tensors with clear semantics for interpretation and modeling.  TensorMaps guarantee a shape, a way to construct tensors of that shape from the HD5 files created during tensorization and a meaning to the values in the tensor that the TensorMap yields.  The most important method of each TensorMap is their ***tensor_from_file*** function.  This callback function takes the TensorMap, an HD5 file handle, and an optional dictionary as input arguments and it returns a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_image_from_hd5(tm, hd5, dependents={}):\n",
    "     return np.array(hd5['mnist_image'])\n",
    "\n",
    "def mnist_label_from_hd5(tm, hd5, dependents={}):\n",
    "    one_hot = np.zeros(tm.shape, dtype=np.float32)\n",
    "    one_hot[int(hd5['mnist_label'][0])] = 1.0\n",
    "    return one_hot\n",
    "    \n",
    "TMAPS['mnist_image'] = TensorMap('mnist_image', shape=(28, 28, 1), tensor_from_file=mnist_image_from_hd5)\n",
    "TMAPS['mnist_label'] = TensorMap('mnist_label', Interpretation.CATEGORICAL, tensor_from_file=mnist_label_from_hd5,\n",
    "                                 channel_map={f'digit_{i}': i for i in range(10)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line Friendly Jupyter Notebooks\n",
    "By directly setting the `sys.argv` array in our jupyter notebooks we make the process of translating from notebook to command line straightforward.  For example, the cell below can be replicated on the command line by running:\n",
    "```\n",
    "./scripts/tf.sh $HOME/ml/ml4h/recipes.py --mode train --tensors ./mnist_hd5s/ \\\n",
    "    --input_tensors mnist_image --output_tensors mnist_label \\\n",
    "    --batch_size 64 --test_steps 64 --epochs 24 \\\n",
    "    --output_folder ./runs/ --id learn_mnist\n",
    "```\n",
    "The script `tf.sh` starts the appropriate docker container and then calls python on the provided arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-18 16:17:13,404 - logger:25 - INFO - Logging configuration was loaded. Log messages can be found at ./runs/learn_mnist/log_2020-09-18_16-17_0.log.\n",
      "2020-09-18 16:17:13,410 - arguments:444 - INFO - Command Line was: \n",
      "./scripts/tf.sh train --tensors ./mnist_hd5s/ --tensormap_prefix ml4h.tensormap.mnist --input_tensors mnist_image --output_tensors mnist_label --batch_size 64 --test_steps 64 --epochs 24 --output_folder ./runs/ --id learn_mnist\n",
      "\n",
      "2020-09-18 16:17:13,410 - arguments:445 - INFO - Arguments are Namespace(activation='relu', aligned_dimension=16, alpha=0.5, anneal_max=2.0, anneal_rate=0.0, anneal_shift=0.0, app_csv=None, b_slice_force=None, balance_csvs=[], batch_size=64, bigquery_credentials_file='/mnt/ml4cvd/projects/jamesp/bigquery/bigquery-viewer-credentials.json', bigquery_dataset='broad-ml4cvd.ukbb7089_r10data', block_size=3, bottleneck_type=<BottleneckType.FlattenRestructure: 1>, cache_size=437500000.0, categorical_field_ids=[], continuous_field_ids=[], continuous_file=None, continuous_file_column=None, continuous_file_discretization_bounds=[], continuous_file_normalize=False, conv_dilate=False, conv_layers=[32], conv_normalize=None, conv_regularize=None, conv_regularize_rate=0.0, conv_type='conv', conv_x=[3], conv_y=[3], conv_z=[2], debug=False, dense_blocks=[32, 24, 16], dense_layers=[16, 64], dense_normalize=None, dense_regularize=None, dense_regularize_rate=0.0, dicom_series='cine_segmented_sax_b6', dicoms='./dicoms/', eager=False, embed_visualization=None, epochs=24, explore_export_errors=False, freeze_model_layers=False, hidden_layer='embed', id='learn_mnist', imputation_method_for_continuous_fields='random', include_array=False, include_instance=False, include_missing_continuous_channel=False, input_tensors=['mnist_image'], inspect_model=False, inspect_show_labels=True, join_tensors=['partners_ecg_patientid_clean'], label_weights=None, language_layer='ecg_rest_text', language_prefix='ukb_ecg_rest', learning_rate=0.0002, learning_rate_schedule=None, logging_level='INFO', match_any_window=False, max_models=16, max_parameters=9000000, max_patients=999999, max_pools=[], max_sample_id=7000000, max_samples=None, max_slices=999999, min_sample_id=0, min_samples=3, min_values=10, mixup_alpha=0, mlp_concat=False, mode='mlp', model_file=None, model_files=[], model_layers=None, mri_field_ids=['20208', '20209'], num_workers=8, number_per_window=1, optimizer='radam', order_in_window=None, output_folder='./runs/', output_tensors=['mnist_label'], padding='same', patience=8, phecode_definitions='/mnt/ml4cvd/projects/jamesp/data/phecode_definitions1.2.csv', phenos_folder='gs://ml4cvd/phenotypes/', plot_hist=True, plot_mode='clinical', pool_type='max', pool_x=2, pool_y=2, pool_z=1, protected_tensors=[], random_seed=12878, reference_end_time_tensor=None, reference_join_tensors=None, reference_labels=None, reference_name='Reference', reference_start_time_tensor=None, reference_tensors=None, sample_csv=None, sample_weight=None, save_last_model=False, t=48, tensor_maps_in=[TensorMap(mnist_image, (28, 28, 1), continuous)], tensor_maps_out=[TensorMap(mnist_label, (10,), categorical)], tensor_maps_protected=[], tensormap_prefix='ml4h.tensormap.mnist', tensors='./mnist_hd5s/', tensors_name='Tensors', tensors_source=None, test_csv=None, test_ratio=0.1, test_steps=64, text_file=None, text_one_hot=False, text_window=32, time_frequency='3M', time_tensor='partners_ecg_datetime', train_csv=None, training_steps=72, tsv_style='standard', u_connect=defaultdict(<class 'set'>, {}), valid_csv=None, valid_ratio=0.2, validation_steps=18, window_name=None, write_pngs=False, x=256, xml_field_ids=['20205', '6025'], xml_folder='/mnt/disks/ecg-rest-xml/', y=256, z=48, zip_folder='/mnt/disks/sax-mri-zip/', zoom_height=96, zoom_width=96, zoom_x=50, zoom_y=35)\n",
      "\n",
      "2020-09-18 16:17:13,411 - tensor_generators:661 - INFO - Found 0 train, 0 validation, and 0 testing tensors at: ./mnist_hd5s/\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough tensors at ./mnist_hd5s/\nFound 0 training, 0 validation, and 0 testing tensors\nDiscarded 0 tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-abf58ce71cae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m            ]\n\u001b[1;32m     13\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_multimodal_multitask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sam/ml/ml4h/recipes.py\u001b[0m in \u001b[0;36mtrain_multimodal_multitask\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_multimodal_multitask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mgenerate_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_train_valid_tensor_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_multimodal_multitask_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     model = train_model_from_generators(\n",
      "\u001b[0;32m/home/sam/ml/ml4h/tensor_generators.py\u001b[0m in \u001b[0;36mtest_train_valid_tensor_generators\u001b[0;34m(tensor_maps_in, tensor_maps_out, tensor_maps_protected, tensors, batch_size, num_workers, training_steps, validation_steps, cache_size, balance_csvs, keep_paths, keep_paths_test, mixup_alpha, sample_csv, valid_ratio, test_ratio, train_csv, valid_csv, test_csv, siamese, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0mtrain_csv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mvalid_csv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m             \u001b[0mtest_csv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m         )\n\u001b[1;32m    800\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/ml/ml4h/tensor_generators.py\u001b[0m in \u001b[0;36mget_train_valid_test_paths\u001b[0;34m(tensors, sample_csv, valid_ratio, test_ratio, train_csv, valid_csv, test_csv)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_paths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_paths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_paths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         raise ValueError(\n\u001b[0;32m--> 665\u001b[0;31m             \u001b[0;34mf'Not enough tensors at {tensors}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m             \u001b[0;34mf'Found {len(train_paths)} training, {len(valid_paths)} validation, and {len(test_paths)} testing tensors\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;34mf'Discarded {len(discard_paths)} tensors'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Not enough tensors at ./mnist_hd5s/\nFound 0 training, 0 validation, and 0 testing tensors\nDiscarded 0 tensors"
     ]
    }
   ],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--tensormap_prefix', 'ml4h.tensormap.mnist',\n",
    "            '--input_tensors', 'mnist_image',\n",
    "            '--output_tensors', 'mnist_label',\n",
    "            '--batch_size', '64',\n",
    "            '--test_steps', '64',\n",
    "            '--epochs', '24',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'learn_mnist'\n",
    "           ]\n",
    "args = parse_args()\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating ML Models in ml4h\n",
    "Each ml4h training run creates several plots to give insight into model performance and learning dynamics.  The plots created will depend on the TensorMaps used but in general will include a metric history showing learning curves of each metric tracked during training, performance plots like ROC and Precision Recall curves for classifiers or scatter plots for regressors, calibration plots, and a t-SNE plot showing a 2D representation of the learned embedding of the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival Analysis\n",
    "In addition to categorical classification tasks shown above, the ML4Health code base supports survival analysis.  In survival analysis, we consider the relative time before an outcome was observed, and we allow for samples to leave our study at anytime, before having an event.  Survival analysis is implemented via the TensorMap interpretations TIME_TO_EVENT and SURVIVAL_CURVE. \n",
    "\n",
    "The TIME_TO_EVENT interpretation is the most straight forward.  TIME_TO_EVENT TensorMaps *tensor_from_file* function returns an array with two values.  The first value indicates whether or not an event occurred for this sample.  The second value indicates the total days of follow up from when the sample enrolled in the study until either an event ocurred or they left the study.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_label_as_time_to_event(tm, hd5, dependents={}):\n",
    "    tensor = np.zeros(tm.shape, dtype=np.float32)\n",
    "    label = float(hd5['mnist_label'][0])\n",
    "    tensor[0] = 1.0 if np.random.rand() > (label / 10) else 0.0\n",
    "    tensor[1] = np.random.randint(1, 3650)\n",
    "    return tensor\n",
    "    \n",
    "TMAPS['mnist_time_to_event'] = TensorMap('mnist_time_to_event', Interpretation.TIME_TO_EVENT, \n",
    "                                         tensor_from_file=mnist_label_as_time_to_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'mnist_image',\n",
    "            '--output_tensors', 'mnist_time_to_event',\n",
    "            '--training_steps', '64',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '30',\n",
    "            '--batch_size', '32',\n",
    "            '--epochs', '1',\n",
    "            '--eager',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'mnist_time_to_event'\n",
    "           ]\n",
    "args = parse_args()\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_invert_label_as_time_to_event(tm, hd5, dependents={}):\n",
    "    tensor = np.zeros(tm.shape, dtype=np.float32)\n",
    "    label = float(hd5['mnist_label'][0])\n",
    "    if label > 6:\n",
    "        tensor[0] = 1.0 if np.random.rand() > 0.95 else 0.0\n",
    "    elif label > 3:\n",
    "        tensor[0] = 1.0 if np.random.rand() > 0.5 else 0.0\n",
    "    elif label > 1:\n",
    "        tensor[0] = 1.0 if np.random.rand() > 0.1 else 0.0    \n",
    "    else:\n",
    "        tensor[0] = 1.0 if np.random.rand() > 0.01 else 0.0\n",
    "    tensor[1] = 1+label* np.random.randint(1, 365)\n",
    "    return tensor\n",
    "    \n",
    "TMAPS['mnist_time_to_event_invert'] = TensorMap('mnist_time_to_event_invert', Interpretation.TIME_TO_EVENT, \n",
    "                                         tensor_from_file=mnist_invert_label_as_time_to_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'mnist_image',\n",
    "            '--output_tensors', 'mnist_time_to_event_invert',\n",
    "            '--training_steps', '64',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '32',\n",
    "            '--batch_size', '64',\n",
    "            '--epochs', '32',\n",
    "            '--eager',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'mnist_time_to_event_invert'\n",
    "           ]\n",
    "args = parse_args()\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_oscillate_label_as_time_to_event(tm, hd5, dependents={}):\n",
    "    tensor = np.zeros(tm.shape, dtype=np.float32)\n",
    "    label = float(hd5['mnist_label'][0])\n",
    "    if label % 2 == 0:\n",
    "        tensor[0] = 1.0 if np.random.rand() > 0.98 else 0.0\n",
    "        tensor[1] = 1+label* np.random.randint(1, 3650)\n",
    "    else:\n",
    "        tensor[0] = 1.0 if np.random.rand() > 0.02 else 0.0\n",
    "        tensor[1] = 1+label* np.random.randint(1, 365)\n",
    "    return tensor\n",
    "    \n",
    "TMAPS['mnist_oscillate_label_as_time_to_event'] = TensorMap('mnist_oscillate_label_as_time_to_event', Interpretation.TIME_TO_EVENT, \n",
    "                                         tensor_from_file=mnist_oscillate_label_as_time_to_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'mnist_image',\n",
    "            '--output_tensors', 'mnist_oscillate_label_as_time_to_event',\n",
    "            '--training_steps', '64',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '32',\n",
    "            '--batch_size', '64',\n",
    "            '--epochs', '28',\n",
    "            '--eager',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'mnist_oscillate_label_as_time_to_event'\n",
    "           ]\n",
    "args = parse_args()\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model the Entire Survival Curve\n",
    "SURVIVAL_CURVE TensorMaps model the survival curve with quantized steps.  These TensorMaps **tensor_from_file** functions return an array of 1s and 0s. The first half of the array contains 1s for each time step that the sample survived and 0s elsewhere. The second half of the array contains a 1 at the time step at which an event occurred if there was one, otherwise it contains only zeros.  Here we use the MNIST dataset to create a synthetic survival analysis cohort.  We use the MNIST label to determine the likelihood of having events and we model several different shapes of survival curve and distributions of follow up.  The **days_window** and **shape** fields of these TensorMaps controls how quantized the predicted survival curves will be.  Specifically each time bin will cover **days_window** / (**shape[-1]**/2) days. **shape** should be an even number because half the array is used for indicating survival up until an event or censorship and the other half indicates events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_label_as_survival_curve(tm, hd5, dependents={}):\n",
    "    label = float(hd5['mnist_label'][0])\n",
    "    has_disease = 1.0 if np.random.rand() > (label / 10) else 0.0\n",
    "    days_follow_up = np.random.randint(1, 3650)\n",
    "        \n",
    "    intervals = int(tm.shape[0] / 2)\n",
    "    days_per_interval = tm.days_window / intervals\n",
    "    survival_then_censor = np.zeros(tm.shape, dtype=np.float32)\n",
    "    for i, day_delta in enumerate(np.arange(0, tm.days_window, days_per_interval)):\n",
    "        survival_then_censor[i] = float(day_delta < days_follow_up)\n",
    "        if day_delta <= days_follow_up < day_delta + days_per_interval:\n",
    "            survival_then_censor[intervals+i] = has_disease\n",
    "    return survival_then_censor\n",
    "    \n",
    "TMAPS['mnist_survival_curve'] = TensorMap('mnist_survival_curve', Interpretation.SURVIVAL_CURVE, shape=(50,),\n",
    "                                         tensor_from_file=mnist_label_as_survival_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'mnist_image',\n",
    "            '--output_tensors', 'mnist_survival_curve',\n",
    "            '--training_steps', '64',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '32',\n",
    "            '--batch_size', '64',\n",
    "            '--epochs', '16',\n",
    "            '--learning_rate', '0.02',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'mnist_label_as_survival_curve'\n",
    "           ]\n",
    "args = parse_args()\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_survival_curve_convex(tm, hd5, dependents={}):\n",
    "    label = float(hd5['mnist_label'][0])\n",
    "    has_disease = 1.0 if np.random.rand() > (label / 10) else 0.0\n",
    "    days_follow_up = np.random.randint(1, label*365)\n",
    "        \n",
    "    intervals = int(tm.shape[0] / 2)\n",
    "    days_per_interval = tm.days_window / intervals\n",
    "    survival_then_censor = np.zeros(tm.shape, dtype=np.float32)\n",
    "    for i, day_delta in enumerate(np.arange(0, tm.days_window, days_per_interval)):\n",
    "        survival_then_censor[i] = float(day_delta < days_follow_up)\n",
    "        if day_delta <= days_follow_up < day_delta + days_per_interval:\n",
    "            survival_then_censor[intervals+i] = has_disease\n",
    "    return survival_then_censor\n",
    "    \n",
    "TMAPS['mnist_survival_curve_convex'] = TensorMap('mnist_survival_curve_convex', Interpretation.SURVIVAL_CURVE, shape=(50,),\n",
    "                                         tensor_from_file=mnist_survival_curve_convex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'mnist_image',\n",
    "            '--output_tensors', 'mnist_survival_curve_convex',\n",
    "            '--training_steps', '64',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '32',\n",
    "            '--batch_size', '64',\n",
    "            '--epochs', '4',\n",
    "            '--learning_rate', '0.02',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'mnist_label_as_survival_curve_convex'\n",
    "           ]\n",
    "args = parse_args()\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_survival_curve_elbow(tm, hd5, dependents={}):\n",
    "    label = float(hd5['mnist_label'][0])\n",
    "    has_disease = 1.0 if np.random.rand() > (label / 20) else 0.0\n",
    "    days_follow_up = np.random.randint(1, 4650) if np.random.rand() > ((10-label) / 10) else np.random.randint(901, 2000)\n",
    "        \n",
    "    intervals = int(tm.shape[0] / 2)\n",
    "    days_per_interval = tm.days_window / intervals\n",
    "    survival_then_censor = np.zeros(tm.shape, dtype=np.float32)\n",
    "    for i, day_delta in enumerate(np.arange(0, tm.days_window, days_per_interval)):\n",
    "        survival_then_censor[i] = float(day_delta < days_follow_up)\n",
    "        if day_delta <= days_follow_up < day_delta + days_per_interval:\n",
    "            survival_then_censor[intervals+i] = has_disease\n",
    "    return survival_then_censor\n",
    "    \n",
    "TMAPS['mnist_survival_curve_elbow'] = TensorMap('mnist_survival_curve', Interpretation.SURVIVAL_CURVE, shape=(50,),\n",
    "                                         tensor_from_file=mnist_survival_curve_elbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'mnist_image',\n",
    "            '--output_tensors', 'mnist_survival_curve_elbow',\n",
    "            '--training_steps', '72',\n",
    "            '--validation_steps', '24',\n",
    "            '--test_steps', '36',\n",
    "            '--batch_size', '64',\n",
    "            '--epochs', '8',\n",
    "            '--learning_rate', '0.01',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'mnist_label_as_survival_curve_elbow'\n",
    "           ]\n",
    "args = parse_args()\n",
    "train_multimodal_multitask(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
