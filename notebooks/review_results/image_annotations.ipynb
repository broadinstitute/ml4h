{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image annotations for a batch of samples\n",
    "\n",
    "Using this notebook, cardiologists are able to quickly view and annotate MRI images for a batch of samples. These annotated images become the training data for the next round of modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    This notebook assumes you have already run notebook <kbd>../terra_featured_workspace/ml4h_setup.ipynb</kbd>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyannotations.images import BoxAnnotator, PointAnnotator, PolygonAnnotator\n",
    "from ml4h.visualization_tools.annotation_storage import BigQueryAnnotationStorage\n",
    "from ml4h.visualization_tools.batch_image_annotations import BatchImageAnnotator\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "// Display cell outputs to full height (no vertical scroll bar)\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_QUERY_ANNOTATIONS_STORAGE = BigQueryAnnotationStorage('uk-biobank-sek-data.ml_results.annotations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the batch of samples to annotate\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    Edit the CSV file path below, if needed, to either a local file or one in Cloud Storage.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---[ EDIT AND RUN THIS CELL TO READ FROM A LOCAL FILE OR A FILE IN CLOUD STORAGE ]---\n",
    "SAMPLE_BATCH_FILE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE_BATCH_FILE:\n",
    "  samples_df = pd.read_csv(tf.io.gfile.GFile(SAMPLE_BATCH_FILE))\n",
    "\n",
    "else:\n",
    "  # Normally these would all be the same or similar TMAP. We are using different ones here just to make it\n",
    "  # more obvious in this demo that we are processing different samples.\n",
    "  samples_df = pd.DataFrame(\n",
    "    columns=BatchImageAnnotator.EXPECTED_COLUMN_NAMES,\n",
    "      data=[\n",
    "          [1655349, 'cine_lax_3ch_192', 25,  'gs://ml4cvd/deflaux/ukbb_tensors/'],\n",
    "          [1655349, 'cine_lax_4ch_192', 25,  'gs://ml4cvd/deflaux/ukbb_tensors/'],\n",
    "          [2403657, 'cine_lax_3ch_192', 25,  'gs://ml4cvd/deflaux/ukbb_tensors/'],\n",
    "     ])\n",
    "\n",
    "samples_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df.head(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate the batch! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate with points\n",
    "\n",
    "Use points to annotate landmarks within the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: a zoom level of 1.0 displays the tensor as-is. For higher zoom levels, this code currently\n",
    "# use the PIL library to scale the image.\n",
    "\n",
    "annotator = BatchImageAnnotator(samples=samples_df,\n",
    "                                zoom=2.0,\n",
    "                                annotation_categories=['region_of_interest'],\n",
    "                                annotation_storage=BIG_QUERY_ANNOTATIONS_STORAGE,\n",
    "                                annotator=PointAnnotator)\n",
    "annotator.annotate_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate with polygons\n",
    "\n",
    "Use polygons to annotate arbitrarily shaped regions within the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: a zoom level of 1.0 displays the tensor as-is. For higher zoom levels, this code currently\n",
    "# use the PIL library to scale the image.\n",
    "\n",
    "annotator = BatchImageAnnotator(samples=samples_df,\n",
    "                                zoom=2.0,\n",
    "                                annotation_categories=['region_of_interest'],\n",
    "                                annotation_storage=BIG_QUERY_ANNOTATIONS_STORAGE,\n",
    "                                annotator=PolygonAnnotator)\n",
    "annotator.annotate_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate with rectangles\n",
    "\n",
    "Use rectangles to annotate rectangular regions within the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: a zoom level of 1.0 displays the tensor as-is. For higher zoom levels, this code currently\n",
    "# use the PIL library to scale the image.\n",
    "\n",
    "annotator = BatchImageAnnotator(samples=samples_df,\n",
    "                                zoom=2.0,\n",
    "                                annotation_categories=['region_of_interest'],\n",
    "                                annotation_storage=BIG_QUERY_ANNOTATIONS_STORAGE,\n",
    "                                annotator=BoxAnnotator)\n",
    "annotator.annotate_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the stored annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator.view_recent_submissions(count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip3 freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions about these particular notebooks? Join the discussion https://github.com/broadinstitute/ml4h/discussions."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-1.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "199px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
