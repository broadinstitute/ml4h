{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/apache_beam/__init__.py:84: UserWarning: Running the Apache Beam SDK on Python 3 is not yet fully supported. You may encounter buggy behavior or missing features.\n",
      "  'Running the Apache Beam SDK on Python 3 is not yet fully supported. '\n",
      "WARNING:root:no GCS storage client\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Keras imports\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# ML4CVD Imports\n",
    "from ml4cvd.arguments import parse_args\n",
    "from ml4cvd.models import make_multimodal_multitask_model, train_model_from_generators\n",
    "from ml4cvd.tensor_generators import TensorGenerator, big_batch_from_minibatch_generator, test_train_valid_tensor_generators\n",
    "\n",
    "# IPython imports\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients_from_output(args, model, output_layer, output_index):\n",
    "    K.set_learning_phase(1)\n",
    "    input_tensor = model.input\n",
    "    x = model.get_layer(output_layer).output[:,output_index]\n",
    "    grads = K.gradients(x, input_tensor)[0]\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-6) # normalization trick: we normalize the gradient\n",
    "    iterate = K.function([input_tensor], [x, grads])\n",
    "    return iterate\n",
    "\n",
    "def saliency_map(input_tensor, model, output_layer, output_index):\n",
    "    get_gradients = gradients_from_output(args, model, output_layer, output_index)\n",
    "    activation, grads = get_gradients([input_tensor])\n",
    "    print('Activation is:', activation, 'gradient shape:', grads.shape)\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 08:44:57,342 - logger:25 - INFO - Logging configuration was loaded. Log messages can be found at ./recipes_output/mri_slice_esv/log_2019-12-05_08-44_0.log.\n",
      "2019-12-05 08:44:57,343 - arguments:197 - INFO - Command Line was:\n",
      "\n",
      "./scripts/tf.sh train --tensors /mnt/disks/sax-lax-40k-lvm/2019-11-21/ --input_tensors t2_flair_brain_30_slices --output_tensors age_2 --batch_size 1 --epochs 2 --learning_rate 0.001 --training_steps 128 --validation_steps 10 --test_steps 1 --model_file /mnt/ml4cvd/projects/jamesp/data/models/mri_slice_esv.hd5 --id mri_slice_esv\n",
      "\n",
      "\n",
      "\n",
      "2019-12-05 08:44:57,344 - arguments:198 - INFO - Total TensorMaps:336 Arguments are Namespace(activation='relu', aligned_dimension=16, alpha=0.5, app_csv=None, b_slice_force=None, balance_csvs=[], batch_size=1, bigquery_credentials_file='/mnt/ml4cvd/projects/jamesp/bigquery/bigquery-viewer-credentials.json', bigquery_dataset='broad-ml4cvd.ukbb7089_r10data', block_size=3, cache_size=1000000000.0, categorical_field_ids=[], continuous_field_ids=[], conv_bn=False, conv_dilate=False, conv_dropout=0.0, conv_layers=[32], conv_normalize=None, conv_regularize=None, conv_type='conv', conv_width=71, conv_x=3, conv_y=3, conv_z=2, debug=False, dense_blocks=[32, 24, 16], dense_layers=[16, 64], dicoms='./dicoms/', dropout=0.0, epochs=2, freeze_model_layers=False, hidden_layer='embed', id='mri_slice_esv', imputation_method_for_continuous_fields='random', include_array=False, include_instance=False, include_missing_continuous_channel=False, input_continuous_tensors=[], input_tensors=['t2_flair_brain_30_slices'], inspect_model=False, inspect_show_labels=True, label_weights=None, learning_rate=0.001, logging_level='INFO', max_models=16, max_parameters=9000000, max_patients=999999, max_pools=[], max_sample_id=7000000, max_samples=None, max_slices=999999, min_sample_id=0, min_samples=3, min_values=10, mixup_alpha=0, mlp_concat=False, mode='mlp', model_file='/mnt/ml4cvd/projects/jamesp/data/models/mri_slice_esv.hd5', model_files=[], model_layers=None, mri_field_ids=['20208', '20209'], num_workers=4, optimizer='radam', output_folder='./recipes_output/', output_tensors=['age_2'], padding='same', patience=8, phecode_definitions='/mnt/ml4cvd/projects/jamesp/data/phecode_definitions1.2.csv', phenos_folder='gs://ml4cvd/phenotypes/', pool_type='max', pool_x=2, pool_y=2, pool_z=1, random_seed=12878, res_layers=[], t=48, tensor_maps_in=[<ml4cvd.TensorMap.TensorMap object at 0x7f50524e2dd8>], tensor_maps_out=[<ml4cvd.TensorMap.TensorMap object at 0x7f5052290ba8>], tensors='/mnt/disks/sax-lax-40k-lvm/2019-11-21/', test_csv=None, test_modulo=10, test_ratio=0.1, test_steps=1, training_steps=128, u_connect=False, valid_ratio=0.2, validation_steps=10, write_pngs=False, x=256, xml_field_ids=['20205', '6025'], xml_folder='/mnt/disks/ecg-rest-xml/', y=256, z=48, zip_folder='/mnt/disks/sax-mri-zip/', zoom_height=96, zoom_width=96, zoom_x=50, zoom_y=35)\n",
      "2019-12-05 08:44:59,021 - tensor_generators:426 - INFO - Found 24702 train, 6915 validation, and 7314 testing tensors at: /mnt/disks/sax-lax-40k-lvm/2019-11-21/\n",
      "2019-12-05 08:44:59,100 - models:352 - INFO - Attempting to load model file from: /mnt/ml4cvd/projects/jamesp/data/models/mri_slice_esv.hd5\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_mri_slice (InputLayer)    (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 320         input_mri_slice[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 32) 9248        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 128, 128, 32) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 32) 9248        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 64) 0           average_pooling2d_1[0][0]        \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 32) 18464       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 96) 0           average_pooling2d_1[0][0]        \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 24) 20760       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 64, 64, 24)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 24)   5208        average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 48)   0           average_pooling2d_2[0][0]        \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 24)   10392       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 72)   0           average_pooling2d_2[0][0]        \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 16)   10384       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 32, 32, 16)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 16)   2320        average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 32)   0           average_pooling2d_3[0][0]        \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 16)   4624        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 48)   0           average_pooling2d_3[0][0]        \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 49152)        0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           786448      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embed (Dense)                   (None, 64)           1088        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_end_systole_volume_conti (None, 1)            65          embed[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 878,569\n",
      "Trainable params: 878,569\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "2019-12-05 08:45:08,171 - models:355 - INFO - Loaded model file from: /mnt/ml4cvd/projects/jamesp/data/models/mri_slice_esv.hd5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 08:45:08,173 - tensor_generators:110 - INFO - Starting test_worker_0.\n",
      "2019-12-05 08:45:08,182 - tensor_generators:234 - INFO - test_worker_0 initialized cache of size 0.997 GB.\n",
      "2019-12-05 08:45:08,203 - tensor_generators:110 - INFO - Starting test_worker_1.\n",
      "2019-12-05 08:45:08,212 - tensor_generators:234 - INFO - test_worker_1 initialized cache of size 0.997 GB.\n",
      "2019-12-05 08:45:08,232 - tensor_generators:110 - INFO - Starting test_worker_2.\n",
      "2019-12-05 08:45:08,242 - tensor_generators:234 - INFO - test_worker_2 initialized cache of size 0.997 GB.\n",
      "2019-12-05 08:45:08,262 - tensor_generators:110 - INFO - Starting test_worker_3.\n",
      "2019-12-05 08:45:08,273 - tensor_generators:234 - INFO - test_worker_3 initialized cache of size 0.997 GB.\n",
      "2019-12-05 08:45:34,068 - tensor_generators:301 - INFO - Worker test_worker_1 - In true epoch 1:\n",
      "\tThe following errors occurred:\n",
      "\t\t[KeyError: \"Unable to open object (object 'ukb_brain_mri' doesn't exist)\"] - 939\n",
      "\t\t[KeyError: \"Unable to open object (object 'T2_FLAIR_brain' doesn't exist)\"] - 889\n",
      "\t\t[skipped_paths] - 2\n",
      "\tGenerator looped & shuffled over 1829 paths.\n",
      "\t0 tensors were presented.\n",
      "\tThe cache holds 0 out of a possible 3658 tensors and is 0% full.\n",
      "\tSo far there have been 0 cache hits.\n",
      "\t2 paths were skipped because they previously failed.\n",
      "\t25.86 seconds elapsed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process test_worker_1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ml4cvd/tensor_generators.py\", line 319, in multiprocessing_worker\n",
      "    self._on_epoch_end()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ml4cvd/tensor_generators.py\", line 303, in _on_epoch_end\n",
      "    raise ValueError(f\"Completed an epoch but did not find any tensors to yield\")\n",
      "ValueError: Completed an epoch but did not find any tensors to yield\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 08:45:34,242 - tensor_generators:301 - INFO - Worker test_worker_0 - In true epoch 1:\n",
      "\tThe following errors occurred:\n",
      "\t\t[KeyError: \"Unable to open object (object 'ukb_brain_mri' doesn't exist)\"] - 937\n",
      "\t\t[KeyError: \"Unable to open object (object 'T2_FLAIR_brain' doesn't exist)\"] - 891\n",
      "\t\t[skipped_paths] - 2\n",
      "\tGenerator looped & shuffled over 1829 paths.\n",
      "\t0 tensors were presented.\n",
      "\tThe cache holds 0 out of a possible 3658 tensors and is 0% full.\n",
      "\tSo far there have been 0 cache hits.\n",
      "\t2 paths were skipped because they previously failed.\n",
      "\t26.07 seconds elapsed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process test_worker_0:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ml4cvd/tensor_generators.py\", line 319, in multiprocessing_worker\n",
      "    self._on_epoch_end()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ml4cvd/tensor_generators.py\", line 303, in _on_epoch_end\n",
      "    raise ValueError(f\"Completed an epoch but did not find any tensors to yield\")\n",
      "ValueError: Completed an epoch but did not find any tensors to yield\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 08:45:34,458 - tensor_generators:301 - INFO - Worker test_worker_3 - In true epoch 1:\n",
      "\tThe following errors occurred:\n",
      "\t\t[KeyError: \"Unable to open object (object 'T2_FLAIR_brain' doesn't exist)\"] - 916\n",
      "\t\t[KeyError: \"Unable to open object (object 'ukb_brain_mri' doesn't exist)\"] - 911\n",
      "\t\t[skipped_paths] - 2\n",
      "\tGenerator looped & shuffled over 1828 paths.\n",
      "\t0 tensors were presented.\n",
      "\tThe cache holds 0 out of a possible 3656 tensors and is 0% full.\n",
      "\tSo far there have been 0 cache hits.\n",
      "\t2 paths were skipped because they previously failed.\n",
      "\t26.19 seconds elapsed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process test_worker_3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ml4cvd/tensor_generators.py\", line 319, in multiprocessing_worker\n",
      "    self._on_epoch_end()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ml4cvd/tensor_generators.py\", line 303, in _on_epoch_end\n",
      "    raise ValueError(f\"Completed an epoch but did not find any tensors to yield\")\n",
      "ValueError: Completed an epoch but did not find any tensors to yield\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-05 08:45:34,639 - tensor_generators:301 - INFO - Worker test_worker_2 - In true epoch 1:\n",
      "\tThe following errors occurred:\n",
      "\t\t[KeyError: \"Unable to open object (object 'T2_FLAIR_brain' doesn't exist)\"] - 950\n",
      "\t\t[KeyError: \"Unable to open object (object 'ukb_brain_mri' doesn't exist)\"] - 877\n",
      "\t\t[skipped_paths] - 2\n",
      "\tGenerator looped & shuffled over 1828 paths.\n",
      "\t0 tensors were presented.\n",
      "\tThe cache holds 0 out of a possible 3656 tensors and is 0% full.\n",
      "\tSo far there have been 0 cache hits.\n",
      "\t2 paths were skipped because they previously failed.\n",
      "\t26.40 seconds elapsed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process test_worker_2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ml4cvd/tensor_generators.py\", line 319, in multiprocessing_worker\n",
      "    self._on_epoch_end()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ml4cvd/tensor_generators.py\", line 303, in _on_epoch_end\n",
      "    raise ValueError(f\"Completed an epoch but did not find any tensors to yield\")\n",
      "ValueError: Completed an epoch but did not find any tensors to yield\n"
     ]
    }
   ],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/sax-lax-40k-lvm/2019-11-21/', \n",
    "            '--input_tensors', 't2_flair_brain_30_slices', \n",
    "            '--output_tensors', 'age_2',\n",
    "            '--batch_size', '1',\n",
    "            '--epochs', '2',  \n",
    "            '--learning_rate', '0.001',\n",
    "            '--training_steps', '128',\n",
    "            '--validation_steps', '10',\n",
    "            '--test_steps', '1',\n",
    "            '--model_file', '/mnt/ml4cvd/projects/jamesp/data/models/mri_slice_esv.hd5',\n",
    "            '--id', 'mri_slice_esv']\n",
    "\n",
    "args = parse_args()\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(generate_test, args.test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f5a417501350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_mri_slice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "test_tensor = test_data['input_mri_slice']\n",
    "print(test_tensor.shape, test_tensor[:1].shape)\n",
    "_, axes = plt.subplots(1, 6, figsize=(18, 14))\n",
    "[axes[i].imshow(test_tensor[i, :, :, 0]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = saliency_map(test_tensor, model, 'output_end_systole_volume_continuous', 0)\n",
    "_, axes = plt.subplots(1, 6, figsize=(18, 14))\n",
    "[axes[i].imshow(grads[i, :, :, 0]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/pix-size-tensors/2019-04-29/', \n",
    "            '--input_tensors', 'mri_slice', \n",
    "            '--output_tensors', 'bmi',\n",
    "            '--batch_size', '6',\n",
    "            '--epochs', '2',  \n",
    "            '--learning_rate', '0.001',\n",
    "            '--training_steps', '128',\n",
    "            '--validation_steps', '10',\n",
    "            '--test_steps', '1',\n",
    "            '--model_file', '/mnt/ml4cvd/projects/jamesp/data/models/mri_slice_bmi.hd5',\n",
    "            '--id', 'mri_slice_bmi']\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(args.tensor_maps_in,  args.tensor_maps_out,  args.tensors, args.batch_size,   args.valid_ratio, args.test_ratio, args.test_modulo, args.balance_csvs)\n",
    "\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(args.tensor_maps_in, args.tensor_maps_out,\n",
    "                                                                        generate_test, args.test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = test_data['input_mri_slice']\n",
    "print(test_tensor.shape, test_tensor[:1].shape)\n",
    "_, axes = plt.subplots(1, 6, figsize=(18, 14))\n",
    "[axes[i].imshow(test_tensor[i, :, :, 0]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = saliency_map(test_tensor, model, 'output_23104_Body-mass-index-BMI_0_0_continuous', 0)\n",
    "_, axes = plt.subplots(1, 6, figsize=(18, 14))\n",
    "[axes[i].imshow(grads[i, :, :, 0]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/pix-size-tensors/2019-04-29/', \n",
    "            '--input_tensors', 'mri_slice', \n",
    "            '--output_tensors', 'genetic_sex',\n",
    "            '--batch_size', '6',\n",
    "            '--epochs', '2',  \n",
    "            '--learning_rate', '0.001',\n",
    "            '--training_steps', '128',\n",
    "            '--validation_steps', '10',\n",
    "            '--test_steps', '1',\n",
    "            '--model_file', '/mnt/ml4cvd/projects/jamesp/data/models/mri_slice_sex.hd5',\n",
    "            '--id', 'mri_slice_sex']\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(args.tensor_maps_in,  args.tensor_maps_out,  args.tensors, args.batch_size,   args.valid_ratio, args.test_ratio, args.test_modulo, args.balance_csvs)\n",
    "\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(args.tensor_maps_in, args.tensor_maps_out,\n",
    "                                                                        generate_test, args.test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = test_data['input_mri_slice']\n",
    "print(test_tensor.shape, test_tensor[:1].shape)\n",
    "_, axes = plt.subplots(1, 6, figsize=(18, 14))\n",
    "[axes[i].imshow(test_tensor[i, :, :, 0]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = saliency_map(test_tensor, model, 'output_genetic_sex_categorical', 0)\n",
    "_, axes = plt.subplots(1, 6, figsize=(18, 14))\n",
    "[axes[i].imshow(grads[i, :, :, 0]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/pix-size-tensors/2019-04-29/', \n",
    "            '--input_tensors', 'mri_slice', \n",
    "            '--output_tensors', 'birth_year',\n",
    "            '--batch_size', '6',\n",
    "            '--epochs', '2',  \n",
    "            '--learning_rate', '0.001',\n",
    "            '--training_steps', '128',\n",
    "            '--validation_steps', '10',\n",
    "            '--test_steps', '1',\n",
    "            '--model_file', '/mnt/ml4cvd/projects/jamesp/data/models/mri_slice_age.hd5',\n",
    "            '--id', 'mri_slice_age']\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(args.tensor_maps_in,  args.tensor_maps_out,  args.tensors, args.batch_size,   args.valid_ratio, args.test_ratio, args.test_modulo, args.balance_csvs)\n",
    "\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(args.tensor_maps_in, args.tensor_maps_out,\n",
    "                                                                        generate_test, args.test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = test_data['input_mri_slice']\n",
    "print(test_tensor.shape, test_tensor[:1].shape)\n",
    "_, axes = plt.subplots(1, 6, figsize=(18, 14))\n",
    "[axes[i].imshow(test_tensor[i, :, :, 0]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = saliency_map(test_tensor, model, 'output_22200_Year-of-birth_0_0_continuous', 0)\n",
    "_, axes = plt.subplots(1, 6, figsize=(18, 14))\n",
    "[axes[i].imshow(grads[i, :, :, 0]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/pix-size-tensors/2019-04-29/', \n",
    "            '--input_tensors', 'mri_systole_diastole', \n",
    "            '--output_tensors', 'end_systole_volume',\n",
    "            '--batch_size', '6',\n",
    "            '--epochs', '2',  \n",
    "            '--learning_rate', '0.001',\n",
    "            '--training_steps', '128',\n",
    "            '--validation_steps', '10',\n",
    "            '--test_steps', '1',\n",
    "            '--model_file', '/mnt/ml4cvd/projects/jamesp/data/models/mri_systole_diastole_esv.hd5',\n",
    "            '--id', 'mri_systole_diastole_esv']\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(args.tensor_maps_in,  args.tensor_maps_out,  args.tensors, args.batch_size,   args.valid_ratio, args.test_ratio, args.test_modulo, args.balance_csvs)\n",
    "\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(args.tensor_maps_in, args.tensor_maps_out,\n",
    "                                                                        generate_test, args.test_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = test_data['input_mri_systole_diastole']\n",
    "print(test_tensor.shape, test_tensor[:1].shape)\n",
    "_, axes = plt.subplots(2, 6, figsize=(18, 4), sharex=True)\n",
    "for i in range(6):\n",
    "    axes[0, i].set_title('Diastole')\n",
    "    axes[1, i].set_title('Systole')\n",
    "    axes[0, i].imshow(test_tensor[i, :, :, 0, 0])\n",
    "    axes[1, i].imshow(test_tensor[i, :, :, 1, 0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = saliency_map(test_tensor, model, 'output_end_systole_volume_continuous', 0)\n",
    "_, axes = plt.subplots(2, 6, figsize=(18, 4), sharex=True)\n",
    "for i in range(6):\n",
    "    axes[0, i].set_title('Diastole')\n",
    "    axes[1, i].set_title('Systole')\n",
    "    axes[0, i].imshow(grads[i, :, :, 0, 0])\n",
    "    axes[1, i].imshow(grads[i, :, :, 1, 0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/ecg-rest-31k/2019-06-10/', \n",
    "            '--input_tensors', 'ecg_rest_1lead', \n",
    "            '--output_tensors', 'ecg_semi_coarse_with_poor',\n",
    "            '--batch_size', '6',\n",
    "            '--epochs', '2',  \n",
    "            '--learning_rate', '0.001',\n",
    "            '--training_steps', '128',\n",
    "            '--validation_steps', '10',\n",
    "            '--test_steps', '1',\n",
    "            '--model_file', '/home/sam/ml/trained_models/ecg_1lead_rhythm_only/ecg_1lead_rhythm_only.hd5',\n",
    "            '--id', 'ecg_1lead_rhythm_only']\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(args.tensor_maps_in,  args.tensor_maps_out,  args.tensors, args.batch_size,   args.valid_ratio, args.test_ratio, args.test_modulo, args.balance_csvs)\n",
    "\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n",
    "\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(args.tensor_maps_in, args.tensor_maps_out,\n",
    "                                                                        generate_test, args.test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = test_data['input_strip_ecg_rest']\n",
    "print(test_tensor.shape, test_tensor[3:4].shape)\n",
    "_, axes = plt.subplots(6, 1, figsize=(18, 14))\n",
    "[axes[i].plot(test_tensor[i,:,:].flatten('F')) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = saliency_map(test_tensor, model, 'output_ecg_semi_coarse_with_poor_categorical', 0)\n",
    "_, axes = plt.subplots(6, 1, figsize=(18, 14))\n",
    "[axes[i].plot(grads[i,:,:].flatten('F')) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = saliency_map(test_tensor, model, 'output_ecg_semi_coarse_with_poor_categorical', 3)\n",
    "_, axes = plt.subplots(6, 1, figsize=(18, 14))\n",
    "[axes[i].plot(grads[i,:,:].flatten('F')) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdir = '/mnt/disks/ecg-rest-31k/2019-06-10/'\n",
    "paths = [xdir+'1238558.hd5', xdir+'1258475.hd5', xdir+'1286494.hd5', xdir+'1381627.hd5', \n",
    "         xdir+'1487911.hd5', xdir+'1509361.hd5', xdir+'1578315.hd5', xdir+'1616127.hd5', xdir+'1723645.hd5', ]\n",
    "generator = TensorGenerator(8, args.tensor_maps_in, args.tensor_maps_out, paths, None, True)\n",
    "data, labels, hd5s = next(generator)\n",
    "print('predicitons are:', model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = data['input_strip_ecg_rest']\n",
    "_, axes = plt.subplots(8, 1, figsize=(18, 14))\n",
    "[axes[i].plot(test_tensor[i,:,:].flatten('F')) for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = saliency_map(test_tensor, model, 'output_ecg_semi_coarse_with_poor_categorical', 3)\n",
    "_, axes = plt.subplots(8, 1, figsize=(18, 14))\n",
    "[axes[i].plot(grads[i,:,:].flatten('F')) for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = saliency_map(test_tensor, model, 'output_ecg_semi_coarse_with_poor_categorical', 0)\n",
    "_, axes = plt.subplots(8, 1, figsize=(18, 14))\n",
    "[axes[i].plot(grads[i,:,:].flatten('F')) for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = saliency_map(test_tensor[7:8], model, 'output_ecg_semi_coarse_with_poor_categorical', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = saliency_map(test_tensor[7:8], model, 'output_ecg_semi_coarse_with_poor_categorical', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
