{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to ML using ML4H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Basic comfort with python, some linear algebra, some data science\n",
    "- Follow the instructions in the main [README](https://github.com/broadinstitute/ml4h) for installing ML4H\n",
    "- Data used in this notebook is available here ([gs://fc-500bd872-4a53-45c9-87d3-39656bd83f85/data/hg002_na24385_ml4h_tensors_v2021_10_14.tar.gz](gs://fc-500bd872-4a53-45c9-87d3-39656bd83f85/data/hg002_na24385_ml4h_tensors_v2021_10_14.tar.gz))\n",
    "- Now we are ready to teach the machines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "from typing import List, Dict, Callable\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from ml4h.defines import StorageType\n",
    "from ml4h.arguments import parse_args\n",
    "from ml4h.TensorMap import TensorMap, Interpretation\n",
    "from ml4h.tensor_generators import test_train_valid_tensor_generators\n",
    "from ml4h.models.train import train_model_from_generators\n",
    "from ml4h.models.legacy_models import make_multimodal_multitask_model\n",
    "from ml4h.models.inspect import plot_and_time_model\n",
    "from ml4h.recipes import compare_multimodal_scalar_task_models, train_multimodal_multitask\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "HD5_FOLDER = './tensors/'\n",
    "OUTPUT_FOLDER = './outputs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python features we make lots of use of in this notebook:\n",
    "- F Strings\n",
    "- Callback Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorMaps\n",
    "The critical data structure in the ml4h codebase is the TensorMap.\n",
    "This abstraction provides a way to translate ***any*** kind of input data, into structured numeric tensors with clear semantics for interpretation and modeling.  TensorMaps guarantee a shape, a way to construct tensors of that shape from the HD5 files created during tensorization and a meaning to the values in the tensor that the TensorMap yields.\n",
    "\n",
    "For example, in the `mnist.py` file these TensorMaps are defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_image_from_hd5(tm: TensorMap, hd5: h5py.File, dependents: Dict = {}) -> np.ndarray:\n",
    "    return np.array(hd5['mnist_image'])\n",
    "\n",
    "\n",
    "mnist_image = TensorMap('mnist_image', shape=(28, 28, 1), tensor_from_file=mnist_image_from_hd5)\n",
    "\n",
    "\n",
    "def mnist_label_from_hd5(tm: TensorMap, hd5: h5py.File, dependents: Dict = {}) -> np.ndarray:\n",
    "    one_hot = np.zeros(tm.shape, dtype=np.float32)\n",
    "    one_hot[int(hd5['mnist_label'][0])] = 1.0\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "mnist_label = TensorMap(\n",
    "    'mnist_label', Interpretation.CATEGORICAL, tensor_from_file=mnist_label_from_hd5,\n",
    "    channel_map={f'digit_{i}': i for i in range(10)},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similiarly, in the `gatk.py` file we define tensors to encode data about genomic variants.  Specifically, we create 3 TensorMaps: `reference` is a 1-hot encoded 128 base-pair window of DNA sequence. `read_tensor` is an alignment of as many as 128 different DNA reads overlapping a 128 base-pair window of reference DNA.  This TensorMap includes 15 channels which encode the DNA bases from the reference from the read sequence and meta data belonging to each read.  Lastly, we define the `CATEGORICAL` TensorMap  `variant_label` which encodes the truth status of this particular genomic variant.  In this dataset we are considering on SNPs and small insertions or deletions giving us the 4 labels: `'NOT_SNP', 'NOT_INDEL', 'SNP', 'INDEL'`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNA_SYMBOLS = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "VARIANT_LABELS = {'NOT_SNP': 0, 'NOT_INDEL': 1, 'SNP': 2, 'INDEL': 3}\n",
    "\n",
    "\n",
    "def tensor_from_hd5(tm: TensorMap, hd5: h5py.File, dependents: Dict = {}) -> np.ndarray:\n",
    "    return np.array(hd5[tm.name])\n",
    "\n",
    "\n",
    "reference = TensorMap('reference', shape=(128, len(DNA_SYMBOLS)), tensor_from_file=tensor_from_hd5)\n",
    "read_tensor = TensorMap('read_tensor', shape=(128, 128, 15), tensor_from_file=tensor_from_hd5)\n",
    "\n",
    "\n",
    "def variant_label_from_hd5(tm: TensorMap, hd5: h5py.File, dependents: Dict = {}) -> np.ndarray:\n",
    "    one_hot = np.zeros(tm.shape, dtype=np.float32)\n",
    "    variant_str = str(hd5['variant_label'][()], 'utf-8')\n",
    "    for channel in tm.channel_map:\n",
    "        if channel.lower() == variant_str.lower():\n",
    "            one_hot[tm.channel_map[channel]] = 1.0\n",
    "    if one_hot.sum() != 1:\n",
    "        raise ValueError(f'TensorMap {tm.name} missing or invalid label: {variant_str} one_hot: {one_hot}')\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "variant_label = TensorMap(\n",
    "    'variant_label', Interpretation.CATEGORICAL,\n",
    "    shape=(len(VARIANT_LABELS),),\n",
    "    tensor_from_file=variant_label_from_hd5,\n",
    "    channel_map=VARIANT_LABELS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the type of data used by the GATK tool CNNScoreVariants to filter DNA sequencing data.  The tensorization code is part of the GATK not ML4H, however tensorized data for use is available at: `gs://fc-500bd872-4a53-45c9-87d3-39656bd83f85/data/hg002_na24385_ml4h_tensors_v2021_10_14.tar.gz`. Once the data has been localized you can unpack the HD5 files into the `HD5_FOLDER` with the cell below (assuming the tar.gz file is in the same directory as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(HD5_FOLDER):\n",
    "    os.makedirs(HD5_FOLDER)\n",
    "!tar -zxvf ./hg002_na24385_ml4h_tensors_v2021_10_14.tar.gz  -C ./tensors/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model Factory\n",
    "The function ***make_multimodal_multitask_model()*** takes lists of TensorMaps and connects them with intelligent goo.  Specifically, given a list of TensorMaps that are model inputs and TensorMaps that are desired outputs the model factory will build a model and loss appropriate for the dimensions and interpretations of the data at hand.  The depending on the input and output TensorMaps provided, the Model Factory will build models for many different situations including:\n",
    "- Classification\n",
    "- Regression\n",
    "- Multitask\n",
    "- Multimodal\n",
    "- Multimodal Multitask\n",
    "- Autoencoders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D CNN for Classification of Genomic Variants\n",
    "Jupyter is great, but can complicate productionizing code. We try to mitigate this by interacting with the jupyter notebook as if it were a command line call to one of ml4h's modes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'gatk.reference',\n",
    "            '--output_tensors', 'gatk.variant_label',\n",
    "            '--batch_size', '16',\n",
    "            '--epochs', '12',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'learn_1d_cnn'\n",
    "           ]\n",
    "args = parse_args()\n",
    "metrics = train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'gatk.read_tensor',\n",
    "            '--output_tensors', 'gatk.variant_label',\n",
    "            '--batch_size', '16',\n",
    "            '--epochs', '12',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--id', 'learn_2d_cnn'\n",
    "           ]\n",
    "args = parse_args()\n",
    "metrics = train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Models that have been trained for the same task (ie with the same output TensorMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['compare_scalar', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'gatk.reference', 'gatk.read_tensor',\n",
    "            '--output_tensors', 'gatk.variant_label',\n",
    "            '--id', 'gatk_model_comparison',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--model_files', f'{OUTPUT_FOLDER}learn_1d_cnn/learn_1d_cnn.h5',\n",
    "                             f'{OUTPUT_FOLDER}learn_2d_cnn/learn_2d_cnn.h5',\n",
    "            '--test_steps', '100', \n",
    "            '--batch_size', '16',\n",
    "           ]\n",
    "args = parse_args()\n",
    "\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "compare_multimodal_scalar_task_models(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Architectures\n",
    "The default architecture produced by the ModelFactory is based the [DenseNet](https://arxiv.org/abs/1608.06993) Convolutional Neural Network.  It is extremely customizable as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', HD5_FOLDER, \n",
    "            '--input_tensors', 'gatk.reference',\n",
    "            '--output_tensors', 'gatk.variant_label',\n",
    "            '--output_folder', OUTPUT_FOLDER,\n",
    "            '--activation', 'swish',\n",
    "            '--conv_layers', '32',\n",
    "            '--conv_width', '32', '32', '32',\n",
    "            '--dense_blocks', '32', '24', '16',\n",
    "            '--dense_layers', '32',  '32', \n",
    "            '--block_size', '4',\n",
    "            '--pool_x', '2',\n",
    "            '--pool_y', '2',\n",
    "            '--inspect_model',\n",
    "            '--epochs', '1',\n",
    "            '--batch_size', '4',\n",
    "            '--id', 'hypertuned_1d',\n",
    "           ]\n",
    "args = parse_args()\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "train_multimodal_multitask(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the cell above the diagram of the model architecture will be saved at: `./outputs/hypertuned_1d/architecture_graph_hypertuned_1d.png`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
