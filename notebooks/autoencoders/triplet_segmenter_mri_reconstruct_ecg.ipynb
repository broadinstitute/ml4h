{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from typing import Dict, List, Tuple, Iterable, Union, Optional, Set, Sequence, Callable, DefaultDict, Any\n",
    "\n",
    "# Keras imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LeakyReLU, PReLU, ELU, ThresholdedReLU, Lambda, Reshape, LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.layers import SpatialDropout1D, SpatialDropout2D, SpatialDropout3D, add, concatenate\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, Flatten, LSTM, RepeatVector\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Conv3D, UpSampling1D, UpSampling2D, UpSampling3D, MaxPooling1D\n",
    "from tensorflow.keras.layers import MaxPooling2D, MaxPooling3D, AveragePooling1D, AveragePooling2D, AveragePooling3D, Layer\n",
    "from tensorflow.keras.layers import SeparableConv1D, SeparableConv2D, DepthwiseConv2D, Concatenate, Add\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalAveragePooling2D, GlobalAveragePooling3D\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ml4h Imports\n",
    "from ml4h.TensorMap import TensorMap\n",
    "from ml4h.arguments import parse_args\n",
    "from ml4h.models import make_multimodal_multitask_model, train_model_from_generators, make_hidden_layer_model, _conv_layer_from_kind_and_dimension\n",
    "from ml4h.tensor_generators import TensorGenerator, big_batch_from_minibatch_generator, test_train_valid_tensor_generators\n",
    "from ml4h.recipes import plot_predictions, infer_hidden_layer_multimodal_multitask\n",
    "\n",
    "\n",
    "Tensor = tf.Tensor\n",
    "\n",
    "ACTIVATION_CLASSES = {\n",
    "    'leaky': LeakyReLU(),\n",
    "    'prelu': PReLU(),\n",
    "    'elu': ELU(),\n",
    "    'thresh_relu': ThresholdedReLU,\n",
    "}\n",
    "ACTIVATION_FUNCTIONS = {\n",
    "    'swish': tf.nn.swish,\n",
    "    'gelu': tfa.activations.gelu,\n",
    "    'lisht': tfa.activations.lisht,\n",
    "    'mish': tfa.activations.mish,\n",
    "}\n",
    "NORMALIZATION_CLASSES = {\n",
    "    'batch_norm': BatchNormalization,\n",
    "    'layer_norm': LayerNormalization,\n",
    "    'instance_norm': tfa.layers.InstanceNormalization,\n",
    "    'poincare_norm': tfa.layers.PoincareNormalize,\n",
    "}\n",
    "CONV_REGULARIZATION_CLASSES = {\n",
    "    # class name -> (dimension -> class)\n",
    "    'spatial_dropout': {2: SpatialDropout1D, 3: SpatialDropout2D, 4: SpatialDropout3D},\n",
    "    'dropout': defaultdict(lambda _: Dropout),\n",
    "}\n",
    "DENSE_REGULARIZATION_CLASSES = {\n",
    "    'dropout': Dropout,  # TODO: add l1, l2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _activation_layer(activation: str) -> Activation:\n",
    "    return (\n",
    "        ACTIVATION_CLASSES.get(activation, None)\n",
    "        or Activation(ACTIVATION_FUNCTIONS.get(activation, None) or activation)\n",
    "    )\n",
    "\n",
    "\n",
    "def _normalization_layer(norm: str) -> Layer:\n",
    "    if not norm:\n",
    "        return lambda x: x\n",
    "    return NORMALIZATION_CLASSES[norm]()\n",
    "\n",
    "\n",
    "def _regularization_layer(dimension: int, regularization_type: str, rate: float):\n",
    "    if not regularization_type:\n",
    "        return lambda x: x\n",
    "    if regularization_type in DENSE_REGULARIZATION_CLASSES:\n",
    "        return DENSE_REGULARIZATION_CLASSES[regularization_type](rate)\n",
    "    return CONV_REGULARIZATION_CLASSES[regularization_type][dimension](rate)\n",
    "\n",
    "\n",
    "def _calc_start_shape(\n",
    "        num_upsamples: int, output_shape: Tuple[int, ...], upsample_rates: Sequence[int], channels: int,\n",
    ") -> Tuple[int, ...]:\n",
    "    \"\"\"\n",
    "    Given the number of blocks in the decoder and the upsample rates, return required input shape to get to output shape\n",
    "    \"\"\"\n",
    "    upsample_rates = list(upsample_rates) + [1] * len(output_shape)\n",
    "    return tuple((shape // rate**num_upsamples for shape, rate in zip(output_shape[:-1], upsample_rates))) + (channels,)\n",
    "\n",
    "\n",
    "class FlatToStructure:\n",
    "    \"\"\"Takes a flat input, applies a dense layer, then restructures to output_shape\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            output_shape: Tuple[int, ...],\n",
    "            activation: str,\n",
    "            normalization: str,\n",
    "    ):\n",
    "        self.input_shapes = output_shape\n",
    "        self.dense = Dense(units=int(np.prod(output_shape)))\n",
    "        self.activation = _activation_layer(activation)\n",
    "        self.reshape = Reshape(output_shape)\n",
    "        self.norm = _normalization_layer(normalization)\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        return self.reshape(self.norm(self.activation(self.dense(x))))\n",
    "\n",
    "\n",
    "def _conv_layer_from_kind_and_dimension(\n",
    "        dimension: int, conv_layer_type: str, conv_x: List[int], conv_y: List[int], conv_z: List[int],\n",
    ") -> Tuple[Layer, List[Tuple[int, ...]]]:\n",
    "    if dimension == 4 and conv_layer_type == 'conv':\n",
    "        conv_layer = Conv3D\n",
    "        kernel = zip(conv_x, conv_y, conv_z)\n",
    "    elif dimension == 3 and conv_layer_type == 'conv':\n",
    "        conv_layer = Conv2D\n",
    "        kernel = zip(conv_x, conv_y)\n",
    "    elif dimension == 2 and conv_layer_type == 'conv':\n",
    "        conv_layer = Conv1D\n",
    "        kernel = zip(conv_x)\n",
    "    elif dimension == 3 and conv_layer_type == 'separable':\n",
    "        conv_layer = SeparableConv2D\n",
    "        kernel = zip(conv_x, conv_y)\n",
    "    elif dimension == 2 and conv_layer_type == 'separable':\n",
    "        conv_layer = SeparableConv1D\n",
    "        kernel = zip(conv_x)\n",
    "    elif dimension == 3 and conv_layer_type == 'depth':\n",
    "        conv_layer = DepthwiseConv2D\n",
    "        kernel = zip(conv_x, conv_y)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown convolution type: {conv_layer_type} for dimension: {dimension}')\n",
    "    return conv_layer, list(kernel)\n",
    "\n",
    "\n",
    "def _upsampler(dimension, pool_x, pool_y, pool_z):\n",
    "    if dimension == 4:\n",
    "        return UpSampling3D(size=(pool_x, pool_y, pool_z))\n",
    "    elif dimension == 3:\n",
    "        return UpSampling2D(size=(pool_x, pool_y))\n",
    "    elif dimension == 2:\n",
    "        return UpSampling1D(size=pool_x)\n",
    "    \n",
    "\n",
    "    \n",
    "def _one_by_n_kernel(dimension):\n",
    "    return tuple([1] * (dimension - 1))\n",
    "\n",
    "\n",
    "class DenseConvolutionalBlock:\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            dimension: int,\n",
    "            block_size: int,\n",
    "            conv_layer_type: str,\n",
    "            filters: int,\n",
    "            conv_x: List[int],\n",
    "            conv_y: List[int],\n",
    "            conv_z: List[int],\n",
    "            activation: str,\n",
    "            normalization: str,\n",
    "            regularization: str,\n",
    "            regularization_rate: float,\n",
    "    ):\n",
    "        conv_layer, kernels = _conv_layer_from_kind_and_dimension(dimension, conv_layer_type, conv_x, conv_y, conv_z)\n",
    "        if isinstance(conv_layer, DepthwiseConv2D):\n",
    "            self.conv_layers = [conv_layer(kernel_size=kernel, padding='same') for kernel in kernels]\n",
    "        else:\n",
    "            self.conv_layers = [conv_layer(filters=filters, kernel_size=kernel, padding='same') for kernel in kernels]\n",
    "        self.activations = [_activation_layer(activation) for _ in range(block_size)]\n",
    "        self.normalizations = [_normalization_layer(normalization) for _ in range(block_size)]\n",
    "        self.regularizations = [_regularization_layer(dimension, regularization, regularization_rate) for _ in range(block_size)]\n",
    "        print(f'Dense Block Convolutional Layers (num_filters, kernel_size): {list(zip([filters]*len(kernels), kernels))}')\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        dense_connections = [x]\n",
    "        for i, (convolve, activate, normalize, regularize) in enumerate(\n",
    "            zip(\n",
    "                    self.conv_layers, self.activations, self.normalizations, self.regularizations,\n",
    "            ),\n",
    "        ):\n",
    "            x = normalize(regularize(activate(convolve(x))))\n",
    "            if i < len(self.conv_layers) - 1:  # output of block does not get concatenated to\n",
    "                dense_connections.append(x)\n",
    "                x = Concatenate()(dense_connections[:])  # [:] is necessary because of tf weirdness\n",
    "        return x\n",
    "\n",
    "    \n",
    "class ConvDecoder2:\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            tensor_map_out: TensorMap,\n",
    "            filters_per_dense_block: List[int],\n",
    "            conv_layer_type: str,\n",
    "            conv_x: List[int],\n",
    "            conv_y: List[int],\n",
    "            conv_z: List[int],\n",
    "            block_size: int,\n",
    "            activation: str,\n",
    "            normalization: str,\n",
    "            regularization: str,\n",
    "            regularization_rate: float,\n",
    "            upsample_x: int,\n",
    "            upsample_y: int,\n",
    "            upsample_z: int,\n",
    "    ):\n",
    "        dimension = tensor_map_out.axes()\n",
    "        self.dense_blocks = [\n",
    "            DenseConvolutionalBlock(\n",
    "                dimension=tensor_map_out.axes(), conv_layer_type=conv_layer_type, filters=filters, conv_x=[x]*block_size,\n",
    "                conv_y=[y]*block_size, conv_z=[z]*block_size, block_size=block_size, activation=activation, normalization=normalization,\n",
    "                regularization=regularization, regularization_rate=regularization_rate,\n",
    "            )\n",
    "            for filters, x, y, z in zip(filters_per_dense_block, conv_x, conv_y, conv_z)\n",
    "        ]\n",
    "        conv_layer, _ = _conv_layer_from_kind_and_dimension(dimension, 'conv', conv_x, conv_y, conv_z)\n",
    "        self.conv_label = conv_layer(tensor_map_out.shape[-1], _one_by_n_kernel(dimension), activation=tensor_map_out.activation, name=tensor_map_out.output_name())\n",
    "        self.upsamples = [_upsampler(dimension, upsample_x, upsample_y, upsample_z) for _ in range(len(filters_per_dense_block) + 1)]\n",
    "        print(f'Decode has: {list(enumerate(zip(self.dense_blocks, self.upsamples)))}')\n",
    "    def __call__(self, x: Tensor) -> Tensor:\n",
    "        for i, (dense_block, upsample) in enumerate(zip(self.dense_blocks, self.upsamples)):\n",
    "            \n",
    "            x = upsample(x)\n",
    "            x = dense_block(x)\n",
    "        return self.conv_label(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow import acos\n",
    "\n",
    "def l2_norm(x, axis=None):\n",
    "    \"\"\"\n",
    "    takes an input tensor and returns the l2 norm along specified axis\n",
    "    \"\"\"\n",
    "\n",
    "    square_sum = K.sum(K.square(x), axis=axis, keepdims=True)\n",
    "    norm = K.sqrt(K.maximum(square_sum, K.epsilon()))\n",
    "\n",
    "    return norm\n",
    "\n",
    "def pairwise_cosine_difference(t1, t2):\n",
    "    \"\"\"\n",
    "    A [batch x n x d] tensor of n rows with d dimensions\n",
    "    B [batch x m x d] tensor of n rows with d dimensions\n",
    "\n",
    "    returns:\n",
    "    D [batch x n x m] tensor of cosine similarity scores between each point i<n, j<m\n",
    "    \"\"\"\n",
    "    t1_norm = t1 / l2_norm(t1, axis=-1)\n",
    "    t2_norm = t2 / l2_norm(t2, axis=-1)\n",
    "    dot = K.clip(K.batch_dot(t1, t2), -1, 1)\n",
    "    return acos(dot)\n",
    "\n",
    "class CosineLossLayer(Layer):\n",
    "    \"\"\"Layer that creates an Cosine loss.\"\"\"\n",
    "    def __init__(self, weight):\n",
    "        super(CosineLossLayer, self).__init__()\n",
    "        self.weight = weight\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'weight': self.weight})\n",
    "        return config\n",
    "    def call(self, inputs):\n",
    "        # We use `add_loss` to create a regularization loss\n",
    "        # that depends on the inputs.\n",
    "        self.add_loss(self.weight * pairwise_cosine_difference(inputs[0], inputs[1]))\n",
    "        return inputs\n",
    "\n",
    "class L2LossLayer(Layer):\n",
    "    \"\"\"Layer that creates an L2 loss.\"\"\"\n",
    "    def __init__(self, weight):\n",
    "        super(L2LossLayer, self).__init__()\n",
    "        self.weight = weight\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'weight': self.weight})\n",
    "        return config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        self.add_loss(self.weight * tf.reduce_sum(tf.square(inputs[0] - inputs[1])))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_paired_autoencoder_model(\n",
    "    pairs: List[Tuple[TensorMap, TensorMap]],\n",
    "    pair_loss = 'cosine',\n",
    "    **kwargs\n",
    ") -> Model:\n",
    "    inputs = {tm: Input(shape=tm.shape, name=tm.input_name()) for tm in args.tensor_maps_in}\n",
    "    original_outputs = {tm:1 for tm in args.tensor_maps_out}\n",
    "    multimodal_activations = []\n",
    "    outputs = []\n",
    "    losses = []\n",
    "    for left, right in pairs:\n",
    "        args.tensor_maps_in = [left]\n",
    "        left_model = make_multimodal_multitask_model(**args.__dict__)\n",
    "        encode_left = make_hidden_layer_model(left_model, [left], args.hidden_layer)\n",
    "        h_left = encode_left(inputs[left])\n",
    "        \n",
    "        args.tensor_maps_in = [right]\n",
    "        right_model = make_multimodal_multitask_model(**args.__dict__)     \n",
    "        encode_right = make_hidden_layer_model(right_model, [right], args.hidden_layer)\n",
    "        h_right = encode_right(inputs[right])        \n",
    "        \n",
    "        if pair_loss == 'cosine':\n",
    "            loss_layer = CosineLossLayer(1.0)\n",
    "        elif pair_loss == 'euclid':\n",
    "            loss_layer = L2LossLayer(1.0)\n",
    "        \n",
    "        paired_embeddings = loss_layer([h_left, h_right])\n",
    "        multimodal_activations.extend(paired_embeddings)\n",
    "        \n",
    "    multimodal_activation = Concatenate()(multimodal_activations)\n",
    "    \n",
    "    pre_decoder_shapes: Dict[TensorMap, Optional[Tuple[int, ...]]] = {}\n",
    "    for tm in args.tensor_maps_out:\n",
    "        shape = _calc_start_shape(num_upsamples=len(args.dense_blocks), output_shape=tm.shape, \n",
    "                                  upsample_rates=[args.pool_x, args.pool_y, args.pool_z], \n",
    "                                  channels=args.dense_blocks[-1])    \n",
    "        \n",
    "        restructure = FlatToStructure(output_shape=shape, activation=args.activation, \n",
    "                                      normalization=args.dense_normalize)\n",
    "        \n",
    "        decode = ConvDecoder2(\n",
    "            tensor_map_out=tm,\n",
    "            filters_per_dense_block=args.dense_blocks[::-1],\n",
    "            conv_layer_type=args.conv_type,\n",
    "            conv_x=args.conv_x,\n",
    "            conv_y=args.conv_y,\n",
    "            conv_z=args.conv_z,\n",
    "            block_size=args.block_size,\n",
    "            activation=args.activation,\n",
    "            normalization=args.conv_normalize,\n",
    "            regularization=args.conv_regularize,\n",
    "            regularization_rate=args.conv_regularize_rate,\n",
    "            upsample_x=args.pool_x,\n",
    "            upsample_y=args.pool_y,\n",
    "            upsample_z=args.pool_z,\n",
    "        )\n",
    "        \n",
    "        outputs.append(decode(restructure(multimodal_activation)))\n",
    "        losses.append(tm.loss)\n",
    "\n",
    "    args.tensor_maps_out =  list(original_outputs.keys())\n",
    "    args.tensor_maps_in = list(inputs.keys())\n",
    "    \n",
    "    m = Model(inputs=list(inputs.values()), outputs=outputs)\n",
    "    my_metrics = {tm.output_name(): tm.metrics for tm in args.tensor_maps_out}\n",
    "    opt = Adam(lr=kwargs['learning_rate'], beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    m.compile(optimizer=opt, loss=losses, metrics=my_metrics)\n",
    "    m.summary()\n",
    "    \n",
    "    if kwargs['model_layers'] is not None:\n",
    "        m.load_weights(kwargs['model_layers'], by_name=True)\n",
    "        print(f\"Loaded model weights from:{kwargs['model_layers']}\")\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/sax-lax-40k-lvm/2020-01-29/', \n",
    "            '--input_tensors', 'ecg.ecg_rest','mri.lax_4ch_diastole_slice0_224_3d', 'mri.cine_segmented_lax_4ch_diastole', \n",
    "            '--output_tensors', 'ecg.ecg_rest','mri.lax_4ch_diastole_slice0_224_3d', 'mri.cine_segmented_lax_4ch_diastole',\n",
    "            '--activation', 'swish',\n",
    "            '--conv_layers', '32',\n",
    "            '--conv_x', '9', '9', '9',\n",
    "            '--conv_y', '3', '3', '3', \n",
    "            '--conv_z', '3', '3', '3',\n",
    "            '--dense_blocks', '32', '32', '32',\n",
    "            '--block_size', '3',\n",
    "            '--dense_layers', '256',\n",
    "            '--pool_x', '2',\n",
    "            '--pool_y', '2',\n",
    "            '--batch_size', '1',\n",
    "            '--patience', '44',\n",
    "            '--epochs', '496',\n",
    "            '--learning_rate', '0.0001',\n",
    "            '--training_steps', '128',\n",
    "            '--validation_steps', '30',\n",
    "            '--test_steps', '8',\n",
    "            '--num_workers', '4',\n",
    "            '--inspect_model',\n",
    "            '--tensormap_prefix', 'ml4h.tensormap.ukb',\n",
    "            '--id', 'ecg_mri_lax_4ch_diastole_euclid_triplet_segmenter_256d']\n",
    "args = parse_args()\n",
    "pairs = [\n",
    "    (args.tensor_maps_in[0], args.tensor_maps_in[1]),\n",
    "    (args.tensor_maps_in[1], args.tensor_maps_in[2])\n",
    "]\n",
    "overparameterized_model = make_paired_autoencoder_model(pairs, pair_loss='euclid', **args.__dict__)\n",
    "generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "train_model_from_generators(\n",
    "        overparameterized_model, generate_train, generate_valid, args.training_steps, args.validation_steps, args.batch_size,\n",
    "        args.epochs, args.patience, args.output_folder, args.id, args.inspect_model, args.inspect_show_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(args.output_folder, args.id + '/')\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(generate_test, args.test_steps)\n",
    "print(list(test_data.keys()))\n",
    "\n",
    "preds = overparameterized_model.predict(test_data)\n",
    "print([p.shape for p in preds])\n",
    "print([tm.name for tm in args.tensor_maps_out])\n",
    "print(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4h.plots import _plot_reconstruction\n",
    "_plot_reconstruction(args.tensor_maps_out[0],  test_data['input_strip_continuous'], preds[0], out_path, test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml4h.explorations import predictions_to_pngs\n",
    "predictions_to_pngs(preds, args.tensor_maps_in, args.tensor_maps_out, \n",
    "                    test_data, test_labels, test_paths, out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(test_data['input_strip_continuous'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(generate_test, args.test_steps)\n",
    "test_data['input_strip_continuous'] = np.random.random((args.test_steps*args.batch_size, 5000, 12))\n",
    "ecg_noise_preds = overparameterized_model.predict(test_data)\n",
    "out_path = os.path.join(args.output_folder, args.id + '/ecg_noise/')\n",
    "if not os.path.exists(os.path.dirname(out_path)):\n",
    "    os.makedirs(os.path.dirname(out_path))\n",
    "_plot_reconstruction(args.tensor_maps_out[0],  test_data['input_strip_continuous'], ecg_noise_preds[0], out_path, test_paths)\n",
    "predictions_to_pngs(ecg_noise_preds, args.tensor_maps_in, args.tensor_maps_out, \n",
    "                    test_data, test_labels, test_paths, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ae_towards_attractor(model, test_data, test_labels, test_key, test_index, rows=4, samples=6, steps = 10):\n",
    "    sample_every = steps//samples\n",
    "    fig, axes = plt.subplots(rows, samples, figsize=(samples*16,rows*16))\n",
    "    col = 0\n",
    "    original = test_data[test_key].copy()\n",
    "    for i in range(steps):\n",
    "        if i % sample_every == 0 and col < samples:\n",
    "            for j in range(rows):\n",
    "                if len(test_data[test_key].shape) == 4:\n",
    "                    axes[j, col].imshow(test_data[test_key][j, :, :, 0], cmap = 'gray')\n",
    "                    axes[j, col].set_yticks(())\n",
    "                elif len(test_data[test_key].shape) == 3:\n",
    "                    for l in range(12):\n",
    "                        axes[j, col].plot(range(1200), test_data[test_key][j, :1200, l])\n",
    "                        axes[j, col].set_yticks(())\n",
    "            col += 1\n",
    "        preds = model.predict(test_data) \n",
    "        test_data[test_key] = preds[test_index]\n",
    "    test_data[test_key] = original\n",
    "    plt.show()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(generate_test, args.test_steps)\n",
    "test_key = 'input_lax_4ch_diastole_slice0_224_3d_continuous'\n",
    "test_shape = test_data[test_key].shape\n",
    "test_data[test_key] = np.random.random(test_shape)\n",
    "out_path = os.path.join(args.output_folder, args.id, test_key + '_noise/')\n",
    "if not os.path.exists(os.path.dirname(out_path)):\n",
    "    os.makedirs(os.path.dirname(out_path))\n",
    "noise_preds = plot_ae_towards_attractor(overparameterized_model, test_data, test_labels, test_key, \n",
    "                                        test_index=1, rows=8, samples=4, steps = 18)\n",
    "print(list(test_data.keys()))\n",
    "_plot_reconstruction(args.tensor_maps_out[0],  test_data['input_strip_continuous'], \n",
    "                     noise_preds[0], out_path, test_paths)\n",
    "predictions_to_pngs(noise_preds, args.tensor_maps_in, args.tensor_maps_out, \n",
    "                    test_data, test_labels, test_paths, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "test_data, test_labels, test_paths = big_batch_from_minibatch_generator(generate_test, args.test_steps)\n",
    "test_key = 'input_strip_continuous'\n",
    "test_shape = test_data[test_key].shape\n",
    "test_data[test_key] = np.random.random(test_shape)\n",
    "out_path = os.path.join(args.output_folder, args.id, test_key + '_noise/')\n",
    "if not os.path.exists(os.path.dirname(out_path)):\n",
    "    os.makedirs(os.path.dirname(out_path))\n",
    "noise_preds = plot_ae_towards_attractor(overparameterized_model, test_data, test_labels, test_key, \n",
    "                                        test_index=0, rows=6, samples=6, steps = 24)\n",
    "print(list(test_data.keys()))\n",
    "_plot_reconstruction(args.tensor_maps_out[0],  test_data['input_strip_continuous'], \n",
    "                     noise_preds[0], out_path, test_paths)\n",
    "predictions_to_pngs(noise_preds, args.tensor_maps_in, args.tensor_maps_out, \n",
    "                    test_data, test_labels, test_paths, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/sam/ml/trained_models/lax_4ch_diastole_autoencode_leaky_converge/tensors_all_union.csv')\n",
    "df['21003_Age-when-attended-assessment-centre_2_0'].plot.hist(bins=30)\n",
    "hidden_inference = './recipes_output/ecg_mri_lax_4ch_diastole_paired_autoencoder_2blocks_256d_200_samples/hidden_inference_ecg_mri_lax_4ch_diastole_paired_autoencoder_2blocks_256d_200_samples.tsv'\n",
    "\n",
    "\n",
    "df2 = pd.read_csv(hidden_inference, sep='\\t')\n",
    "df['fpath'] = pd.to_numeric(df['fpath'], errors='coerce')\n",
    "df2['sample_id'] = pd.to_numeric(df2['sample_id'], errors='coerce')\n",
    "#df.info()\n",
    "latent_df = pd.merge(df, df2, left_on='fpath', right_on='sample_id', how='inner')\n",
    "#latent_df.info()\n",
    "df3 = pd.read_csv('/home/sam/tsvs/ttn_disease.tsv', sep='\\t')\n",
    "df4 = pd.read_csv('/home/sam/csvs/has_exome.csv')\n",
    "latent_df = pd.merge(df3, latent_df, left_on='sample_id', right_on='sample_id', how='right')\n",
    "latent_df.info()\n",
    "print(latent_df['has_ttntv'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_on_matrix(matrix, pca_components):\n",
    "    pca = PCA()\n",
    "    pca.fit(matrix)\n",
    "    print(f'PCA explains {100*np.sum(pca.explained_variance_ratio_[:pca_components]):0.1f}% of variance with {pca_components} top PCA components.')\n",
    "    matrix_reduced = pca.transform(matrix)[:, :pca_components]\n",
    "    print(f'PCA reduces matrix shape:{matrix_reduced.shape} from matrix shape: {matrix.shape}')\n",
    "    plot_scree(pca_components, 100*pca.explained_variance_ratio_)\n",
    "    return pca, matrix_reduced\n",
    "\n",
    "def plot_scree(pca_components, percent_explained):\n",
    "    _ = plt.figure(figsize=(6, 4))\n",
    "    plt.plot(range(len(percent_explained)), percent_explained, 'g.-', linewidth=1)\n",
    "    plt.axvline(x=pca_components, c='r', linewidth=3)\n",
    "    label = f'{np.sum(percent_explained[:pca_components]):0.1f}% of variance explained by top {pca_components} of {len(percent_explained)} components'\n",
    "    plt.text(pca_components+0.02*len(percent_explained), percent_explained[1], label)\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('Principal Components')\n",
    "    plt.ylabel('% of Variance Explained by Each Component')\n",
    "    figure_path = f'./results/pca_{pca_components}_of_{len(percent_explained)}_testimonials.png'\n",
    "    if not os.path.exists(os.path.dirname(figure_path)):\n",
    "        os.makedirs(os.path.dirname(figure_path))\n",
    "    plt.savefig(figure_path)\n",
    "    \n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0)) * 180 / 3.141592\n",
    "\n",
    "def directions_in_latent_space(stratify_column, stratify_thresh, split_column, split_thresh, latent_cols, latent_df):\n",
    "    hit = latent_df.loc[latent_df[stratify_column] >= stratify_thresh][latent_cols].to_numpy()\n",
    "    miss = latent_df.loc[latent_df[stratify_column] < stratify_thresh][latent_cols].to_numpy()\n",
    "    miss_mean_vector = np.mean(miss, axis=0)\n",
    "    hit_mean_vector = np.mean(hit, axis=0)\n",
    "    strat_vector = hit_mean_vector - miss_mean_vector\n",
    "    \n",
    "    hit1 = latent_df.loc[(latent_df[stratify_column] >= stratify_thresh) \n",
    "                        & (latent_df[split_column] >= split_thresh)][latent_cols].to_numpy()\n",
    "    miss1 = latent_df.loc[(latent_df[stratify_column] < stratify_thresh) \n",
    "                        & (latent_df[split_column] >= split_thresh)][latent_cols].to_numpy()\n",
    "    hit2 = latent_df.loc[(latent_df[stratify_column] >= stratify_thresh) \n",
    "                        & (latent_df[split_column] < split_thresh)][latent_cols].to_numpy()\n",
    "    miss2 = latent_df.loc[(latent_df[stratify_column] < stratify_thresh) \n",
    "                        & (latent_df[split_column] < split_thresh)][latent_cols].to_numpy()\n",
    "    miss_mean_vector1 = np.mean(miss1, axis=0)\n",
    "    hit_mean_vector1 = np.mean(hit1, axis=0)\n",
    "    angle1 = angle_between(miss_mean_vector1, hit_mean_vector1)\n",
    "    miss_mean_vector2 = np.mean(miss2, axis=0)\n",
    "    hit_mean_vector2 = np.mean(hit2, axis=0)\n",
    "    angle2 = angle_between(miss_mean_vector2, hit_mean_vector2)\n",
    "    h1_vector = hit_mean_vector1-miss_mean_vector1\n",
    "    h2_vector = hit_mean_vector2-miss_mean_vector2\n",
    "    angle3 = angle_between(h1_vector, h2_vector)\n",
    "    angle4 = angle_between(strat_vector, h1_vector)\n",
    "    angle5 = angle_between(strat_vector, h2_vector)\n",
    "    print(f'\\n Between {stratify_column}, and splits: {split_column}\\n',\n",
    "          f'Angles h1 and m1: {angle1:.2f}, h2 and m2 {angle2:.2f} h1-m1 and h2-m2 {angle3:.2f} degrees.\\n'\n",
    "          f'stratify threshold: {stratify_thresh}, split thresh: {split_thresh}, \\n'\n",
    "          f'hit_mean_vector2 shape {miss_mean_vector1.shape}, miss1:{hit_mean_vector2.shape} \\n'\n",
    "          f'Hit1 shape {hit1.shape}, miss1:{miss1.shape} threshold:{stratify_thresh}\\n'\n",
    "          f'Hit2 shape {hit2.shape}, miss2:{miss2.shape}\\n')\n",
    "\n",
    "def stratify_latent_space(stratify_column, stratify_thresh, latent_cols, latent_df):\n",
    "    hit = latent_df.loc[latent_df[stratify_column] >= stratify_thresh][latent_cols].to_numpy()\n",
    "    miss = latent_df.loc[latent_df[stratify_column] < stratify_thresh][latent_cols].to_numpy()\n",
    "    miss_mean_vector = np.mean(miss, axis=0)\n",
    "    hit_mean_vector = np.mean(hit, axis=0)\n",
    "    angle = angle_between(miss_mean_vector, hit_mean_vector)\n",
    "    print(f'Angle between {stratify_column} centroid and all others is: {angle:.1f} degrees.\\n'\n",
    "          f'Hit shape {hit.shape}, miss:{miss.shape} threshold:{stratify_thresh}\\n'\n",
    "          f'Distance: {np.linalg.norm(hit_mean_vector-miss_mean_vector):.3f}, Hit std {np.std(hit, axis=1).mean():.3f}, miss std:{np.std(miss, axis=1).mean():.3f}\\n')\n",
    "    \n",
    "def plot_pcs(sides, color_key):\n",
    "    f, axes = plt.subplots(sides, sides, figsize=(16, 16))\n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        colors = latent_df[color_key].to_numpy()\n",
    "        points = ax.scatter(matrix_reduce[:, i], matrix_reduce[:, i+1], c=colors)\n",
    "        f.colorbar(points, ax=ax)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "pca, matrix_reduce = pca_on_matrix(df2[latent_cols].to_numpy(), 10)\n",
    "for strat in ['Sex_Female_0_0', 'has_ttntv', 'atrial_fibrillation_or_flutter', \n",
    "              'coronary_artery_disease', 'hypertension']:\n",
    "    stratify_latent_space(strat, 1.0, latent_cols, latent_df)\n",
    "strats = ['LVEF', 'LVM', 'LVEDV', 'sample_id',\n",
    "              '21001_Body-mass-index-BMI_0_0', '21003_Age-when-attended-assessment-centre_2_0']\n",
    "theshes = [45, 100, 150, 3500000, 27.5, 70]\n",
    "for strat, thresh in zip(strats, theshes):\n",
    "    stratify_latent_space(strat, thresh, latent_cols, latent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{256+i}' for i in range(latent_dimension)]\n",
    "pca, matrix_reduce = pca_on_matrix(df2[latent_cols].to_numpy(), 10)\n",
    "for strat in ['Sex_Female_0_0', 'has_ttntv', 'atrial_fibrillation_or_flutter', \n",
    "              'coronary_artery_disease', 'hypertension']:\n",
    "    stratify_latent_space(strat, 1.0, latent_cols, latent_df)\n",
    "strats = ['LVEF', 'LVM', 'LVEDV', 'sample_id',\n",
    "              '21001_Body-mass-index-BMI_0_0', '21003_Age-when-attended-assessment-centre_2_0']\n",
    "theshes = [45, 100, 150, 3500000, 27.5, 70]\n",
    "for strat, thresh in zip(strats, theshes):\n",
    "    stratify_latent_space(strat, thresh, latent_cols, latent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 512\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "pca, matrix_reduce = pca_on_matrix(df2[latent_cols].to_numpy(), 10)\n",
    "for strat in ['Sex_Female_0_0', 'atrial_fibrillation_or_flutter', \n",
    "              'coronary_artery_disease', 'hypertension']:\n",
    "    stratify_latent_space(strat, 1.0, latent_cols, latent_df)\n",
    "strats = ['LVEF', 'LVM', 'LVEDV', 'sample_id',\n",
    "              '21001_Body-mass-index-BMI_0_0', '21003_Age-when-attended-assessment-centre_2_0']\n",
    "theshes = [45, 100, 150, 3500000, 27.5, 70]\n",
    "for strat, thresh in zip(strats, theshes):\n",
    "    stratify_latent_space(strat, thresh, latent_cols, latent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{256+i}' for i in range(latent_dimension)]\n",
    "pca, matrix_reduce = pca_on_matrix(df2[latent_cols].to_numpy(), 10)\n",
    "c_strats = [ 'Sex_Female_0_0']\n",
    "for c_strat in c_strats:\n",
    "    strats = ['LVEF', 'LVM', 'LVEDV', 'sample_id',\n",
    "                  '21001_Body-mass-index-BMI_0_0', '21003_Age-when-attended-assessment-centre_2_0']\n",
    "    theshes = [50, 100, 150, 3750000, 27.5, 70]\n",
    "    for strat, thresh in zip(strats, theshes):\n",
    "        directions_in_latent_space(c_strat, 1.0, strat, thresh, latent_cols, latent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{256+i}' for i in range(latent_dimension)]\n",
    "pca, matrix_reduce = pca_on_matrix(df2[latent_cols].to_numpy(), 10)\n",
    "c_strats = [ 'sample_id']\n",
    "for c_strat in c_strats:\n",
    "    strats = ['LVEF', 'LVM', 'LVEDV', 'sample_id',\n",
    "                  '21001_Body-mass-index-BMI_0_0', '21003_Age-when-attended-assessment-centre_2_0']\n",
    "    theshes = [50, 100, 150, 3750000, 27.5, 70]\n",
    "    for strat, thresh in zip(strats, theshes):\n",
    "        directions_in_latent_space(c_strat, 3750000.0, strat, thresh, latent_cols, latent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "ecg_encode = latent_df[latent_cols].to_numpy()\n",
    "latent_cols = [f'latent_{256+i}' for i in range(latent_dimension)]\n",
    "mri_encode = latent_df[latent_cols].to_numpy()\n",
    "diff = np.sqrt(np.einsum('ij, ij->ij', ecg_encode - mri_encode, ecg_encode - mri_encode))\n",
    "print(diff.shape) \n",
    "print(np.mean(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{ecg_encode[:5,:5]} \\n{mri_encode[:5,:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "ecg_encode = latent_df[latent_cols].to_numpy()\n",
    "latent_cols = [f'latent_{18+i}' for i in range(latent_dimension)]\n",
    "mri_encode = latent_df[latent_cols].to_numpy()\n",
    "diff = np.sqrt(np.einsum('ij, ij->ij', ecg_encode - mri_encode, ecg_encode - mri_encode))\n",
    "print(diff.shape) \n",
    "print(np.mean(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2_random = np.random.random((4452, 256))\n",
    "ch3_random = np.random.random((4452, 256))\n",
    "diff = np.sqrt(np.einsum('ij, ij->ij', ch2_random - ch3_random, ch2_random - ch3_random))\n",
    "print(diff.shape) \n",
    "print(np.mean(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/sax-lax-40k-lvm/2020-01-29/', \n",
    "            '--input_tensors', 'ecg.ecg_rest', 'mri.lax_4ch_diastole_slice0_224_3d', \n",
    "            '--output_tensors', 'ecg.ecg_rest', 'mri.lax_4ch_diastole_slice0_224_3d',\n",
    "            '--activation', 'swish',\n",
    "            '--conv_layers', '32',\n",
    "            '--conv_x', '9', '9', '9',\n",
    "            '--conv_y', '3', '3', '3', \n",
    "            '--conv_z', '3', '3', '3', \n",
    "            '--dense_blocks', '32', '32', '32',\n",
    "            '--block_size', '3',\n",
    "            '--dense_layers', '256',\n",
    "            '--pool_x', '2',\n",
    "            '--pool_y', '2',\n",
    "            '--batch_size', '1',\n",
    "            '--patience', '44',\n",
    "            '--epochs', '532',\n",
    "            '--learning_rate', '0.0002',\n",
    "            '--training_steps', '72',\n",
    "            '--validation_steps', '30',\n",
    "            '--test_steps', '8',\n",
    "            '--num_workers', '4',\n",
    "            '--inspect_model',\n",
    "            '--tensormap_prefix', 'ml4h.tensormap.ukb',\n",
    "            '--hidden_layer', 'concatenate_36',\n",
    "            '--model_file', './recipes_output/ecg_mri_lax_4ch_diastole_paired_autoencoder_2blocks_256d_200_samples/ecg_mri_lax_4ch_diastole_paired_autoencoder_2blocks_256d_200_samples.h5',\n",
    "            '--train_csv', '/home/sam/lvh/small_set.csv',\n",
    "            #'--sample_csv', '/home/sam/lvh/lvh_hold_out.txt',\n",
    "            '--id', 'ecg_mri_lax_4ch_diastole_paired_autoencoder_2blocks_256d_200_samples']\n",
    "args = parse_args()\n",
    "\n",
    "#overparameterized_model = make_multimodal_multitask_model(**args.__dict__)\n",
    "#infer_hidden_layer_multimodal_multitask(args)\n",
    "#generate_train, generate_valid, generate_test = test_train_valid_tensor_generators(**args.__dict__)\n",
    "# train_model_from_generators(\n",
    "#         overparameterized_model, generate_train, generate_valid, args.training_steps, args.validation_steps, args.batch_size,\n",
    "#         args.epochs, args.patience, args.output_folder, args.id, args.inspect_model, args.inspect_show_labels,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
