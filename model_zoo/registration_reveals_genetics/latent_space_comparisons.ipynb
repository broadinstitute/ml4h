{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Ridge\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import brier_score_loss, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from ml4h.explorations import latent_space_dataframe\n",
    "\n",
    "# IPython imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = {}\n",
    "label_file = '/home/sam/trained_models/explore_phenotypes_3/tensors_all_union.csv'\n",
    "labels = pd.read_csv(label_file)\n",
    "phenotypes = [\n",
    "  'Sex_Male_0_0',\n",
    "  'sex',\n",
    "  'diabetes_type_2',\n",
    "  'hypercholesterolemia',\n",
    "  'hypertension',\n",
    "  'Atrial_fibrillation',\n",
    "    'age', 'bmi', 'bmi_0', 'RRInterval', \n",
    "    'LVM', 'LVEDV', 'LVESV', \n",
    "    'PC1', 'PC2', 'PC5',\n",
    "\n",
    "]\n",
    "\n",
    "col_rename = {f'22009_Genetic-principal-components_0_{i}': f'PC{i}' for i in range(1,41)}\n",
    "col_rename['Genetic-sex_Male_0_0'] = 'sex'\n",
    "col_rename['21003_Age-when-attended-assessment-centre_2_0'] = 'age'\n",
    "col_rename['21001_Body-mass-index-BMI_2_0'] = 'bmi'\n",
    "col_rename['21001_Body-mass-index-BMI_0_0'] = 'bmi_0'\n",
    "col_rename['2887_Number-of-cigarettes-previously-smoked-daily_0_0'] = 'smoking'\n",
    "col_rename['30690_Cholesterol_0_0'] = 'cholesterol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_files = {\n",
    "'Brain T1': '/home/sam/trained_models/brain_t1_slice_80_autoencoder_256d_v2022_06_07/hidden_axial_80_brain_t1_slice_80_autoencoder_256d_v2022_06_07.tsv',\n",
    "'Brain MNI': '/home/sam/trained_models/t1_mni_slices_48_80_autoencoder_256d/hidden_axial_68_100_t1_mni_slices_48_80_autoencoder_256d.tsv',\n",
    "}\n",
    "latent_size = {\n",
    "'Brain T1':256,\n",
    "'Brain MNI':256,\n",
    "}\n",
    "\n",
    "pairs = [\n",
    "    ('Brain MNI', 'Brain T1'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_files = {\n",
    "'DXA 12': '/home/sam/trained_models/dxa_12_autoencoder_256d/hidden_dxa_1_12_dxa_12_autoencoder_256d.tsv',\n",
    "'DXA 12 Homography': '/home/sam/trained_models/dxa_12_homography_autoencoder_512d/hidden_dxa_1_12_dxa_12_homography_autoencoder_512d.tsv',\n",
    "}\n",
    "latent_size = {\n",
    "'DXA 12':256,\n",
    "'DXA 12 Homography':512,\n",
    "}\n",
    "\n",
    "pairs = [\n",
    "    ('DXA 12 Homography', 'DXA 12'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_files = {\n",
    "'DXA 2 AE': '/home/sam/trained_models/dxa_2_autoencoder_256d/hidden_dxa_1_2_dxa_2_autoencoder_256d.tsv',\n",
    "'DXA 2 DF': '/home/sam/trained_models/dxa_2_5_dropfuse_256d/hidden_dxa_1_2_dxa_2_5_dropfuse_256d.tsv',\n",
    "'DXA 5 AE': '/home/sam/trained_models/dxa_5_autoencoder_256d/hidden_dxa_1_5_dxa_5_autoencoder_256d.tsv',\n",
    "'DXA 5 DF': '/home/sam/trained_models/dxa_2_5_dropfuse_256d/hidden_dxa_1_5_dxa_2_5_dropfuse_256d.tsv',\n",
    "}\n",
    "latent_size = {\n",
    "'DXA 2 AE':256,\n",
    "'DXA 2 DF':256,\n",
    "'DXA 5 AE':256,\n",
    "'DXA 5 DF':256,  \n",
    "}\n",
    "\n",
    "pairs = [\n",
    "    ('DXA 2 DF','DXA 2 AE'),\n",
    "    ('DXA 5 DF','DXA 5 AE'),\n",
    "]\n",
    "\n",
    "# latent_files = {\n",
    "# 'cMRI Dense AE': '/home/sam/csvs/dense_autoencoder_1_sample_cmri_inferences.tsv',\n",
    "# 'cMRI Circular AE': '/home/sam/csvs/circular_autoencoder_lax_4ch_v2023_04_28.tsv',\n",
    "# 'ECG 10s': '/home/sam/trained_models/ecg_rest_autoencoder_256d_v2023_05_09/hidden_strip_ecg_rest_autoencoder_256d_v2023_05_09.tsv',\n",
    "# 'ECG Median': '/home/sam/trained_models/hypertuned_48m_16e_ecg_median_raw_10_autoencoder_256d/hidden_embed_hypertuned_48m_16e_ecg_median_raw_10_autoencoder_256d.tsv',\n",
    "# 'cMRI AE':'/home/sam/trained_models/hypertuned_32m_8e_lax_4ch_heart_center_autoencoder_256d/hidden_lax_4ch_heart_center_hypertuned_32m_8e_lax_4ch_heart_center_autoencoder_256d.tsv',    \n",
    "# 'cMRI ECG DropFuse': '/home/sam/trained_models/dropout_pair_contrastive_lax_4ch_cycle_ecg_median_10_pretrained_256d_v2020_06_07/hidden_lax_4ch_heart_center_dropout_pair_contrastive_lax_4ch_cycle_ecg_median_10_pretrained_256d_v2020_06_07.tsv',\n",
    "# 'ECG cMRI DropFuse': '/home/sam/trained_models/dropout_pair_contrastive_lax_4ch_cycle_ecg_median_10_pretrained_256d_v2020_06_07/hidden_ecg_rest_median_raw_10_dropout_pair_contrastive_lax_4ch_cycle_ecg_median_10_pretrained_256d_v2020_06_07.tsv',\n",
    "  \n",
    "# }\n",
    "# latent_size = {\n",
    "# 'cMRI Dense AE': 50,\n",
    "# 'cMRI Circular AE': 50,\n",
    "\n",
    "#    'ECG 10s': 256,\n",
    "#    'ECG Median': 256,\n",
    "#     'cMRI AE':256,\n",
    "#     'cMRI ECG DropFuse':256,\n",
    "#     'ECG cMRI DropFuse':256,\n",
    "    \n",
    "# }\n",
    "# pairs = [\n",
    "#     ('cMRI Circular AE','cMRI Dense AE'),\n",
    "#     ('ECG Median','ECG 10s'),\n",
    "#         ('cMRI ECG DropFuse','cMRI AE'),\n",
    "#         ('ECG cMRI DropFuse','cMRI AE'),\n",
    "    \n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic(label_header, train, test, indexes, verbose=False):\n",
    "    if verbose:\n",
    "        print(f'{label_header} len train {len(train)} len test {len(test)}')\n",
    "        print(f'\\nTrain:\\n{train[label_header].value_counts()} \\n\\nTest:\\n{test[label_header].value_counts()}')\n",
    "    clf = LogisticRegression(penalty='elasticnet', solver='saga', class_weight='balanced', l1_ratio=0.5)\n",
    "    clf.fit(train[indexes], train[label_header])\n",
    "    \n",
    "    sparsity = np.mean(clf.coef_ == 0) * 100\n",
    "    score = clf.score(test[indexes], test[label_header])\n",
    "    train_score = clf.score(train[indexes], train[label_header])\n",
    "    auc_score = roc_auc_score(clf.predict(test[indexes]), test[label_header])\n",
    "    train_auc_score = roc_auc_score(clf.predict(train[indexes]), train[label_header])\n",
    "    if verbose:\n",
    "        print(f'{label_header} AUC:{auc_score:.3f}  Train AUC:{train_auc_score:.3f}, Sparsity: {sparsity:.2f}\\n')\n",
    "    return auc_score\n",
    "\n",
    "def fit_linear(label_header, train, test, indexes, verbose=False):\n",
    "    if verbose:\n",
    "        print(f'{label_header} len train {len(train)} len test {len(test)}')\n",
    "        print(f'\\nTrain:\\n{len(train[label_header].value_counts())} \\n\\nTest:\\n{len(test[label_header].value_counts())}')\n",
    "    \n",
    "    clf = make_pipeline(StandardScaler(with_mean=True), Ridge(solver='lsqr', max_iter=250000))\n",
    "    clf.fit(train[indexes], train[label_header])\n",
    "\n",
    "    score = clf.score(test[indexes], test[label_header])\n",
    "    train_score = clf.score(train[indexes], train[label_header])\n",
    "    if verbose:\n",
    "        print(f'{label_header} R^2:{score:.3f}  Train R^2:{train_score:.3f}\\n')\n",
    "    return score\n",
    "\n",
    "def latent_space_regression(label_file, latent_file, num_features = 256, start_features=0, train_ratio = 0.6, folds=4, verbose=False):\n",
    "    labels = pd.read_csv(label_file)\n",
    "    if latent_file.split('.')[-1].lower() == 'csv':\n",
    "        indexes = [f'{i}' for i in range(start_features, num_features)]\n",
    "        latent = pd.read_csv(latent_file)\n",
    "    else:\n",
    "        indexes = [f'latent_{i}' for i in range(start_features, num_features)]\n",
    "        latent = pd.read_csv(latent_file, sep='\\t')\n",
    "    \n",
    "    df = pd.merge(labels, latent, left_on='fpath', right_on='sample_id', how='inner')\n",
    "    df = df.rename(columns=col_rename)\n",
    "    scores = {}\n",
    "    errors = {}\n",
    "    for label in phenotypes if len(phenotypes) else labels.columns:\n",
    "        try:\n",
    "            full = df[df[label].notna()]\n",
    "            if len(full[label].value_counts()) > 2:\n",
    "                s = []\n",
    "                for _ in range(folds):\n",
    "                    train = full.sample(frac=train_ratio)\n",
    "                    test = full.drop(train.index)\n",
    "                    s.append(fit_linear(label, train, test, indexes, verbose))\n",
    "                scores[f'{label} R^2'] = np.mean(s)\n",
    "                errors[f'{label} R^2'] = 2*np.std(s)\n",
    "            else:\n",
    "                s = []\n",
    "                for _ in range(folds):\n",
    "                    train = full.sample(frac=train_ratio)\n",
    "                    test = full.drop(train.index)\n",
    "                    s.append(fit_logistic(label, train, test, indexes, verbose))\n",
    "                scores[f'{label} AUC'] = np.mean(s)\n",
    "                errors[f'{label} AUC'] = 2*np.std(s) \n",
    "        except Exception as e:\n",
    "            print(f'Could not fit LR for {label} {e}')\n",
    "    \n",
    "    for k,v in sorted(scores.items(), key=lambda x: x[0].lower()):\n",
    "        print(f'{k} {v:.3f}')\n",
    "\n",
    "    return scores, errors\n",
    "\n",
    "\n",
    "def plot_nested_dictionary(all_scores):\n",
    "    n = 4\n",
    "    chack = ['tab:orange', 'tab:blue', 'tab:green']\n",
    "    for model in all_scores:\n",
    "        n = max(n, len(all_scores[model][0]))\n",
    "    cols = max(2, int(math.ceil(math.sqrt(n))))\n",
    "    rows = max(2, int(math.ceil(n / cols)))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 2.5), dpi=300)\n",
    "    renest = defaultdict(dict)\n",
    "    errors = defaultdict(dict)\n",
    "    for model in all_scores:\n",
    "        for metric in all_scores[model][0]:\n",
    "            renest[metric][model] = all_scores[model][0][metric]\n",
    "            errors[metric][model] = all_scores[model][1][metric]\n",
    "    for metric, ax in zip(renest, axes.ravel()):\n",
    "        models = [k for k,v in sorted(renest[metric].items(), key=lambda x: x[0].lower())]\n",
    "        values = [v for k,v in sorted(renest[metric].items(), key=lambda x: x[0].lower())]\n",
    "        err = [v for k,v in sorted(errors[metric].items(), key=lambda x: x[0].lower())]\n",
    "        y_pos = np.arange(len(models))\n",
    "        #print(f' {len(renest[metric])} len(models) : {len(models)} metric  {renest[metric]}')\n",
    "        ax.barh(y_pos, values, xerr=err, align='center')\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(models)\n",
    "        ax.invert_yaxis()  # labels read top-to-bottom\n",
    "        if 'AUC' in metric:\n",
    "            ax.set_xlabel('AUROC')\n",
    "        else:\n",
    "            ax.set_xlabel('$R^2$')\n",
    "            \n",
    "        ax.barh(y_pos, values, xerr=err, align='center', color=colors.TABLEAU_COLORS)\n",
    "#         if len(metric.split('_')) > 1:\n",
    "#             metric = metric.split('_')[1] + metric[-4:]\n",
    "#         ax.set_title(metric.replace('R^2', '$R^2$'))\n",
    "        if '21001_Body-mass-index-BMI_0_0' in metric:\n",
    "            ax.set_title('BMI')\n",
    "        elif '21003_Age-when-attended-assessment-centre_2_0' in metric:\n",
    "            ax.set_title('Age')\n",
    "        elif 'Sex_Male_0_0' in metric:\n",
    "            ax.set_title('Sex')\n",
    "        else:\n",
    "            ax.set_title(metric.split(' ')[0]) \n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in latent_files:\n",
    "    all_scores[name] = latent_space_regression(label_file, latent_files[name], \n",
    "                                               num_features=latent_size[name],\n",
    "                                               folds=3, train_ratio=0.8,\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_pairs(scores, pairs):\n",
    "    for (p1,p2) in pairs:\n",
    "        s1 = scores[p1]\n",
    "        s2 = scores[p2]\n",
    "        stats = Counter()\n",
    "        print(f'comparing {p1} to {p2}' )\n",
    "        for k in s2[0]:\n",
    "            print(f'\\t{k} {s1[0][k]:0.3f}, {s2[0][k]:0.3f},  Diff: {(s1[0][k] - s2[0][k]):0.3f} ')\n",
    "            if 'R^2' in k:\n",
    "                stats[f'{p1} R^2 sum'] += s1[0][k]\n",
    "                stats[f'{p2} R^2 sum'] += s2[0][k]\n",
    "                stats[f'{p1} R^2 std'] += s1[1][k]\n",
    "                stats[f'{p2} R^2 std'] += s2[1][k]\n",
    "                stats['R^2 n'] += 1\n",
    "            elif 'AUC' in k:\n",
    "                stats[f'{p1} AUC sum'] += s1[0][k]\n",
    "                stats[f'{p2} AUC sum'] += s2[0][k]\n",
    "                stats[f'{p1} AUC std'] += s1[1][k]\n",
    "                stats[f'{p2} AUC std'] += s2[1][k]\n",
    "                stats['AUC n'] += 1\n",
    "        auc1 = stats[f'{p1} AUC sum']/stats['AUC n'] \n",
    "        auc_std1 = stats[f'{p1} AUC std']/(stats['AUC n'] )\n",
    "        auc2 = stats[f'{p2} AUC sum']/stats['AUC n']\n",
    "        auc_std2 = stats[f'{p2} AUC std']/(stats['AUC n'] ) \n",
    "        r21 = stats[f'{p1} R^2 sum']/stats['R^2 n']\n",
    "        r2_std1 = stats[f'{p1} R^2 std']/(stats['R^2 n'] )\n",
    "        r22 = stats[f'{p2} R^2 sum']/stats['R^2 n']\n",
    "        r2_std2 = stats[f'{p2} R^2 std']/(stats['R^2 n'] )\n",
    "        print(f\"\\n {p1} vs {p2} \")\n",
    "        print(f\"\\t\\t Mean AUCs {auc1:0.3f} ({auc1-auc_std1:0.3f}, {auc1+auc_std1:0.3f}), {auc2:0.3f} ({auc2-auc_std2:0.3f}, {auc2+auc_std2:0.3f}) \")\n",
    "        print(f\" \\t\\t Mean R^2 {r21:0.3f} ({r21-r2_std1:0.3f}, {r21+r2_std1:0.3f}),  {r22:0.3f} ({r22-r2_std2:0.3f}, {r22+r2_std2:0.3f}) \\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pairs(all_scores, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf='/home/sam/trained_models/dxa_5_autoencoder_256d/hidden_dxa_1_5_dxa_5_autoencoder_256d.tsv'\n",
    "all_scores['DXA 5 AE'] = latent_space_regression(label_file, lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf='/home/sam/trained_models/dxa_2_5_dropfuse_256d/hidden_dxa_1_5_dxa_2_5_dropfuse_256d.tsv'\n",
    "all_scores['DXA 5 DF'] = latent_space_regression(label_file, lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf='/home/sam/trained_models/dxa_11_autoencoder_256d/hidden_dxa_1_11_dxa_11_autoencoder_256d.tsv'\n",
    "all_scores['DXA 11 AE'] = latent_space_regression(label_file, lf)\n",
    "lf='/home/sam/trained_models/dxa_11_12_dropfuse_256d_v2023_04_17/hidden_dxa_1_11_dxa_11_12_dropfuse_256d_v2023_04_17.tsv'\n",
    "all_scores['DXA 11 DF'] = latent_space_regression(label_file, lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf=f'/home/sam/trained_models/hypertuned_64m_18e_lax_4ch_heart_center_autoencoder_256d/hidden_embed_hypertuned_64m_18e_lax_4ch_heart_center_autoencoder_256d.tsv'\n",
    "all_scores['MRI Autoencoder 256D'] = latent_space_regression(label_file, lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = f'/home/sam/csvs/03-11-2021_simclr_320-320_ukb_embeddings.csv'\n",
    "all_scores['ECG PCLR 320D'] = latent_space_regression(label_file, lf, num_features=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nested_dictionary(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
