{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Ridge\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import brier_score_loss, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Ridge\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from ml4h.explorations import latent_space_dataframe\n",
    "\n",
    "# IPython imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_phecode_file(latent_df, phecode_file, phecode_name, min_cases):\n",
    "    df = pd.read_csv(phecode_file, sep='\\t')\n",
    "    if df.has_disease.sum() > min_cases:\n",
    "        df = df.rename(columns={\"has_disease\": phecode_name})\n",
    "        new_df = pd.merge(latent_df, df, left_on='fpath', right_on='sample_id', how='inner')\n",
    "        if len(new_df[phecode_name].value_counts()) > 1 and new_df[phecode_name].value_counts()[1] > min_cases:\n",
    "            return new_df\n",
    "        else:\n",
    "            return latent_df\n",
    "    else:\n",
    "        return latent_df\n",
    "\n",
    "\n",
    "def merge_code_folder(latent_df, phe_folder='/home/sam/select_phecodes/', min_cases=4, max_codes=35):\n",
    "    phe_codes = []\n",
    "    for phe_file in sorted(os.listdir(phe_folder)):\n",
    "        phe_code = phe_file.replace('.txt', '')\n",
    "        print(f'try phecode: {phe_code}')\n",
    "        latent_df = merge_phecode_file(latent_df, phe_folder + phe_file, phe_code, min_cases)\n",
    "        if phe_code in latent_df:\n",
    "            print(f'{phe_code} has enough prevalence: {latent_df[phe_code].value_counts()[1]}')\n",
    "            phe_codes.append(phe_code)\n",
    "            if len(phe_codes) >= max_codes:\n",
    "                break\n",
    "    return latent_df, phe_codes\n",
    "\n",
    "def ttest_feature(feature, snp):\n",
    "    ref = latent_df[latent_df[snp] == 0][feature].dropna().to_numpy(dtype=np.float32)\n",
    "    het = latent_df[latent_df[snp] == 1][feature].dropna().to_numpy(dtype=np.float32)\n",
    "    hom = latent_df[latent_df[snp] == 2][feature].dropna().to_numpy(dtype=np.float32)\n",
    "    var = latent_df[(latent_df[snp] == 1) | (latent_df[snp] == 2)][feature].dropna().to_numpy(dtype=np.float32)\n",
    "    t2, p2 = stats.ttest_ind(var, ref, equal_var = False)\n",
    "    print(f\"Reference n={len(ref)}, Heterozygous n={len(het)}, Homozygous n={len(hom)}, Non-reference n={len(var)}\")\n",
    "    t_het_ref, p_het_ref = stats.ttest_ind(het, ref, equal_var = False)\n",
    "    print(f\"Ref v Het {feature}:\\t\\t T-Statistic = {t_het_ref:0.2f}, P-Value = {p_het_ref}\")\n",
    "    t_hom_ref, p_hom_ref = stats.ttest_ind(hom, ref, equal_var = False)\n",
    "    print(f\"Ref v Hom {feature}:\\t\\t T-Statistic = {t_hom_ref:0.2f}, P-Value = {p_hom_ref}\")\n",
    "    t_var_ref, p_var_ref = stats.ttest_ind(var, ref, equal_var = False)\n",
    "    print(f\"Ref v Var {feature}:\\t\\t T-Statistic = {t_var_ref:0.2f}, P-Value = {p_var_ref}\\n\")\n",
    "    return {#'T-test REF vs HET '+snp: (t_het_ref, p_het_ref), \n",
    "            #'T-test REF vs HOM '+snp: (t_hom_ref, p_hom_ref),\n",
    "            'T-test REF vs VAR '+snp: (t_var_ref, p_var_ref)}\n",
    "    \n",
    "def plot_nested_dictionary(all_scores):\n",
    "    n = 4\n",
    "    eps = 1e-300\n",
    "    for model in all_scores:\n",
    "        n = max(n, len(all_scores[model]))\n",
    "    cols = max(2, int(math.ceil(math.sqrt(n))))\n",
    "    rows = max(2, int(math.ceil(n / cols)))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 3), sharex=True)\n",
    "    renest = defaultdict(dict)\n",
    "    errors = defaultdict(dict)\n",
    "    lens = {}\n",
    "    max_tstat = 0\n",
    "    max_pval = 0\n",
    "    for model in all_scores:\n",
    "        for metric in all_scores[model]:\n",
    "            renest[metric][model] = all_scores[model][metric][0]\n",
    "            errors[metric][model] = all_scores[model][metric][1]\n",
    "            lens[metric] = all_scores[model][metric][2]\n",
    "            max_tstat = max(abs(all_scores[model][metric][0]), max_tstat)\n",
    "            max_pval = max(-np.log10(all_scores[model][metric][1]+eps), max_pval)\n",
    "    for metric, ax in zip(renest, axes.ravel()):\n",
    "         \n",
    "        models = [k for k,v in sorted(renest[metric].items(), key=lambda x: x[0].lower())]\n",
    "        tstats = [abs(v) for k,v in sorted(renest[metric].items(), key=lambda x: x[0].lower())]\n",
    "        pvalues = [-np.log10(v) if v > 1e-4800 else 500 for k,v in sorted(errors[metric].items(), key=lambda x: x[0].lower())]\n",
    "        y_pos = np.arange(len(models))\n",
    "        x = np.linspace(0, 1, int(max_pval))\n",
    "        plt.imshow(x[:, np.newaxis], cmap=cm.jet)\n",
    "        cb = plt.colorbar(ax=ax, ticks=[0, 1.0])\n",
    "        cb.set_label('Negative Log P-Value')\n",
    "        cb.ax.set_yticklabels(['0', f'{max_pval:0.0f}'])\n",
    "        ax.barh(y_pos, tstats, color=[cm.jet(p/max_pval) for p in pvalues], align='center')\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(models)\n",
    "        ax.invert_yaxis()  # labels read top-to-bottom\n",
    "        ax.set_xlabel('Tâ€“Statistic')\n",
    "        ax.xaxis.set_tick_params(which='both', labelbottom=True)\n",
    "        ax.set_title(f'{metric}\\n n={lens[metric]}')\n",
    "            \n",
    "    plt.tight_layout()    \n",
    "    \n",
    "\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "            angle_between((1, 0, 0), (0, 1, 0))\n",
    "            90\n",
    "            angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            180\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0)) * 180 / 3.141592\n",
    "\n",
    "def get_phenotype_vector(stratify_column, stratify_thresh, stratify_std, latent_cols, latent_df):\n",
    "    hit = latent_df.loc[latent_df[stratify_column] >= stratify_thresh+stratify_std][latent_cols].to_numpy()\n",
    "    miss = latent_df.loc[latent_df[stratify_column] < stratify_thresh-stratify_std][latent_cols].to_numpy()\n",
    "    miss_mean_vector = np.mean(miss, axis=0)\n",
    "    hit_mean_vector = np.mean(hit, axis=0)\n",
    "    angle = angle_between(miss_mean_vector, hit_mean_vector)\n",
    "#     print(f'Angle between {stratify_column} and all others: {angle}, \\n'\n",
    "#           f'Hit shape {hit.shape}, miss:{miss.shape} threshold:{stratify_thresh}\\n'\n",
    "#           f'Distance: {np.linalg.norm(hit_mean_vector - miss_mean_vector):.3f}, '\n",
    "#           f'Hit std {np.std(hit, axis=1).mean():.3f}, miss std:{np.std(miss, axis=1).mean():.3f}\\n')\n",
    "    return hit_mean_vector - miss_mean_vector    \n",
    "\n",
    "def check_snp_angles(snps, stratify_column, stratify_thresh, stratify_std, latent_cols, latent_df):\n",
    "    pheno_vec = get_phenotype_vector(stratify_column, stratify_thresh, stratify_std, latent_cols, latent_df)\n",
    "    sum_angles = 0\n",
    "    for snp in snps:\n",
    "        snp_vec = get_phenotype_vector(snp, 1, 0, latent_cols, latent_df)\n",
    "        angle = angle_between(pheno_vec, snp_vec)\n",
    "        sum_angles += abs(90-angle)\n",
    "        print(f'Phenotype vector: {stratify_column} SNP:{snp} angle:{angle:0.1f}')\n",
    "    print(f'{stratify_column} Average Difference from perpendicular: {sum_angles/len(snps):0.1f}\\n')\n",
    "    \n",
    "    \n",
    "def stratify_and_project_latent_space(stratify_column, stratify_thresh, stratify_std, \n",
    "                                      latent_cols, adjust_cols, latent_df, test_df, component_folder,\n",
    "                                      manova=False, permute=False, save_components=False, histograms=False):   \n",
    "    hit = latent_df.loc[latent_df[stratify_column] >= stratify_thresh+(1*stratify_std)]\n",
    "    miss = latent_df.loc[latent_df[stratify_column] < stratify_thresh-(1*stratify_std)]\n",
    "    hit_np = hit[latent_cols].to_numpy()\n",
    "    miss_np = miss[latent_cols].to_numpy()\n",
    "    miss_mean_vector = np.mean(miss_np, axis=0)\n",
    "    hit_mean_vector = np.mean(hit_np, axis=0)\n",
    "    angle = angle_between(miss_mean_vector, hit_mean_vector)\n",
    "    space = test_df[latent_cols].to_numpy()\n",
    "    space -= np.mean(space)\n",
    "    space /= np.std(space)\n",
    "    phenotype_vector = unit_vector(hit_mean_vector-miss_mean_vector)\n",
    "    all_dots = np.array([np.dot(phenotype_vector, v) for v in space])\n",
    "    all_phecodes = test_df[stratify_column].to_numpy()\n",
    "    if permute:\n",
    "        all_phecodes = np.random.permutation(all_phecodes)\n",
    "    if len(adjust_cols) > 0:\n",
    "        all_adjustments = test_df[adjust_cols].to_numpy()\n",
    "        all_data = np.column_stack([all_phecodes, all_adjustments, np.ones(all_dots.shape[0])])\n",
    "        formula = f'phecode ~ {\" + \".join(adjust_cols)} + component'\n",
    "    else:\n",
    "        all_data = np.column_stack([all_phecodes, np.ones(all_dots.shape[0])])\n",
    "        formula = f'phecode ~ component'\n",
    "    \n",
    "    data = {'component': all_dots, 'phecode': all_phecodes}\n",
    "    for i, col in enumerate(adjust_cols):\n",
    "        data[col] = all_adjustments[:, i]\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    try:\n",
    "        results = smf.logit(formula, data=df).fit(disp=False)\n",
    "        stat_key = 'z'\n",
    "        smf_ols_p_value = float(results.summary2().tables[1][f'P>|{stat_key}|']['component'])\n",
    "        smf_ols_t_stat = float(results.summary2().tables[1][f'{stat_key}']['component'])\n",
    "        if save_components:\n",
    "            test_df['component'] = all_dots\n",
    "            os.makedirs(os.path.dirname(component_folder), exist_ok=True)\n",
    "            tsv = f'{component_folder}/{stratify_column}_component.tsv'\n",
    "            test_df.to_csv(tsv, index=False, sep='\\t')\n",
    "        return results.summary2().tables[1]\n",
    "    except np.linalg.LinAlgError as e:\n",
    "        print(f'Phecode {stratify_column} Failed')\n",
    "        return None\n",
    "\n",
    "    \n",
    "def phewas_feature(stratify_column, stratify_thresh, stratify_std, feature_col, \n",
    "                   adjust_cols, latent_df, test_df, component_folder):   \n",
    "    hit = latent_df.loc[latent_df[stratify_column] >= stratify_thresh+(1*stratify_std)]\n",
    "    miss = latent_df.loc[latent_df[stratify_column] < stratify_thresh-(1*stratify_std)]\n",
    "    all_dots = test_df[feature_col].to_numpy()\n",
    "    all_phecodes = test_df[stratify_column].to_numpy()\n",
    "\n",
    "    if len(adjust_cols) > 0:\n",
    "        all_adjustments = test_df[adjust_cols].to_numpy()\n",
    "        formula = f'phecode ~ {\" + \".join(adjust_cols)} + component' \n",
    "    else:\n",
    "        formula = f'phecode ~ component'\n",
    "    \n",
    "    data = {'component': all_dots, 'phecode': all_phecodes}\n",
    "    for i, col in enumerate(adjust_cols):\n",
    "        data[col] = all_adjustments[:, i]\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    try:\n",
    "        results = smf.logit(formula, data=df).fit(disp=False)\n",
    "        stat_key = 'z'\n",
    "        smf_ols_p_value = float(results.summary2().tables[1][f'P>|{stat_key}|']['component'])\n",
    "        smf_ols_t_stat = float(results.summary2().tables[1][f'{stat_key}']['component'])\n",
    "        return results.summary2().tables[1]\n",
    "    except np.linalg.LinAlgError as e:\n",
    "        print(f'Phecode {stratify_column} Failed')\n",
    "        return None    \n",
    "    \n",
    "    \n",
    "def merge_and_stratify_phecode_file(latent_df, test_df, latent_cols, adjust_cols, \n",
    "                                    phecode_file, test_phecode_file, min_cases, \n",
    "                                    component_folder, permute=False):\n",
    "    \n",
    "    if 'phecode' not in phecode_file:\n",
    "        print(f'No phecode {phecode_file}')\n",
    "        return\n",
    "    df = pd.read_csv(phecode_file, sep='\\t')\n",
    "    phecode_name = df.iloc[0].disease\n",
    "    if df.has_disease.sum() > min_cases:\n",
    "        df = df.rename(columns={'has_disease': phecode_name})\n",
    "        latent_df = pd.merge(latent_df, df, left_on='sample_id', right_on='sample_id', how='inner')     \n",
    "        test_df = pd.merge(test_df, df, left_on='sample_id', right_on='sample_id', how='inner')\n",
    "        if len(latent_df[phecode_name].value_counts()) > 1 and latent_df[phecode_name].value_counts()[1] > min_cases:\n",
    "            if len(latent_cols) == 1:\n",
    "                results = phewas_feature(phecode_name, 1, 0, latent_cols[0], adjust_cols, \n",
    "                                         latent_df, test_df, component_folder)\n",
    "            else:\n",
    "                results = stratify_and_project_latent_space(phecode_name, 1, 0, latent_cols, adjust_cols, \n",
    "                                              latent_df, test_df, component_folder, permute=permute,\n",
    "                                              save_components=False, histograms=False)\n",
    "            \n",
    "            return results, phecode_name\n",
    "               \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "def merge_and_stratify_by_code_folder(latent_df, test_df, latent_cols, adjust_cols, component_folder,\n",
    "                                      phe_folder='./phecodes/', test_phe_folder='./phecodes/', \n",
    "                                      min_cases=20, permute=False):\n",
    "    counts = {}\n",
    "    p_vals = {}\n",
    "    betas = {}\n",
    "    ses = {}\n",
    "\n",
    "    for phe_file in sorted(os.listdir(phe_folder)):\n",
    "        p = merge_and_stratify_phecode_file(latent_df, test_df, latent_cols, adjust_cols, \n",
    "                                            phe_folder + phe_file, test_phe_folder + phe_file, \n",
    "                                            min_cases, component_folder, permute)\n",
    "        if p is not None:\n",
    "            results, name = p\n",
    "            if results is not None:\n",
    "                pdf = pd.read_csv(test_phe_folder + phe_file, sep='\\t')\n",
    "                counts[name] = pdf.has_disease.sum()\n",
    "                p_vals[name] = results['P>|z|']['component']\n",
    "                betas[name] = results['Coef.']['component']\n",
    "                ses[name] = results['Std.Err.']['component']\n",
    "                print(f'Phecode: {p[1]}, Pvalue: {p_vals[name]}')\n",
    "    return p_vals, betas, ses, counts\n",
    "    \n",
    "   \n",
    "def project_latent_space_on_phecode(stratify_column, stratify_thresh, stratify_std, \n",
    "                                      latent_cols, adjust_cols, phenotype_vector, test_df, component_folder,\n",
    "                                      permute=False, save_components=False, histograms=False):\n",
    "    \n",
    "    space = test_df[latent_cols].to_numpy()\n",
    "    space -= np.mean(space)\n",
    "    space /= np.std(space)\n",
    "    all_dots = np.array([np.dot(phenotype_vector, v) for v in space])\n",
    "    all_phenotypes = test_df[stratify_column].to_numpy()\n",
    "    if permute:\n",
    "        all_phenotypes = np.random.permutation(all_phenotypes)\n",
    "    if len(adjust_cols) > 0:\n",
    "        all_adjustments = test_df[adjust_cols].to_numpy()\n",
    "        all_data = np.column_stack([all_phenotypes, all_adjustments, np.ones(all_dots.shape[0])])\n",
    "        formula = f'phecode ~ {\" + \".join(adjust_cols)} + component'\n",
    "        adjust_formula = f'phecode ~ {\" + \".join(adjust_cols)}'\n",
    "    else:\n",
    "        all_data = np.column_stack([all_phenotypes, np.ones(all_dots.shape[0])])\n",
    "        formula = f'phecode ~ component'\n",
    "    \n",
    "    data = {'component': all_dots, 'phecode': all_phenotypes}\n",
    "    for i, col in enumerate(adjust_cols):\n",
    "        data[col] = all_adjustments[:, i]\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    if save_components:\n",
    "        test_df['component'] = all_dots\n",
    "        os.makedirs(os.path.dirname(component_folder), exist_ok=True)\n",
    "        tsv = f'{component_folder}/{stratify_column}_component.tsv'\n",
    "        test_df.to_csv(tsv, index=False, sep='\\t')\n",
    "    try:\n",
    "        results = smf.logit(formula, data=df).fit(disp=False)\n",
    "        \n",
    "        preds = results.predict(df)\n",
    "        results2 = smf.logit(adjust_formula, data=df).fit(maxiter=200, disp=False)\n",
    "        preds2 = results2.predict(df)\n",
    "        auc_w_component = roc_auc_score(all_phenotypes, preds)\n",
    "        auc_no_component = roc_auc_score(all_phenotypes, preds2)        \n",
    "        if histograms: # and -np.log10(results.summary2().tables[1]['P>|z|']['component']) > 10:\n",
    "            hit_dots = all_dots[all_phenotypes == 1]\n",
    "            miss_dots = all_dots[all_phenotypes == 0]\n",
    "            dists = [list(hit_dots), list(miss_dots)]\n",
    "            labels = [f'{stratify_column} n={len(hit_dots)}', f'No {stratify_column} n={len(miss_dots)}']\n",
    "            for i, data in enumerate(dists):\n",
    "                #plt.hist(data, bins = 40, label=labels[i], alpha=0.5, density=True)\n",
    "                sb.kdeplot(np.array(data), bw=0.5)\n",
    "                # Title and labels\n",
    "#                 plt.title(f'{stratify_column}')\n",
    "#                 plt.xlabel(f'Component in direction of {stratify_column} vector')\n",
    "#                 plt.ylabel('Density')\n",
    "#             plt.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        return results.summary2().tables[1], auc_w_component, auc_no_component\n",
    "    except np.linalg.LinAlgError as e:\n",
    "        print(f'Phecode {stratify_column} Failed')\n",
    "        return None, None, None\n",
    "    \n",
    "\n",
    "def stratify_phecode_file_on_phecode(phenotype_vectors, test_df, latent_cols, adjust_cols, \n",
    "                                    test_phecode_file, min_cases, \n",
    "                                    component_folder, permute, histograms):\n",
    "    \n",
    "    if 'phecode' not in test_phecode_file:\n",
    "        return None, None, None, None\n",
    "    df = pd.read_csv(test_phecode_file, sep='\\t')\n",
    "    phecode_name = df.iloc[0].disease\n",
    "    phekey = phecode_name.replace('phecode', 'phe')\n",
    "    #print(f'PHEHEHE {phekey}')\n",
    "    row = phenotype_vectors[phenotype_vectors.phecode_text == phekey]\n",
    "\n",
    "    if len(row) > 0 and df.has_disease.sum() > min_cases:\n",
    "        df = df.rename(columns={'has_disease': phecode_name})\n",
    "        test_df = pd.merge(test_df, df, left_on='sample_id', right_on='sample_id', how='inner')\n",
    "        cols = [f'pv_{i}' for i in range(len(latent_cols))]\n",
    "        phenotype_vector = row[cols].to_numpy()[0, :]\n",
    "        #print(f'PHEHEHE {phekey} {len(row)} phenotype_vector {phenotype_vector.shape} ' )\n",
    "        if len(test_df[phecode_name].value_counts()) > 1 and test_df[phecode_name].value_counts()[1] > min_cases:\n",
    "            results, a1, a2 = project_latent_space_on_phecode(phecode_name, 1, 0, latent_cols, adjust_cols, \n",
    "                                                      phenotype_vector, test_df, component_folder, \n",
    "                                                      permute=permute, save_components=False, histograms=histograms)\n",
    "            return results, phecode_name, a1, a2\n",
    "    return None, None, None, None      \n",
    "\n",
    "def stratify_code_folder_on_phecode(phenotype_vectors, test_df, latent_cols, adjust_cols, component_folder,\n",
    "                                    test_phe_folder='./phecodes/', min_cases=20, permute=False, histograms=False):\n",
    "    p_vals = {}\n",
    "    counts = {}\n",
    "    betas = {}\n",
    "    ses = {}\n",
    "    auc1 = {}\n",
    "    auc2 = {}\n",
    "    for phe_file in sorted(os.listdir(test_phe_folder)):\n",
    "        results, name, a1, a2 = stratify_phecode_file_on_phecode(phenotype_vectors, test_df, latent_cols, adjust_cols,\n",
    "                                                         test_phe_folder + phe_file, min_cases, component_folder, \n",
    "                                                         permute, histograms)\n",
    "        \n",
    "        if results is not None:\n",
    "            pdf = pd.read_csv(test_phe_folder + phe_file, sep='\\t')\n",
    "            counts[name] = pdf.has_disease.sum()\n",
    "            p_vals[name] = results['P>|z|']['component']\n",
    "            betas[name] = results['Coef.']['component']\n",
    "            ses[name] = results['Std.Err.']['component']\n",
    "            auc1[name] = a1\n",
    "            auc2[name] = a2\n",
    "            print(f'Phe: {name}, N: {counts[name]}, P: {p_vals[name]:0.2E}, betas {betas[name]:0.3f} err: {ses[name]:0.4f}')\n",
    "    return p_vals, betas, ses, counts, auc1, auc2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = '/home/sam/trained_models/explore_phenotypes/tensors_all_union.csv'\n",
    "labels = pd.read_csv(label_file)\n",
    "all_scores = defaultdict(dict)\n",
    "adjust_cols = []\n",
    "\n",
    "phecode_meta = pd.read_csv('/home/sam/csvs/phecode_definitions.csv') \n",
    "cat_colors= {}\n",
    "for i,k in enumerate(phecode_meta.category.value_counts().keys()):\n",
    "    cat_colors[k] = i\n",
    "    #print(f'{i} {k}')\n",
    "\n",
    "phecode_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_file=f'/home/sam/trained_models/hypertuned_48m_16e_ecg_median_raw_10_autoencoder_256d/hidden_embed_hypertuned_48m_16e_ecg_median_raw_10_autoencoder_256d.tsv'\n",
    "latent_df = latent_space_dataframe(latent_space_file, label_file)\n",
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "adjust_cols = ['ecg_age', 'sex', 'white']\n",
    "train = latent_df.sample(frac=0.5)\n",
    "test = latent_df.drop(train.index)\n",
    "adjusted_ukb_ae_ecg = merge_and_stratify_by_code_folder(train, test, latent_cols, \n",
    "                                                 adjust_cols, './ukb_ecg_ae_phecode_projections/',\n",
    "                                                 phe_folder='/home/sam/phecodes_tables_prevalent/', \n",
    "                                                 test_phe_folder='/home/sam/phecodes_tables_prevalent/', \n",
    "                                                 min_cases=100,\n",
    "                                                 permute=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phecode_dicts(pval_dict):\n",
    "    categories = defaultdict(list)\n",
    "    categories_text = defaultdict(list)\n",
    "\n",
    "    for phe, pval in sorted(pval_dict.items(), key=operator.itemgetter(1)):\n",
    "        print(f\"phe is {phe.replace('phecode_', '').replace('_', '.')}\")\n",
    "        row = phecode_meta[phecode_meta.phecode == float(phe.replace('phecode_', '').replace('_', '.'))].iloc[0]\n",
    "        if row.category in cat_colors:\n",
    "            categories[row.category].append(pval)\n",
    "            categories_text[row.category].append(row.phenotype)\n",
    "            print(f'category: {row.category}\\n phenotype: {row.phenotype}  phecode is {phe} and pvalue {pval:0.4E}\\n' )\n",
    "    return categories, categories_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukb_cat, ukb_text = phecode_dicts(adjusted_ukb_ae_ecg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qq_plot_theoretical(categories, text, title='QQ Plot', p_thresh=0.95):\n",
    "    fig, ax = plt.subplots(figsize=(16, 12), dpi=400)\n",
    "    sort_cat = sorted(categories.items(), key=operator.itemgetter(0))\n",
    "    \n",
    "    annotations = []\n",
    "    x_offsets = [0]\n",
    "    x_labels = []\n",
    "    for i, (k,v) in enumerate(sort_cat):\n",
    "        if len(categories[k]) < 3:\n",
    "            continue\n",
    "        neglog10p = -np.log10(np.array(categories[k])+1e-300)\n",
    "        expected = -np.log10(np.arange(1.0/len(categories[k]), 1+1e-8, 1.0/len(categories[k]))) + x_offsets[-1]\n",
    "        #print(f'{x_offset} expected {len(expected)}  neglog10p {len(neglog10p)} \\n EXpected {expected[0]}')\n",
    "        ax.scatter(sorted(expected[:len(neglog10p)], reverse=True), sorted(neglog10p[:len(expected)], reverse=True), \n",
    "                   label=k.capitalize())\n",
    "        ax.plot([x_offsets[-1], expected[0]],[0, 1]) \n",
    "        x_offsets.append(expected[0] + 0.2)\n",
    "        x_labels.append(k.capitalize())\n",
    "        for j, txt in enumerate(text[k]):\n",
    "            if neglog10p[j] > p_thresh:\n",
    "                annotations.append(ax.annotate(txt, xy=(expected[j], neglog10p[j]), fontsize=12))\n",
    "                #annotations.append(ax.annotate(txt.replace(' ',\"\\n\"), xy=(expected[j], neglog10p[j]), fontsize=8))\n",
    "                \n",
    "    ax.set_xticks(x_offsets[:-1])\n",
    "    ax.set_xticklabels(x_labels, rotation=30, ha='right')\n",
    "    #plt.ylim(0, 15)\n",
    "    ax.legend(ncol=2, fontsize=14)\n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.set_xlabel('Expected -log10(P_value) per PheCode category')\n",
    "    ax.set_ylabel('Observed -log10(P_value) per PheCode category')\n",
    "    mask = np.zeros(fig.canvas.get_width_height(), bool)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    for a in annotations:\n",
    "        bbox = a.get_window_extent(renderer=fig.canvas.get_renderer())\n",
    "        if not np.isinf(bbox.x0): \n",
    "            x0 = int(bbox.x0)\n",
    "            x1 = int(math.ceil(bbox.x1))\n",
    "            y0 = int(bbox.y0)\n",
    "            y1 = int(math.ceil(bbox.y1))\n",
    "\n",
    "            s = np.s_[x0:x1+1, y0:y1+1]\n",
    "            if np.any(mask[s]):\n",
    "                a.set_visible(False)\n",
    "            else:\n",
    "                mask[s] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(ukb_cat, ukb_text, 'UKB Phecode Vectors PheWAS in UKB from ECG Median Autoencoder Latent Space, Cases > 500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_phewas(pvals, betas, ses, counts, auc1, auc2, file_name):\n",
    "    tuples = []\n",
    "    for phe, pval in sorted(pvals.items(), key=operator.itemgetter(1)):\n",
    "        #print(f\"phe is {phe.replace('phecode_', '').replace('_', '.')}\")\n",
    "        row = phecode_meta[phecode_meta.phecode == float(phe.replace('phecode_', '').replace('_', '.'))].iloc[0]\n",
    "        if row.category in cat_colors:\n",
    "            cols = [row.phecode, phe, pval, row.phenotype, row.category, \n",
    "                    counts[phe], betas[phe], ses[phe], auc1[phe], auc2[phe]\n",
    "                   ]\n",
    "            tuples.append(tuple(cols))\n",
    "    headers = ['phecode', 'phecode_text', 'p_value', 'phenotype', 'category',\n",
    "               'n', 'beta', 'se', 'AUC_with_ECG', 'AUC_no_ECG']\n",
    "    df = pd.DataFrame(tuples, columns = headers)\n",
    "    df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phewas(p_vals, betas, ses, counts, auc1, auc2, '/home/sam/csvs/phewas_ukb_with_mgh_vectors_2022_11_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install adjustText\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/home/sam/csvs/meta_analysis_components_fixed_apr21.csv')\n",
    "df = pd.read_csv('/home/sam/csvs/meta_analysis_components_fixed_may26.csv')\n",
    "\n",
    "p_thresh = -np.log10(0.05/len(df))\n",
    "title = 'QQ Plot for ECG Autoencoder PheWAS Fixed Effects Meta Analysis'\n",
    "fig, ax = plt.subplots(figsize=(18,10), dpi=600)\n",
    "ax.axhline(y=p_thresh, color='darkslategrey', linestyle='solid')\n",
    "print(p_thresh)\n",
    "annotations = []\n",
    "x_offsets = [0]\n",
    "x_labels = []\n",
    "cmap = plt.get_cmap('hsv')\n",
    "colors = cmap(np.linspace(0, 0.8, len(df.category.unique())))\n",
    "for category, color in zip(sorted(df.category.unique(), reverse=True), colors):\n",
    "    dfc = df[df.category == category]\n",
    "    dfc = dfc.sort_values('meta_p', ascending=False)\n",
    "    neglog10p = -np.log10(dfc.meta_p.to_numpy()+1e-300)\n",
    "    expected = -np.log10(np.arange(1.0/len(dfc), 1+1e-8, 1.0/len(dfc))) + x_offsets[-1]\n",
    "    ccategory = ' '.join(map(str.capitalize, category.split(' ')))\n",
    "#     ax.scatter(sorted(expected[:len(neglog10p)], reverse=True), sorted(neglog10p[:len(expected)], reverse=True), \n",
    "#                label=ccategory, color=color)\n",
    "    ax.scatter(sorted(expected, reverse=True), sorted(neglog10p, reverse=True), \n",
    "               label=ccategory, color=color)    \n",
    "    ax.plot([x_offsets[-1], expected[0]],[0, 1], color=color) \n",
    "    x_labels.append(ccategory)\n",
    "    x_offsets.append(expected[0] + 1)\n",
    "    for j, txt in enumerate(dfc.phenotype.to_numpy()) :\n",
    "        if neglog10p[j] > p_thresh:\n",
    "            ctxt = ' '.join(map(str.capitalize, txt.split(' ')))\n",
    "            annotations.append(ax.text(expected[-j]+0.4, neglog10p[j]+4, ctxt))\n",
    "\n",
    "            \n",
    "         \n",
    "    ax.set_xticks(x_offsets[:-1])\n",
    "    ax.set_xticklabels(x_labels, rotation=30, ha='right')\n",
    "    \n",
    "    ax.legend(loc='center left')\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    # sort both labels and handles by labels\n",
    "    labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))\n",
    "    ax.legend(handles, labels, ncol=4)\n",
    "    #ax.set_title(title)\n",
    "    ax.set_xlabel('Phecode Category')\n",
    "    ax.set_ylabel('Observed -log10(p)')\n",
    "\n",
    "\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "# adjust_text(annotations, only_move={'points':'y', 'texts':'y'},\n",
    "#             arrowprops=dict(arrowstyle=\"-\", color='black', lw=1.5))\n",
    "mask = np.zeros(fig.canvas.get_width_height(), bool)\n",
    "fig.canvas.draw()\n",
    "for a in reversed(annotations):\n",
    "    bbox = a.get_window_extent(renderer=fig.canvas.get_renderer())\n",
    "    if not np.isinf(bbox.x0): \n",
    "        x0 = int(bbox.x0)\n",
    "        x1 = int(math.ceil(bbox.x1))\n",
    "        y0 = int(bbox.y0)\n",
    "        y1 = int(math.ceil(bbox.y1))\n",
    "\n",
    "        s = np.s_[x0:x1, y0:y1]\n",
    "        if np.any(mask[s]):\n",
    "            a.set_visible(False)\n",
    "        else:\n",
    "            mask[s] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def cross_correlate_space(df, num_features):\n",
    "    index = [f'pv_{i}' for i in range(num_features)]\n",
    "    space = np.nan_to_num(df[index].to_numpy())\n",
    "    corrs = np.zeros((len(df),len(df)))\n",
    "    labels = {}\n",
    "    print(len(df), space.shape)\n",
    "    cats = df.category.to_numpy()\n",
    "    labels = {}\n",
    "    print(len(df), space.shape)\n",
    "    for i in range(len(df)):\n",
    "        if i== 0 or cats[i-1] != cats[i]:\n",
    "            labels[' '.join(map(str.capitalize, cats[i].split(' ')))] = i\n",
    "            print(f'{i} new cats {cats[i]}')\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df)):\n",
    "            corrs[i,j] = pearsonr(space[i,:], space[j,:])[0]\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), dpi=300)\n",
    "    sb.heatmap(corrs, cmap='twilight', square=True, ax=ax, vmax=1,vmin=-1, \n",
    "               cbar_kws={\"label\": f\"Phecode Vector\\n Pearson Correlation\", \"shrink\": .5})\n",
    "    \n",
    "    ax.set_xticks(list(labels.values()))\n",
    "    ax.set_xticklabels(list(labels.keys()))\n",
    "    ax.set_yticks(list(labels.values()))\n",
    "    ax.set_yticklabels(list(labels.keys()))\n",
    "    ax.set_xlabel('Phecode Categories')\n",
    "    ax.set_ylabel('Phecode Categories')\n",
    "    \n",
    "phenotype_vectors = phenotype_vectors.sort_values('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_correlate_space(phenotype_vectors, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
