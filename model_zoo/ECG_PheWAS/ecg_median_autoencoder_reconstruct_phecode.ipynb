{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from ml4h_ccds.data_descriptions.ecg import ECGDataDescription\n",
    "from ml4h_ccds.data_descriptions.wide_file import WideFileDataDescription\n",
    "from ml4h_ccds.data_descriptions.util import download_s3_if_not_exists\n",
    "\n",
    "from ml4h.models.model_factory import block_make_multimodal_multitask_model\n",
    "from ml4h.TensorMap import TensorMap, Interpretation\n",
    "\n",
    "from ml4ht.data.util.date_selector import DateRangeOptionPicker, first_dt, DATE_OPTION_KEY, DateRangeOptionPicker\n",
    "from ml4ht.data.data_description import DataDescription\n",
    "from ml4ht.data.sample_getter import DataDescriptionSampleGetter\n",
    "from ml4ht.data.explore import explore_data_descriptions, explore_sample_getter\n",
    "from ml4ht.data.data_loader import SampleGetterDataset, numpy_collate_fn,SampleGetterIterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION_DIR = os.path.expanduser(\"~\")  # downloaded data will be stored here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-college",
   "metadata": {},
   "source": [
    "# ECG data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ecg(ecg, _):\n",
    "    \"\"\"Transform ECG units to millivolts\"\"\"\n",
    "    return ecg / 1000\n",
    "\n",
    "def standardize_by_sample_ecg(ecg, _):\n",
    "    \"\"\"Transform ECG units to millivolts\"\"\"\n",
    "    return (ecg - np.mean(ecg)) / (np.std(ecg) + 1e-6) \n",
    "\n",
    "ecg_dd_i = ECGDataDescription(\n",
    "    SESSION_DIR, \n",
    "    name='input_ecg_2500_std_continuous', \n",
    "    ecg_len=2500,  # all ECGs will be linearly interpolated to be this length\n",
    "    #transforms=[standardize_by_sample_ecg],  # these will be applied in order\n",
    "    # data will be automatically localized from s3\n",
    "    s3_bucket_name='2017P001650', s3_bucket_path=['ecg_mgh_hd5s'],   # 'ecg_mgh_hd5s',  list of hd5s\n",
    ")\n",
    "\n",
    "ecg_dd_o = ECGDataDescription(\n",
    "    SESSION_DIR, \n",
    "    name='output_ecg_2500_std_continuous', \n",
    "    ecg_len=2500,  # all ECGs will be linearly interpolated to be this length\n",
    "    transforms=[standardize_by_sample_ecg],  # these will be applied in order\n",
    "    # data will be automatically localized from s3\n",
    "    s3_bucket_name='2017P001650', s3_bucket_path=['ecg_mgh_hd5s'],   # 'ecg_mgh_hd5s',  list of hd5s\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test it out on one of the available dates!\n",
    "sg_explore_df = pd.read_csv('../../af_survive_explore_all.csv')\n",
    "working_ids = sg_explore_df[sg_explore_df[\"error\"].isna()][\"sample_id\"]\n",
    "sample_id = working_ids.iloc[1]\n",
    "options = ecg_dd_i.get_loading_options(sample_id)\n",
    "print(options)\n",
    "print(working_ids[:10])\n",
    "# plt.plot(np.linspace(0, 10, 5000), ecg_dd_i.get_raw_data(1, options[0]))\n",
    "# plt.xlabel(\"time (s)\")\n",
    "# plt.ylabel(\"amplitude (mV)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7adbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython imports\n",
    "%matplotlib inline\n",
    "mrn = 1519973\n",
    "options = ecg_dd_i.get_loading_options(mrn)\n",
    "\n",
    "plt.plot(np.linspace(0, 10, 2500), ecg_dd_i.get_raw_data(mrn, options[-1]))\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.ylabel(\"amplitude (mV)\")\n",
    "plt.show()\n",
    "\n",
    "example = ecg_dd_i.get_raw_data(mrn, options[-1])\n",
    "example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a440d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('/home/samuel.friedman/trained_models/mgh_ecg_medians/inferred_hd5s/4282470.hd5', 'r') as hd5:\n",
    "    ecg = np.array(hd5['ecg_rest_median_raw_10_prediction'])\n",
    "    print(f'{ecg.shape}')\n",
    "leads = ['I', 'aVR', 'V1', 'V4', \n",
    "             'II', 'aVL', 'V2', 'V5', \n",
    "             'III', 'aVF', 'V3', 'V6', ]\n",
    "    \n",
    "channel_map = {\n",
    "    'I': 0, 'II': 1, 'III': 2, 'V1': 3, 'V2': 4, 'V3': 5,\n",
    "    'V4': 6, 'V5': 7, 'V6': 8, 'aVF': 9, 'aVL': 10, 'aVR': 11,\n",
    "}\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 16), dpi=300, sharey=False, sharex=True)\n",
    "for i, (ax, lead) in enumerate(zip(axes.ravel(), leads)):\n",
    "    ax.plot(range(600), ecg[:, channel_map[lead]])\n",
    "    ax.set_title(f\"Lead: {lead}\")\n",
    "    ax.set_xlabel(\"time (s)\")\n",
    "    ax.set_ylabel(\"amplitude (mV)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29593b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import h5py\n",
    "with h5py.File('/home/samuel.friedman/trained_models/mgh_ecg_medians/inferred_hd5s/5212097.hd5', 'r') as hd5:\n",
    "    ecg = np.array(hd5['ecg_rest_median_raw_10_prediction'])\n",
    "    print(f'{ecg.shape}')\n",
    "leads = ['I', 'aVR', 'V1', 'V4', \n",
    "             'II', 'aVL', 'V2', 'V5', \n",
    "             'III', 'aVF', 'V3', 'V6', ]\n",
    "    \n",
    "channel_map = {\n",
    "    'I': 0, 'II': 1, 'III': 2, 'V1': 3, 'V2': 4, 'V3': 5,\n",
    "    'V4': 6, 'V5': 7, 'V6': 8, 'aVF': 9, 'aVL': 10, 'aVR': 11,\n",
    "}\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 16), dpi=300, sharey=False, sharex=True)\n",
    "for i, (ax, lead) in enumerate(zip(axes.ravel(), leads)):\n",
    "    ax.plot(range(600), ecg[:, channel_map[lead]])\n",
    "    ax.set_title(f\"Lead: {lead}\")\n",
    "    ax.set_xlabel(\"time (s)\")\n",
    "    ax.set_ylabel(\"amplitude (mV)\")\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how all of the components are merged together\n",
    "sg = DataDescriptionSampleGetter(\n",
    "    input_data_descriptions=[ecg_dd_i],  # what we want a model to use as input data\n",
    "    output_data_descriptions=[ecg_dd_o],  # what we want a model to predict from the input data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_explore_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's test out the SampleGetter on a sample id\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# sample_id = working_ids.iloc[1]\n",
    "# in_data, out_data = sg(sample_id)\n",
    "\n",
    "# ecg = in_data[ecg_dd_i.name]\n",
    "\n",
    "\n",
    "# plt.plot(np.linspace(0, 10, len(ecg)), ecg)\n",
    "# plt.title(f\"ECG for patient\")\n",
    "# plt.xlabel('time (s)')\n",
    "# plt.ylabel('amplitude (mV)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy pasted from ml4h branch nd_ml4ht_integration\n",
    "from ml4h.defines import PARTNERS_DATETIME_FORMAT, ECG_REST_AMP_LEADS\n",
    "def _not_implemented_tensor_from_file(_, __, ___=None):\n",
    "    \"\"\"Used to make sure TensorMap is never used to load data\"\"\"\n",
    "    raise NotImplementedError('This TensorMap cannot load data.')\n",
    "    \n",
    "\n",
    "def tensor_map_from_data_description(\n",
    "        data_description: DataDescription,\n",
    "        interpretation: Interpretation,\n",
    "        shape,\n",
    "        name=None,\n",
    "        **tensor_map_kwargs,\n",
    ") -> TensorMap:\n",
    "    \"\"\"\n",
    "    Allows a DataDescription to be used in the model factory\n",
    "    by converting a DataDescription into a TensorMap\n",
    "    \"\"\"\n",
    "    tmap = TensorMap(\n",
    "        name=name if name else data_description.name,\n",
    "        interpretation=interpretation,\n",
    "        shape=shape,\n",
    "        tensor_from_file=_not_implemented_tensor_from_file,\n",
    "        **tensor_map_kwargs,\n",
    "    )\n",
    "    return tmap\n",
    "\n",
    "\n",
    "ecg_tmap = tensor_map_from_data_description(\n",
    "    ecg_dd_i,\n",
    "    Interpretation.CONTINUOUS,\n",
    "    (2500, 12), name='ecg_2500_std',\n",
    "    channel_map=ECG_REST_AMP_LEADS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-second",
   "metadata": {},
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1803794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, Union, Callable\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "def _plot_partners_full(voltage: Dict[str, np.ndarray], ax: plt.Axes) -> None:\n",
    "    full_voltage = np.full((12, 2500), np.nan)\n",
    "    for i, lead in enumerate(voltage):\n",
    "        full_voltage[i] = voltage[lead] #[::2]\n",
    "\n",
    "    # convert voltage to millivolts\n",
    "    # full_voltage /= 1000\n",
    "\n",
    "    # calculate space between leads\n",
    "    min_y, max_y = ax.get_ylim()\n",
    "    y_offset = (max_y - min_y) / len(voltage)\n",
    "\n",
    "    text_xoffset = 5\n",
    "    text_yoffset = -0.01\n",
    "\n",
    "    # plot signal and add labels\n",
    "    for i, lead in enumerate(voltage):\n",
    "        this_offset = (len(voltage) - i - 0.5) * y_offset\n",
    "        ax.plot(full_voltage[i] + this_offset, color=\"black\", linewidth=0.375)\n",
    "        ax.text(\n",
    "            0 + text_xoffset,\n",
    "            this_offset + text_yoffset,\n",
    "            lead,\n",
    "            ha=\"left\",\n",
    "            va=\"top\",\n",
    "            weight=\"bold\",\n",
    "        )\n",
    "    plt.show()\n",
    "        \n",
    "def _plot_partners_clinical(voltage: Dict[str, np.ndarray], ax: plt.Axes, label='black') -> None:\n",
    "    # get voltage in clinical chunks\n",
    "    clinical_voltage = np.full((6, 2500), np.nan)\n",
    "    halfgap = 5\n",
    "\n",
    "    clinical_voltage[0][0 : 625 - halfgap] = voltage[\"I\"][0 : 625 - halfgap]\n",
    "    clinical_voltage[0][625 + halfgap : 1250 - halfgap] = voltage[\"aVR\"][\n",
    "        625 + halfgap : 1250 - halfgap\n",
    "    ]\n",
    "    clinical_voltage[0][1250 + halfgap : 1875 - halfgap] = voltage[\"V1\"][\n",
    "        1250 + halfgap : 1875 - halfgap\n",
    "    ]\n",
    "    clinical_voltage[0][1875 + halfgap : 2500] = voltage[\"V4\"][1875 + halfgap : 2500]\n",
    "\n",
    "    clinical_voltage[1][0 : 625 - halfgap] = voltage[\"II\"][0 : 625 - halfgap]\n",
    "    clinical_voltage[1][625 + halfgap : 1250 - halfgap] = voltage[\"aVL\"][\n",
    "        625 + halfgap : 1250 - halfgap\n",
    "    ]\n",
    "    clinical_voltage[1][1250 + halfgap : 1875 - halfgap] = voltage[\"V2\"][\n",
    "        1250 + halfgap : 1875 - halfgap\n",
    "    ]\n",
    "    clinical_voltage[1][1875 + halfgap : 2500] = voltage[\"V5\"][1875 + halfgap : 2500]\n",
    "\n",
    "    clinical_voltage[2][0 : 625 - halfgap] = voltage[\"III\"][0 : 625 - halfgap]\n",
    "    clinical_voltage[2][625 + halfgap : 1250 - halfgap] = voltage[\"aVF\"][\n",
    "        625 + halfgap : 1250 - halfgap\n",
    "    ]\n",
    "    clinical_voltage[2][1250 + halfgap : 1875 - halfgap] = voltage[\"V3\"][\n",
    "        1250 + halfgap : 1875 - halfgap\n",
    "    ]\n",
    "    clinical_voltage[2][1875 + halfgap : 2500] = voltage[\"V6\"][1875 + halfgap : 2500]\n",
    "\n",
    "    clinical_voltage[3] = voltage[\"V1\"]\n",
    "    clinical_voltage[4] = voltage[\"II\"]\n",
    "    clinical_voltage[5] = voltage[\"V5\"]\n",
    "\n",
    "    voltage = clinical_voltage\n",
    "\n",
    "    # convert voltage to millivolts\n",
    "    voltage /= 1000\n",
    "\n",
    "    # calculate space between leads\n",
    "    min_y, max_y = ax.get_ylim()\n",
    "    y_offset = (max_y - min_y) / len(voltage)\n",
    "\n",
    "    text_xoffset = 5\n",
    "    text_yoffset = -0.1\n",
    "\n",
    "    # plot signal and add labels\n",
    "    for i in range(len(voltage)):\n",
    "        this_offset = (len(voltage) - i - 0.5) * y_offset\n",
    "        if label == 'Original':\n",
    "            color = 'red'\n",
    "            alpha = 1.0\n",
    "            linestyle='solid'\n",
    "            lw =1.475\n",
    "        else:\n",
    "            color = 'blue'\n",
    "            alpha = 0.5\n",
    "            linestyle='solid'#'dashed'\n",
    "            lw =1.875            \n",
    "        if i == 0:\n",
    "            ax.plot(voltage[i] + this_offset, label=label, color=color, alpha=alpha, linestyle=linestyle, linewidth=lw)\n",
    "        else:\n",
    "            ax.plot(voltage[i] + this_offset, color=color, alpha=alpha, linestyle=linestyle, linewidth=lw)\n",
    "        if i == 0:\n",
    "            ax.text(\n",
    "                0 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"I\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "            ax.text(\n",
    "                625 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"aVR\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "            ax.text(\n",
    "                1250 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"V1\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "            ax.text(\n",
    "                1875 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"V4\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "        elif i == 1:\n",
    "            ax.text(\n",
    "                0 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"II\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "            ax.text(\n",
    "                625 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"aVL\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "            ax.text(\n",
    "                1250 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"V2\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "            ax.text(\n",
    "                1875 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"V5\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "        elif i == 2:\n",
    "            ax.text(\n",
    "                0 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"III\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "            ax.text(\n",
    "                625 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"aVF\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "            ax.text(\n",
    "                1250 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"V3\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "            ax.text(\n",
    "                1875 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"V6\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "        elif i == 3:\n",
    "            ax.text(\n",
    "                0 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"V1\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "        elif i == 4:\n",
    "            ax.text(\n",
    "                0 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"II\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "        elif i == 5:\n",
    "            ax.text(\n",
    "                0 + text_xoffset,\n",
    "                this_offset + text_yoffset,\n",
    "                \"V5\",\n",
    "                ha=\"left\",\n",
    "                va=\"top\",\n",
    "                weight=\"bold\",\n",
    "            )\n",
    "\n",
    "\n",
    "def _plot_partners_figure(\n",
    "    data: Dict[str, Union[np.ndarray, str, Dict]],\n",
    "    plot_signal_function: Callable[[Dict[str, np.ndarray], plt.Axes], None],\n",
    "    plot_mode: str,\n",
    "    output_folder: str,\n",
    "    run_id: str,\n",
    ") -> None:\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    plt.rcParams[\"font.size\"] = 9.5\n",
    "\n",
    "    w, h = 11, 8.5\n",
    "    fig = plt.figure(\n",
    "        figsize=(w, h),\n",
    "        dpi=100,\n",
    "    )\n",
    "\n",
    "    # patient info and ecg text\n",
    "    _plot_partners_text(data, fig, w, h)\n",
    "\n",
    "    # define plot area in inches\n",
    "    left = 0.17\n",
    "    bottom = h - 7.85\n",
    "    width = w - 2 * left\n",
    "    height = h - bottom - 2.3\n",
    "\n",
    "    # ecg plot area\n",
    "    ax = fig.add_axes([left / w, bottom / h, width / w, height / h])\n",
    "\n",
    "    # voltage is in microvolts\n",
    "    # the entire plot area is 5.55 inches tall, 10.66 inches wide (141 mm, 271 mm)\n",
    "    # the resolution on the y-axis is 10 mm/mV\n",
    "    # the resolution on the x-axis is 25 mm/s\n",
    "    inch2mm = lambda inches: inches * 25.4\n",
    "\n",
    "    # 1. set y-limit to max 14.1 mV\n",
    "    y_res = 10  # mm/mV\n",
    "    max_y = inch2mm(height) / y_res\n",
    "    min_y = 0\n",
    "    ax.set_ylim(min_y, max_y)\n",
    "\n",
    "    # 2. set x-limit to max 10.8 s, center 10 s leads\n",
    "    sampling_frequency = 250  # Hz\n",
    "    x_res = 25  # mm/s\n",
    "    max_x = inch2mm(width) / x_res\n",
    "    x_buffer = (max_x - 10) / 2\n",
    "    max_x -= x_buffer\n",
    "    min_x = -x_buffer\n",
    "    max_x *= sampling_frequency\n",
    "    min_x *= sampling_frequency\n",
    "    ax.set_xlim(min_x, max_x)\n",
    "\n",
    "    # 3. set ticks for every 0.1 mV or every 1/25 s\n",
    "    y_tick = 1 / y_res\n",
    "    x_tick = 1 / x_res * sampling_frequency\n",
    "    x_major_ticks = np.arange(min_x, max_x, x_tick * 5)\n",
    "    x_minor_ticks = np.arange(min_x, max_x, x_tick)\n",
    "    y_major_ticks = np.arange(min_y, max_y, y_tick * 5)\n",
    "    y_minor_ticks = np.arange(min_y, max_y, y_tick)\n",
    "\n",
    "    ax.set_xticks(x_major_ticks)\n",
    "    ax.set_xticks(x_minor_ticks, minor=True)\n",
    "    ax.set_yticks(y_major_ticks)\n",
    "    ax.set_yticks(y_minor_ticks, minor=True)\n",
    "\n",
    "    ax.tick_params(\n",
    "        which=\"both\", left=False, bottom=False, labelleft=False, labelbottom=False,\n",
    "    )\n",
    "    ax.grid(b=True, color=\"r\", which=\"major\", lw=0.5)\n",
    "    ax.grid(b=True, color=\"r\", which=\"minor\", lw=0.2)\n",
    "\n",
    "    # signal plot\n",
    "    voltage = data[\"2500_raw\"]\n",
    "    plot_signal_function(voltage, ax)\n",
    "\n",
    "    # bottom text\n",
    "    fig.text(\n",
    "        0.17 / w,\n",
    "        0.46 / h,\n",
    "        f\"{x_res}mm/s    {y_res}mm/mV    {sampling_frequency}Hz\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "\n",
    "def _two_ecgs_clinical(\n",
    "    data1: Dict[str, Union[np.ndarray, str, Dict]],\n",
    "    data2: Dict[str, Union[np.ndarray, str, Dict]],\n",
    "    plot_signal_function: Callable[[Dict[str, np.ndarray], plt.Axes], None],\n",
    "    out_path, label1='Original', label2='Reconstruction'\n",
    "):    \n",
    "    plt.rcParams[\"font.size\"] = 9.5\n",
    "\n",
    "    w, h = 11, 8.5\n",
    "    fig = Figure(\n",
    "        figsize=(w, h),\n",
    "        dpi=300,\n",
    "    )\n",
    "\n",
    "    # patient info and ecg text\n",
    "    # _plot_partners_text(data, fig, w, h)\n",
    "\n",
    "    # define plot area in inches\n",
    "    left = 0.17\n",
    "    bottom = h - 7.85\n",
    "    width = w - 2 * left\n",
    "    height = h - bottom - 2.3\n",
    "\n",
    "    # ecg plot area\n",
    "    ax = fig.add_axes([left / w, bottom / h, width / w, height / h])\n",
    "\n",
    "    # voltage is in microvolts\n",
    "    # the entire plot area is 5.55 inches tall, 10.66 inches wide (141 mm, 271 mm)\n",
    "    # the resolution on the y-axis is 10 mm/mV\n",
    "    # the resolution on the x-axis is 25 mm/s\n",
    "    inch2mm = lambda inches: inches * 25.4\n",
    "\n",
    "    # 1. set y-limit to max 14.1 mV\n",
    "    y_res = 10  # mm/mV\n",
    "    max_y = inch2mm(height) / y_res\n",
    "    min_y = 0\n",
    "    ax.set_ylim(min_y, max_y)\n",
    "\n",
    "    # 2. set x-limit to max 10.8 s, center 10 s leads\n",
    "    sampling_frequency = 250  # Hz\n",
    "    x_res = 25  # mm/s\n",
    "    max_x = inch2mm(width) / x_res\n",
    "    x_buffer = (max_x - 10) / 2\n",
    "    max_x -= x_buffer\n",
    "    min_x = -x_buffer\n",
    "    max_x *= sampling_frequency\n",
    "    min_x *= sampling_frequency\n",
    "    ax.set_xlim(min_x, max_x)\n",
    "\n",
    "    # 3. set ticks for every 0.1 mV or every 1/25 s\n",
    "    y_tick = 1 / y_res\n",
    "    x_tick = 1 / x_res * sampling_frequency\n",
    "    x_major_ticks = np.arange(min_x, max_x, x_tick * 5)\n",
    "    x_minor_ticks = np.arange(min_x, max_x, x_tick)\n",
    "    y_major_ticks = np.arange(min_y, max_y, y_tick * 5)\n",
    "    y_minor_ticks = np.arange(min_y, max_y, y_tick)\n",
    "\n",
    "    ax.set_xticks(x_major_ticks)\n",
    "    ax.set_xticks(x_minor_ticks, minor=True)\n",
    "    ax.set_yticks(y_major_ticks)\n",
    "    ax.set_yticks(y_minor_ticks, minor=True)\n",
    "\n",
    "    ax.tick_params(\n",
    "        which=\"both\", left=False, bottom=False, labelleft=False, labelbottom=False\n",
    "    )\n",
    "    ax.grid(b=True, color=\"r\", which=\"major\", lw=0.5)\n",
    "    ax.grid(b=True, color=\"r\", which=\"minor\", lw=0.2)\n",
    "    \n",
    "    plot_signal_function(data1, ax, label=label1)\n",
    "    plot_signal_function(data2, ax, label=label2)\n",
    "    ax.legend()\n",
    "    # bottom text\n",
    "    fig.text(\n",
    "        0.17 / w,\n",
    "        0.46 / h,\n",
    "        f\"{x_res}mm/s    {y_res}mm/mV    {sampling_frequency}Hz\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    fig.savefig(f'{out_path}.png', format='png')\n",
    "    return fig\n",
    "\n",
    "\n",
    "def _plot_partners_figure(\n",
    "    data: Dict[str, Union[np.ndarray, str, Dict]],\n",
    "    plot_signal_function: Callable[[Dict[str, np.ndarray], plt.Axes], None],\n",
    "    out_path,\n",
    "):\n",
    "    plt.rcParams[\"font.size\"] = 9.5\n",
    "\n",
    "    w, h = 11, 8.5\n",
    "    fig = Figure(\n",
    "        figsize=(w, h),\n",
    "        dpi=100,\n",
    "    )\n",
    "\n",
    "    # patient info and ecg text\n",
    "    # _plot_partners_text(data, fig, w, h)\n",
    "\n",
    "    # define plot area in inches\n",
    "    left = 0.17\n",
    "    bottom = h - 7.85\n",
    "    width = w - 2 * left\n",
    "    height = h - bottom - 2.3\n",
    "\n",
    "    # ecg plot area\n",
    "    ax = fig.add_axes([left / w, bottom / h, width / w, height / h])\n",
    "\n",
    "    # voltage is in microvolts\n",
    "    # the entire plot area is 5.55 inches tall, 10.66 inches wide (141 mm, 271 mm)\n",
    "    # the resolution on the y-axis is 10 mm/mV\n",
    "    # the resolution on the x-axis is 25 mm/s\n",
    "    inch2mm = lambda inches: inches * 25.4\n",
    "\n",
    "    # 1. set y-limit to max 14.1 mV\n",
    "    y_res = 10  # mm/mV\n",
    "    max_y = inch2mm(height) / y_res\n",
    "    min_y = 0\n",
    "    ax.set_ylim(min_y, max_y)\n",
    "\n",
    "    # 2. set x-limit to max 10.8 s, center 10 s leads\n",
    "    sampling_frequency = 250  # Hz\n",
    "    x_res = 25  # mm/s\n",
    "    max_x = inch2mm(width) / x_res\n",
    "    x_buffer = (max_x - 10) / 2\n",
    "    max_x -= x_buffer\n",
    "    min_x = -x_buffer\n",
    "    max_x *= sampling_frequency\n",
    "    min_x *= sampling_frequency\n",
    "    ax.set_xlim(min_x, max_x)\n",
    "\n",
    "    # 3. set ticks for every 0.1 mV or every 1/25 s\n",
    "    y_tick = 1 / y_res\n",
    "    x_tick = 1 / x_res * sampling_frequency\n",
    "    x_major_ticks = np.arange(min_x, max_x, x_tick * 5)\n",
    "    x_minor_ticks = np.arange(min_x, max_x, x_tick)\n",
    "    y_major_ticks = np.arange(min_y, max_y, y_tick * 5)\n",
    "    y_minor_ticks = np.arange(min_y, max_y, y_tick)\n",
    "\n",
    "    ax.set_xticks(x_major_ticks)\n",
    "    ax.set_xticks(x_minor_ticks, minor=True)\n",
    "    ax.set_yticks(y_major_ticks)\n",
    "    ax.set_yticks(y_minor_ticks, minor=True)\n",
    "\n",
    "    ax.tick_params(\n",
    "        which=\"both\", left=False, bottom=False, labelleft=False, labelbottom=False\n",
    "    )\n",
    "    ax.grid(b=True, color=\"r\", which=\"major\", lw=0.5)\n",
    "    ax.grid(b=True, color=\"r\", which=\"minor\", lw=0.2)\n",
    "\n",
    "    # signal plot\n",
    "    #voltage = data[\"2500_raw\"]\n",
    "    plot_signal_function(data, ax)\n",
    "\n",
    "    # bottom text\n",
    "    fig.text(\n",
    "        0.17 / w,\n",
    "        0.46 / h,\n",
    "        f\"{x_res}mm/s    {y_res}mm/mV    {sampling_frequency}Hz\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    fig.savefig(f'{out_path}.png', format='png')\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "def reconstruct_phecode(decoders, tensor_map, latent_df, test_df, latent_cols, \n",
    "                        phecode_file, out_path, scalar=4.0, mrn=0, label1='Control',\n",
    "                        label2='Reconstruction', centroid_method=True):\n",
    "    if 'PheCode' not in phecode_file:\n",
    "        return\n",
    "    df = pd.read_csv(phecode_file, sep='\\t')\n",
    "    phecode_name = f'phe_{df.iloc[0].phenotype}'.replace('.', '_').replace(' ', '')\n",
    "\n",
    "    ratio = df.has_disease.sum() / len(df.has_disease)\n",
    "    print(f'phecode_name  {phecode_name} ratio: {ratio}')\n",
    "    print([c for c in df if 'latent' not in c] )   #phecode_name, 1, 0\n",
    "    df = df.rename(columns={'has_disease': phecode_name})\n",
    "    latent_df = pd.merge(latent_df, df, left_on='LINKER_ID', right_on='linker_id', how='inner')\n",
    "    print(f'MERGED phecode_name  {phecode_name}')\n",
    "    latent_df.info()\n",
    "    hit = latent_df.loc[latent_df[phecode_name] >= 1]\n",
    "    miss = latent_df.loc[latent_df[phecode_name] < 1]\n",
    "    hit_np = hit[latent_cols].to_numpy()\n",
    "    miss_np = miss[latent_cols].to_numpy()\n",
    "    positroid = np.mean(hit_np, axis=0)\n",
    "    negatroid = np.mean(miss_np, axis=0)\n",
    "    phenotype_vector = negatroid - positroid\n",
    "    \n",
    "    if len(hit_np) < 100:\n",
    "        return\n",
    "        \n",
    "    if centroid_method:\n",
    "        y = decoders[tensor_map].predict(np.array([negatroid]))[0]\n",
    "        cn = closest_node(positroid, hit_np)\n",
    "        print(f'cn shape {hit_np[cn].shape} cn is {cn}')\n",
    "        yp = decoders[tensor_map].predict(np.array([positroid]))[0]\n",
    "\n",
    "    else:\n",
    "        mencode = latent_df[latent_df.MRN == mrn][latent_cols].to_numpy()\n",
    "        y = decoders[tensor_map].predict(mencode)[0]\n",
    "        yp = decoders[tensor_map].predict(mencode+(scalar*phenotype_vector))[0]        \n",
    "\n",
    "    print(f'yp is {yp.shape} \\n yp is {y.shape}')    \n",
    "\n",
    "    index2channel = {v: k for k, v in tensor_map.channel_map.items()}\n",
    "    leads = ['I', 'aVR', 'V1', 'V4', \n",
    "             'II', 'aVL', 'V2', 'V5', \n",
    "             'III', 'aVF', 'V3', 'V6', ]\n",
    "\n",
    "    width = 16\n",
    "    height = 12\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(width, height), dpi=300, sharey=True)\n",
    "\n",
    "    channel_map = {\n",
    "    'I': 0, 'II': 1, 'III': 2, 'V1': 6, 'V2': 7, 'V3': 8,\n",
    "    'V4': 9, 'V5': 10, 'V6': 11, 'aVF': 5, 'aVL': 4, 'aVR': 3,\n",
    "    }\n",
    "    inch2mm = lambda inches: inches * 25.4\n",
    "    for j, (ax, lead) in enumerate(zip(axes.ravel(), leads)):\n",
    "            # 1. set y-limit to max 14.1 mV\n",
    "        max_y = 4.1\n",
    "        y_res = inch2mm(height/3) / max_y \n",
    "        \n",
    "        min_y = -4\n",
    "        ax.set_ylim(min_y, max_y)\n",
    "\n",
    "\n",
    "\n",
    "        # 3. set ticks for every 0.1 mV or every 1/25 s\n",
    "        #y_tick = 1 / y_res\n",
    "        #mms = inch2mm(width/4)\n",
    "        #x_res = mms / 1.2  # mm/s\n",
    "        #x_tick = 1 / x_res * 500\n",
    "        x_major_ticks = np.arange(0, 601, 100)\n",
    "        x_minor_ticks = np.arange(0, 601, 50)\n",
    "        y_major_ticks = np.arange(min_y, max_y, 2.0)\n",
    "        y_minor_ticks = np.arange(min_y, max_y, 0.1)\n",
    "\n",
    "        ax.set_xticks(x_major_ticks)\n",
    "        ax.set_xticks(x_minor_ticks, minor=True)\n",
    "        ax.set_xticklabels([0,0.2,0.4,0.6,0.8,1.0,1.2])\n",
    "        ax.set_yticks(y_major_ticks)\n",
    "        ax.set_yticks(y_minor_ticks, minor=True)\n",
    "        ax.grid(b=True, color=\"k\", which=\"major\", lw=0.5)\n",
    "        ax.grid(b=True, color=\"k\", which=\"minor\", lw=0.2)\n",
    "        \n",
    "        ax.plot(y[:, channel_map[lead]], c=\"blue\", lw=3, label=label1)\n",
    "        ax.plot(yp[:, channel_map[lead]], c=\"red\", lw=5, alpha=0.5, label=label2)\n",
    "        ax.set_title(f\"Lead: {lead}\")\n",
    "        #if j == 0:\n",
    "        ax.legend(fontsize = 12)\n",
    "        \n",
    "        ax.set_xlabel('Seconds')\n",
    "        ax.set_ylabel('mV')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    fig.savefig(f'{out_path}{phecode_name}.png', format='png')\n",
    "    \n",
    "    print(f'Plotted ECGs for {phecode_name} positive N: {len(hit)} negative N: {len(miss)}')\n",
    "    \n",
    "def closest_node(node, nodes):\n",
    "    dist_2 = np.sum((nodes - node)**2, axis=1)\n",
    "    return np.argsort(dist_2)[0]\n",
    "\n",
    "def closest_node_cos(a, nodes):\n",
    "    dist_2 = [np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b)) for b in nodes]\n",
    "    return np.argmin(dist_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from ml4h.arguments import parse_args\n",
    "from ml4h.metrics import coefficient_of_determination\n",
    "from ml4h.explorations import latent_space_dataframe\n",
    "from ml4h.models.model_factory import block_make_multimodal_multitask_model\n",
    "\n",
    "model_name = 'mgh_ecg_rest_median_raw_10_autoencoder_256d_v2022_04_13'\n",
    "model_name = 'mgh_biosppy_median_60bpm_autoencoder_256d_v2022_05_21'\n",
    "\n",
    "\n",
    "sys.argv = ['train',\n",
    "            '--input_tensors', 'ecg_biosppy_median_60bpm_mgb',\n",
    "            '--output_tensors', 'ecg_biosppy_median_60bpm_mgb',\n",
    "            '--activation', 'mish',\n",
    "            '--block_size', '8', '--conv_width', '61', '--conv_layers', '64', '64', '--pool_type', 'max', \n",
    "            '--dense_blocks', '64', '64', '--dense_layers', '128', '--pool_type', 'average',\n",
    "            '--learning_rate', '0.00002',\n",
    "            '--encoder_blocks', 'conv_encode', '--merge_blocks', '--decoder_blocks', 'conv_decode',\n",
    "           '--tensormap_prefix', 'ml4h.tensormap.ukb.ecg',\n",
    "            '--model_file', f'../../trained_models/{model_name}/{model_name}.h5',\n",
    "           \n",
    "           ]\n",
    "args = parse_args()\n",
    "\n",
    "\n",
    "# ecg_tmap_median = tensor_map_from_data_description(\n",
    "#     ecg_dd_i,\n",
    "#     Interpretation.CONTINUOUS,\n",
    "#     (600, 12), name='ecg_rest_median_raw_10',\n",
    "#     channel_map=ECG_REST_AMP_LEADS\n",
    "# )\n",
    "# args.tensor_maps_in = [ecg_tmap_median]\n",
    "# args.tensor_maps_out = [ecg_tmap_median]\n",
    "\n",
    "ecg_autoencoder, encoders, decoders, merger = block_make_multimodal_multitask_model(**args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b52abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('../../mrn_linker.txt', sep='\\t')\n",
    "# latent = pd.read_csv('mgh_drop_fuse_latent_space.csv')\n",
    "# latent_df = pd.merge(latent, links, left_on='MGH_MRN_0', right_on='MRN', how='inner')\n",
    "lf='/home/samuel.friedman/trained_models/mgh_biosppy_median_60bpm_autoencoder_256d_v2022_05_21/hidden_median_mgh_biosppy_median_60bpm_autoencoder_256d_v2022_05_21.tsv'\n",
    "\n",
    "\n",
    "#latent = pd.read_csv('./trained_models/ecg_2500_autoencoder_mgh_c3po_128d_v2021_12_17/mgh_latent_ecg_2500_autoencoder_mgh_c3po_128d_v2021_12_17.tsv', sep='\\t')\n",
    "#latent = pd.read_csv('../../trained_models/mgh_ecg_rest_median_raw_10_autoencoder_256d_v2022_04_13/merged_mgh_latent_mgh_ecg_rest_median_raw_10_autoencoder_256d_v2022_04_13.tsv', sep='\\t')\n",
    "#latent = pd.read_csv('./trained_models/mgh_ecg_rest_median_raw_10_lead_I_autoencoder_256d_v2022_04_09/mgh_latent_lead_I_mgh_ecg_rest_median_raw_10_lead_I_autoencoder_256d_v2022_04_09.tsv', sep='\\t')\n",
    "latent = pd.read_csv(lf, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "latent_df = pd.merge(latent, links, left_on='sample_id', right_on='MRN', how='inner')\n",
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "latent_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6126d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "                                    phecode_file='../../phecodes/PheCode_805.txt',\n",
    "                                    out_path='../../ecg_phecode_reconstruct/', \n",
    "                    label1='Control',               \n",
    "                    label2='Right Bundle Branch Block', centroid_method=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb98c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "                                    phecode_file='../../phecodes/PheCode_806.txt',\n",
    "                                    out_path='../../ecg_phecode_reconstruct/', \n",
    "                                    label2='Left Bundle Branch Block', centroid_method=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "                                    phecode_file='../../phecodes/PheCode_388.txt',\n",
    "                                    out_path='../../ecg_phecode_reconstruct/', \n",
    "                                    label2='Obesity', centroid_method=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab83499",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file='../../phecodes/PheCode_793.txt',\n",
    "                    out_path='../../ecg_phecode_reconstruct/', \n",
    "                   label2='Hypertrophic Cardiomyopathy', centroid_method=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file='../../phecodes/PheCode_793.txt',\n",
    "                    out_path='../../ecg_phecode_reconstruct/', \n",
    "                   label2='Hypertrophic Cardiomyopathy', centroid_method=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"496_3\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Bronchiectasis', centroid_method=True)\n",
    "\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"250\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Diabetes mellitus', centroid_method=True)\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"272_1\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Hyperlipidemia', centroid_method=True)\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"274_1\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Gout', centroid_method=True)\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"585\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Renal failure', centroid_method=True)\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"600\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Hyperplasia of prostate', centroid_method=True)\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"574\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Cholelithiasis and cholecystitis', centroid_method=True)\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"562\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Diverticulosis and diverticulitis', centroid_method=True)\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"327_3\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Sleep apnea', centroid_method=True)\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"345\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Epilepsy, recurrent seizures, convulsions', centroid_method=True)\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"331_9\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Cerebral degeneration, unspecified', centroid_method=True)\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"316\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Substance addiction and disorders', centroid_method=True)\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"285\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Other anemias', centroid_method=True)\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols,\n",
    "                    phecode_file=phe2file[\"286\"],\n",
    "                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                    label2='Coagulation defects', centroid_method=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e2effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "                                    phecode_file='../../phecodes/PheCode_370.txt',\n",
    "                                    out_path='../../ecg_phecode_reconstruct/', \n",
    "                   label2='Hyperpotassemia', centroid_method=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5221aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "                                    phecode_file='../../phecodes/PheCode_371.txt',\n",
    "                                    out_path='../../ecg_phecode_reconstruct/', \n",
    "                   label2='Hypopotassemia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafcbcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "                                    phecode_file='../../phecodes/PheCode_798.txt',\n",
    "                                    out_path='../../ecg_phecode_reconstruct/',\n",
    "                   label2='AV block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b98ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "#                                     phecode_file='../../phecodes/PheCode_388.txt',\n",
    "#                                     out_path='../../ecg_phecode_reconstruct/obesity', \n",
    "#                     scalar=5.0, mrn=3467344, label2='Obesity Vector Transformation', centroid_method=True)\n",
    "\n",
    "# reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "#                                     phecode_file='../../phecodes/PheCode_388.txt',\n",
    "#                                     out_path='../../ecg_phecode_reconstruct/obesity', \n",
    "#                     scalar=5.0, mrn=1130296, label2='Obesity Vector Transformation')\n",
    "\n",
    "reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "                                    phecode_file='../../phecodes/PheCode_806.txt',\n",
    "                                    out_path='../../ecg_phecode_reconstruct/lbbb', \n",
    "                    scalar=2.0, \n",
    "                    mrn=3467344,\n",
    "                   label2='Left Bundle Branch Block')\n",
    "\n",
    "# reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "#                                     phecode_file='../../phecodes/PheCode_806.txt',\n",
    "#                                     out_path='../../ecg_phecode_reconstruct/lbbb', \n",
    "#                     scalar=2.0, mrn=1130296,\n",
    "#                    label2='Left Bundle Branch Block')\n",
    "\n",
    "# reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "#                                     phecode_file='../../phecodes/PheCode_1182.txt',\n",
    "#                                     out_path='../../ecg_phecode_reconstruct/arf', \n",
    "#                     scalar=3.0, mrn=3467344, label2='Acute Renal Failure')\n",
    "\n",
    "\n",
    "# reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "#                                     phecode_file='../../phecodes/PheCode_798.txt',\n",
    "#                                     out_path='../../ecg_phecode_reconstruct/lbbb', \n",
    "#                     scalar=1.0, mrn=3467344,\n",
    "#                    label2='AV block')\n",
    "\n",
    "# reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "#                                     phecode_file='../../phecodes/PheCode_793.txt',\n",
    "#                                     out_path='../../ecg_phecode_reconstruct/lbbb', \n",
    "#                     scalar=4.0, mrn=1130296,\n",
    "#                    label2='HCM', centroid_method=True)\n",
    "\n",
    "# reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "#                                     phecode_file='../../phecodes/PheCode_955.txt',\n",
    "#                                     out_path='../../ecg_phecode_reconstruct/lbbb', \n",
    "#                     scalar=2.0, mrn=1130296,\n",
    "#                    label2='Chronic Bronchitis')\n",
    "\n",
    "\n",
    "\n",
    "# reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "#                                     phecode_file='../../phecodes/PheCode_1053.txt',\n",
    "#                                     out_path='../../ecg_phecode_reconstruct/lbbb', \n",
    "#                     scalar=5.0, mrn=3467344,\n",
    "#                    label2='GERD')\n",
    "\n",
    "# reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "#                                     phecode_file='../../phecodes/PheCode_545.txt',\n",
    "#                                     out_path='../../ecg_phecode_reconstruct/lbbb', \n",
    "#                     scalar=4.0, mrn=1130296,\n",
    "#                    label2='Obstructive Sleep Apnea')\n",
    "\n",
    "# reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "#                                     phecode_file='../../phecodes/PheCode_370.txt',\n",
    "#                                     out_path='../../ecg_phecode_reconstruct/lbbb', \n",
    "#                     scalar=2.0, mrn=1130296,\n",
    "#                    label2='Hyperpotassemia')\n",
    "\n",
    "# reconstruct_phecode(decoders, args.tensor_maps_in[0], latent_df, latent_df, latent_cols, \n",
    "#                                     phecode_file='../../phecodes/PheCode_371.txt',\n",
    "#                                     out_path='../../ecg_phecode_reconstruct/lbbb', \n",
    "#                     scalar=12.0, mrn=1130296,\n",
    "#                    label2='Hypopotassemia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187555c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "def plot_phecode(phecode_file,tensor_map, n=12,\n",
    "                 label1='Normal',\n",
    "                    label2='Reconstruction',\n",
    "                 hd5s='/home/samuel.friedman/trained_models/mgh_ecg_medians/inferred_hd5s/'):\n",
    "    if 'PheCode' not in phecode_file:\n",
    "        return\n",
    "    df = pd.read_csv(phecode_file, sep='\\t')\n",
    "    phecode_name = f'phe_{df.iloc[0].phenotype}'.replace('.', '_').replace(' ', '')\n",
    "    ratio = df.has_disease.sum() / len(df.has_disease)\n",
    "    links = pd.read_csv('../../mrn_linker.txt', sep='\\t')\n",
    "    df = pd.merge(df, links, left_on='linker_id', right_on='LINKER_ID', how='inner')\n",
    "    df = df.rename(columns={'has_disease': phecode_name})\n",
    "\n",
    "    hit = df.loc[df[phecode_name] >= 1]\n",
    "    miss = df.loc[df[phecode_name] < 1]\n",
    "    i = 0\n",
    "    ecgs = []\n",
    "    for _,row in hit.iterrows():\n",
    "        f = os.path.join(hd5s, f'{row.MRN}.hd5')\n",
    "        if os.path.exists(f):\n",
    "            with h5py.File(f, 'r') as hd5:\n",
    "                ecgs.append(np.array(hd5['ecg_rest_median_raw_10_prediction'], dtype=np.float32))\n",
    "                print(f'MRN chosen {row.MRN}')\n",
    "            i += 1\n",
    "            if i >= n:\n",
    "                break\n",
    "    ecgs = np.array(ecgs)\n",
    "    yp = np.median(ecgs, axis=0)\n",
    "    \n",
    "    i = 0\n",
    "    ecgs = []\n",
    "    for _,row in miss.iterrows():\n",
    "        f = os.path.join(hd5s, f'{row.MRN}.hd5')\n",
    "        if os.path.exists(f):\n",
    "            with h5py.File(f, 'r') as hd5:\n",
    "                ecgs.append(np.array(hd5['ecg_rest_median_raw_10_prediction'], dtype=np.float32))\n",
    "            i += 1\n",
    "            if i >= n:\n",
    "                break\n",
    "    ecgs = np.array(ecgs)\n",
    "    y = np.median(ecgs, axis=0)\n",
    "    \n",
    "    index2channel = {v: k for k, v in tensor_map.channel_map.items()}\n",
    "    leads = ['I', 'aVR', 'V1', 'V4', \n",
    "             'II', 'aVL', 'V2', 'V5', \n",
    "             'III', 'aVF', 'V3', 'V6', ]\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 4, figsize=(18, 12), dpi=300, sharey=True)\n",
    "    channel_map = {\n",
    "    'I': 0, 'II': 1, 'III': 2, 'V1': 3, 'V2': 4, 'V3': 5,\n",
    "    'V4': 6, 'V5': 7, 'V6': 8, 'aVF': 9, 'aVL': 10, 'aVR': 11,\n",
    "}\n",
    "    for j, (ax, lead) in enumerate(zip(axes.ravel(), leads)):\n",
    "        ax.plot(y[:, channel_map[lead]], c=\"blue\", label=label1)\n",
    "        ax.plot(yp[:, channel_map[lead]], c=\"red\", lw=2, alpha=0.7, label=label2)\n",
    "        ax.set_title(f\"Lead: {lead}\")\n",
    "        ax.legend()\n",
    "        #axes[j, 1].legend()\n",
    "        ax.legend()\n",
    "    plt.tight_layout()\n",
    "    #plt.show()   \n",
    "    print(f'Plotted ECGs for {phecode_name} positive N: {len(hit)} negative N: {len(miss)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_phecode('../../phecodes/PheCode_388.txt', args.tensor_maps_in[0], label2='Obesity')\n",
    "plot_phecode('../../phecodes/PheCode_806.txt', args.tensor_maps_in[0], label2='Left Bundle Branch Block')\n",
    "# plot_phecode('../../phecodes/PheCode_1182.txt', args.tensor_maps_in[0], label2='Acute Renal Failure')\n",
    "# plot_phecode('../../phecodes/PheCode_798.txt', args.tensor_maps_in[0], label2='AV Block')\n",
    "# plot_phecode('../../phecodes/PheCode_793.txt', args.tensor_maps_in[0], label2='Hypertrophic obstructive cardiomyopathy')\n",
    "\n",
    "# plot_phecode('../../phecodes/PheCode_955.txt', args.tensor_maps_in[0], label2='Chronic Bronchitis')\n",
    "\n",
    "# plot_phecode('../../phecodes/PheCode_545.txt', args.tensor_maps_in[0], label2='Obstructive Sleep Apnea')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('../../mrn_linker.txt', sep='\\t')\n",
    "links.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee7d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import seaborn as sb\n",
    "def write_phecode(latent_df, phecode_file, out_path):\n",
    "    if 'PheCode' not in phecode_file:\n",
    "        return\n",
    "    df = pd.read_csv(phecode_file, sep='\\t')\n",
    "    phecode_name = f'phe_{df.iloc[0].phenotype}'.replace('.', '_').replace(' ', '')\n",
    "    #print(f'phe file {phecode_file} has name: {phecode_name} cases: {df.has_disease.sum()}')\n",
    "    ratio = df.has_disease.sum() / len(df.has_disease)\n",
    "    print(f'phecode_name  {phecode_name} ratio: {ratio} len phe: {len(df)}')\n",
    "    print([c for c in df if 'latent' not in c] )   #phecode_name, 1, 0\n",
    "    df = df.rename(columns={'has_disease': phecode_name})\n",
    "    latent_df = pd.merge(latent_df, df, left_on='LINKER_ID', right_on='linker_id', how='inner')\n",
    "    print(f'MERGED phecode_name  {phecode_name}')\n",
    "    latent_df.info()\n",
    "    latent_df[[c for c in latent_df if 'latent' not in c]].to_csv(f'{out_path}.csv', index=False)\n",
    "\n",
    "     \n",
    "\n",
    "    \n",
    "def histogram_phecode(latent_df, phecode_file, phecode_title, out_path, random_permute=False):\n",
    "    if 'PheCode' not in phecode_file:\n",
    "        return\n",
    "    df = pd.read_csv(phecode_file, sep='\\t')\n",
    "    phecode_name = f'phe_{df.iloc[0].phenotype}'.replace('.', '_').replace(' ', '')\n",
    "    #print(f'phe file {phecode_file} has name: {phecode_name} cases: {df.has_disease.sum()}')\n",
    "    ratio = df.has_disease.sum() / len(df.has_disease)\n",
    "    print(f'phecode_name  {phecode_name} ratio: {ratio} len phe: {len(df)}')\n",
    "    print([c for c in df if 'latent' not in c] )   #phecode_name, 1, 0\n",
    "    df = df.rename(columns={'has_disease': phecode_name})\n",
    "    latent_df = pd.merge(latent_df, df, left_on='LINKER_ID', right_on='linker_id', how='inner')\n",
    "    print(f'MERGED phecode_name  {phecode_name}')\n",
    "    latent_df.info()\n",
    "    hit = latent_df.loc[latent_df[phecode_name] >= 1]\n",
    "    miss = latent_df.loc[latent_df[phecode_name] < 1]\n",
    "    if random_permute:\n",
    "        hit = latent_df.sample(n=len(hit))\n",
    "        miss = latent_df.drop(hit.index)\n",
    "    hit_np = hit[latent_cols].to_numpy()\n",
    "    miss_np = miss[latent_cols].to_numpy()\n",
    "\n",
    "    phenotype_vector = unit_vector(positroid - negatroid)\n",
    "    space = latent_df[latent_cols].to_numpy()\n",
    "#     hit_np -= np.mean(space)\n",
    "#     hit_np /= np.std(space)\n",
    "#     miss_np -= np.mean(space)\n",
    "#     miss_np /= np.std(space)  \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 4), dpi=300)\n",
    "    hit_dots = np.array([np.dot(phenotype_vector, v) for v in hit_np])\n",
    "    miss_dots = np.array([np.dot(phenotype_vector, v) for v in miss_np])\n",
    "    dists = [list(hit_dots), list(miss_dots)]\n",
    "    if random_permute:\n",
    "        labels = [f'{phecode_title} Present, n={len(hit_dots)}', \n",
    "                  f'{phecode_title} Absent, n={len(miss_dots)}']\n",
    "        ax.set_xlabel(f'Position along random vector')\n",
    "    else:\n",
    "        labels = [f'{phecode_title} Present, n={len(hit_dots)}', f'{phecode_title} Absent, n={len(miss_dots)}']\n",
    "        ax.set_xlabel(f'Position along {phecode_title} vector')\n",
    "    \n",
    "    t_stat, p_val = stats.ttest_ind(hit_dots, miss_dots, equal_var = False)\n",
    "    for i, data in enumerate(dists):\n",
    "        #plt.hist(data, bins = 40, label=labels[i], alpha=0.5, density=True)\n",
    "        sb.kdeplot(np.array(data), bw=0.25, label=labels[i], ax=ax)\n",
    "        # Title and labels\n",
    "        ax.set_title(f'{phecode_title}')# T-Test P-Value {p_val:0.2E}')\n",
    "        \n",
    "        ax.set_ylabel('Normalized density of distribution')\n",
    "        ax.legend()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "def write_phecode_centroid(latent_df, phecode_file, out_path):\n",
    "    if 'PheCode' not in phecode_file:\n",
    "        return\n",
    "    df = pd.read_csv(phecode_file, sep='\\t')\n",
    "    phecode_name = f'phe_{df.iloc[0].phenotype}'.replace('.', '_').replace(' ', '')\n",
    "    #print(f'phe file {phecode_file} has name: {phecode_name} cases: {df.has_disease.sum()}')\n",
    "    ratio = df.has_disease.sum() / len(df.has_disease)\n",
    "    print(f'phecode_name  {phecode_name} ratio: {ratio} len phe: {len(df)}')\n",
    "    #print([c for c in df if 'latent' not in c] )   #phecode_name, 1, 0\n",
    "    df = df.rename(columns={'has_disease': phecode_name})\n",
    "    latent_df = pd.merge(latent_df, df, left_on='LINKER_ID', right_on='linker_id', how='inner')\n",
    "    #print(f'MERGED phecode_name  {phecode_name}')\n",
    "    #latent_df.info()\n",
    "    hit = latent_df.loc[latent_df[phecode_name] >= 1]\n",
    "    miss = latent_df.loc[latent_df[phecode_name] < 1]\n",
    "    hit_np = hit[latent_cols].to_numpy()\n",
    "    miss_np = miss[latent_cols].to_numpy()\n",
    "    space = latent_df[latent_cols].to_numpy()\n",
    "    space -= np.mean(space)\n",
    "    space /= np.std(space)\n",
    "    hit_np -= np.mean(space)\n",
    "    hit_np /= np.std(space)\n",
    "    miss_np -= np.mean(space)\n",
    "    miss_np /= np.std(space)\n",
    "    print(f'len(hit): {len(hit)} len(miss): {len(miss)}')\n",
    "    positroid = np.mean(hit_np, axis=0)\n",
    "    negatroid = np.mean(miss_np, axis=0)\n",
    "    phenotype_vector = positroid - negatroid\n",
    "    print(f'pearsonr: {pearsonr(positroid, negatroid)}')\n",
    "    #latent_df['dot'] = np.dot(latent_df[latent_cols].to_numpy(), phenotype_vector)\n",
    "    #latent_df = latent_df.sort_values(by=f'dot', ascending=False)\n",
    "    #latent_df[f'{phecode_name}_percentile'] = (latent_df[f'dot'].argsort().astype(np.float32)/len(latent_df))*100\n",
    "\n",
    "    dist = (space - positroid)**2\n",
    "    #print(f'dist: {dist.shape}')\n",
    "    dist = np.sum(dist, axis=1)\n",
    "    #print(f'dist: {dist.shape}')\n",
    "    dist = np.sqrt(dist)\n",
    "    #print(f'dist: {dist.shape}')\n",
    "    latent_df[f'{phecode_name}_positroid_distance'] = dist\n",
    "    latent_df = latent_df.sort_values(by=f'{phecode_name}_positroid_distance')\n",
    "    latent_df[f'{phecode_name}_positroid_percentile'] = (latent_df[f'{phecode_name}_positroid_distance'].argsort().astype(np.float32)/len(latent_df))*100\n",
    "    \n",
    "#     d2 = (space - negatroid)**2\n",
    "#     d2 = np.sum(d2, axis=1)\n",
    "#     d2 = np.sqrt(d2)\n",
    "#     latent_df[f'{phecode_name}_negatroid_distance'] = d2\n",
    "    print(f\"Distance pearsonr: {pearsonr(latent_df[f'{phecode_name}_positroid_distance'], latent_df[f'{phecode_name}_positroid_distance'])}\")\n",
    "    #latent_df[f'{phecode_name}_negatroid_percentile'] = (latent_df[f'{phecode_name}_negatroid_distance'].argsort().astype(np.float32)/len(latent_df))*100\n",
    "    latent_df[[c for c in latent_df if 'latent' not in c]].to_csv(f'{out_path}.csv', index=False)\n",
    "    return latent_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd8010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = write_phecode_centroid(latent_df, phecode_file='../../phecodes/PheCode_806.txt',\n",
    "              out_path='../../phecode_centroids/lbbb_phecode_426_32_new2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38128aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "histogram_phecode(latent_df, phecode_file='../../phecodes/PheCode_388.txt', phecode_title='Obesity',\n",
    "              out_path='../../mgh_Obesity_phecode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe629ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_phecode(latent_df, phecode_file='../../phecodes/PheCode_806.txt', phecode_title='Left Bundle Branch Block',\n",
    "              out_path='../../mgh_lbbb_phecode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phecode(latent_df, phecode_file='../../phecodes/PheCode_388.txt',\n",
    "              out_path='../../mgh_obesity_phecode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4843877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phe2file = {}\n",
    "test_phe_folder = '../../phecodes_bwh/'\n",
    "for phe_file in sorted(os.listdir(test_phe_folder)):\n",
    "    df = pd.read_csv(test_phe_folder + phe_file, sep='\\t')\n",
    "    phecode_name = f'{df.iloc[0].phenotype}'.replace('.', '_').replace(' ', '')\n",
    "    phe2file[phecode_name] = f'../../phecodes/{phe_file}'\n",
    "    print(f'phe_file  {phe_file}   {phecode_name}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eceb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "phe_list=[ '401', '426_32',\n",
    "'571',\n",
    "'572',\n",
    "          '394_1',\n",
    "'425',\n",
    "'428_1',\n",
    "'411_2',\n",
    "          '411_4',\n",
    "'427',\n",
    " '427_2',\n",
    "          '427_12',\n",
    "          '428_4',\n",
    "'425_11',\n",
    "'496',\n",
    "'509',\n",
    "'495',\n",
    "          '442_1',\n",
    "'502',\n",
    "'496_3',\n",
    "'476',\n",
    "'512',\n",
    "'585',\n",
    "'580_1',\n",
    "'600',\n",
    "          '496_3', '250', '272_1', '274_1', '585', '600', '574', '562', '327_3', '345', '331_9', '316', '285', '286'\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3df2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phecode_centroid(latent_df, phecode_file=phe2file[code], \n",
    "                           out_path=f'../../phecode_centroids_new/mgh_phecode_{code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in phe_list:\n",
    "    write_phecode_centroid(latent_df, phecode_file=phe2file[code], \n",
    "                           out_path=f'../../phecode_centroids_v2022_11_11/mgh_phecode_{code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7caa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in phe2file:\n",
    "    write_phecode_centroid(latent_df, phecode_file=phe2file[code], \n",
    "                           out_path=f'../../phecode_centroids/mgh_phecode_{code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = write_phecode_centroid(latent_df, phecode_file='../../phecodes/PheCode_806.txt',\n",
    "              out_path='../../phecode_centroids/lbbb_phecode_426_32_new2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d09af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pearsonr(df.phe_426_32_positroid_distance, df.phe_426_32_negatroid_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17415779",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phecode(latent_df, phecode_file='../../phecodes/PheCode_388.txt',\n",
    "              out_path='../../mgh_obesity_phecode_278.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5fb263",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phecode(latent_df, phecode_file='../../phecodes/PheCode_830.txt',\n",
    "              out_path='../../mgh_congestive_hf_phecode_428')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d98d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phecode(latent_df, phecode_file='../../phecodes/PheCode_806.txt',\n",
    "              out_path='../../mgh_lbbb_phecode_426.32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phecode(latent_df, phecode_file='../../phecodes/PheCode_760.txt',\n",
    "              out_path='../../mgh_hypertension_phecode_401')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba227c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
