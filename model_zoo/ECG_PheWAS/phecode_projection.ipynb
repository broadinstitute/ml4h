{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "from statsmodels.tools.sm_exceptions import PerfectSeparationError\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Ridge\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, roc_auc_score\n",
    "from sklearn.metrics import brier_score_loss, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from ml4h_ccds.data_descriptions.util import download_s3_if_not_exists\n",
    "from ml4h.explorations import latent_space_dataframe\n",
    "\n",
    "# IPython imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confounder_vector(label_header, df, indexes):\n",
    "    clf = Ridge(normalize=True, max_iter=50000) #ElasticNet(max_iter=50000, normalize=True)#Ridge(normalize=True, max_iter=10000)#ElasticNet(max_iter=50000, normalize=True) #LinearRegression() #LinearRegression(normalize=True)   #ElasticNet(normalize=True)\n",
    "    clf.fit(df[indexes], df[label_header])\n",
    "    train_score = clf.score(df[indexes], df[label_header])\n",
    "    return clf.coef_, train_score\n",
    "\n",
    "\n",
    "def confounder_matrix(adjust_cols, df, indexes):\n",
    "    vectors = []\n",
    "    scores = {}\n",
    "    for col in adjust_cols:\n",
    "        cv, r2 = confounder_vector(col, df, indexes)\n",
    "        scores[col] = r2\n",
    "        vectors.append(cv)\n",
    "    return np.array(vectors), scores\n",
    "\n",
    "\n",
    "def iterative_subspace_removal(adjust_cols, latent_df, latent_cols, r2_thresh=0.01): \n",
    "    new_cols = latent_cols\n",
    "    new_adjust_cols = adjust_cols\n",
    "    space = latent_df[latent_cols].to_numpy()\n",
    "    iteration = 0\n",
    "    while len(new_adjust_cols) > 0 and space.shape[-1] > len(new_adjust_cols):\n",
    "        cfm, scores = confounder_matrix(new_adjust_cols, latent_df, new_cols)\n",
    "        u, s, vt = np.linalg.svd(cfm, full_matrices=True)\n",
    "        nspace = np.matmul(space, vt[:, len(new_adjust_cols):])\n",
    "        new_cols=[]\n",
    "        for i in range(nspace.shape[-1]):\n",
    "            col = f'new_latent_{iteration}_{i}'\n",
    "            new_cols.append(col)\n",
    "            latent_df[col] = nspace[:, i]\n",
    "        \n",
    "        iteration += 1\n",
    "        space = nspace\n",
    "        new_adjust_cols = [col for col, score in scores.items() if score > r2_thresh]\n",
    "        print(f'Scores were {scores}, remaining columns are {new_adjust_cols}')\n",
    "        print(f'After iteration {iteration} Space shape is: {space.shape}')\n",
    "    return new_cols\n",
    "\n",
    "def stratify_and_project_latent_space(stratify_column, stratify_thresh, stratify_std, \n",
    "                                      latent_cols, adjust_cols, latent_df, test_df, component_folder,\n",
    "                                      manova=False, permute=0, save_components=True, histograms=False):\n",
    "    \n",
    "    if manova:\n",
    "        formula = f\"{'+'.join(latent_cols)} ~ {stratify_column}\"\n",
    "        maov = MANOVA.from_formula(formula, data=latent_df)\n",
    "        test = maov.mv_test()\n",
    "        s = test[stratify_column]['stat']\n",
    "        return s['Pr > F'][0]   \n",
    "    \n",
    "    hit = latent_df.loc[latent_df[stratify_column] >= stratify_thresh+(1*stratify_std)]\n",
    "    miss = latent_df.loc[latent_df[stratify_column] < stratify_thresh-(1*stratify_std)]\n",
    "    hit_np = hit[latent_cols].to_numpy()\n",
    "    miss_np = miss[latent_cols].to_numpy()\n",
    "    miss_mean_vector = np.mean(miss_np, axis=0)\n",
    "    hit_mean_vector = np.mean(hit_np, axis=0)\n",
    "    angle = angle_between(miss_mean_vector, hit_mean_vector)\n",
    "    space = test_df[latent_cols].to_numpy()\n",
    "    space -= np.mean(space)\n",
    "    space /= np.std(space)\n",
    "    phenotype_vector = unit_vector(hit_mean_vector-miss_mean_vector)\n",
    "    all_dots = np.array([np.dot(phenotype_vector, v) for v in space])\n",
    "    all_phenotypes = test_df[stratify_column].to_numpy()\n",
    "    if permute > 0:\n",
    "        for i in range(len(all_phenotypes)):\n",
    "            if np.random.random() < permute:\n",
    "                all_phenotypes[i] = 1-all_phenotypes[i]\n",
    "    if len(adjust_cols) > 0:\n",
    "        all_adjustments = test_df[adjust_cols].to_numpy()\n",
    "        all_data = np.column_stack([all_phenotypes, all_adjustments, np.ones(all_dots.shape[0])])\n",
    "        formula = f'phecode ~ {\" + \".join(adjust_cols)} + component'\n",
    "        adjust_formula = f'phecode ~ {\" + \".join(adjust_cols)}'\n",
    "    else:\n",
    "        all_data = np.column_stack([all_phenotypes, np.ones(all_dots.shape[0])])\n",
    "        formula = f'phecode ~ component'\n",
    "\n",
    "    data = {'component': all_dots, 'phecode': all_phenotypes}\n",
    "    for i, col in enumerate(adjust_cols):\n",
    "        data[col] = all_adjustments[:, i]\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    try:\n",
    "        results = smf.logit(formula, data=df).fit(maxiter=200, disp=False)\n",
    "        \n",
    "        preds = results.predict(df)\n",
    "        results2 = smf.logit(adjust_formula, data=df).fit(maxiter=200, disp=False)\n",
    "        preds2 = results2.predict(df)\n",
    "        auc_w_component = roc_auc_score(all_phenotypes, preds)\n",
    "        auc_no_component = roc_auc_score(all_phenotypes, preds2)\n",
    "        smf_ols_p_value = float(results.summary2().tables[1]['P>|z|']['component'])\n",
    "        smf_ols_t_stat = float(results.summary2().tables[1]['z']['component'])\n",
    "\n",
    "        if histograms and -np.log10(results.summary2().tables[1]['P>|z|']['component']) > 10:\n",
    "            fig, ax = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "            hit_dots = all_dots[all_phenotypes == 1]\n",
    "            miss_dots = all_dots[all_phenotypes == 0]\n",
    "            dists = [list(hit_dots), list(miss_dots)]\n",
    "            labels = [f'{stratify_column} n={len(hit_dots)}', f'No {stratify_column} n={len(miss_dots)}']\n",
    "            for i, data in enumerate(dists):\n",
    "                #plt.hist(data, bins = 40, label=labels[i], alpha=0.5, density=True)\n",
    "                sb.kdeplot(np.array(data), bw=0.5, label=labels[i], ax=ax)\n",
    "                # Title and labels\n",
    "                ax.set_title(f'{stratify_column}')\n",
    "                ax.set_xlabel(f'Component in direction of {stratify_column} vector')\n",
    "                ax.set_ylabel('Density')\n",
    "            ax.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        return results.summary2().tables[1], phenotype_vector, auc_w_component, auc_no_component\n",
    "    except (np.linalg.LinAlgError, PerfectSeparationError) as e:\n",
    "        print(f'Phecode {stratify_column} Failed')\n",
    "        return None, None, None, None\n",
    "       \n",
    "def phewas_feature(stratify_column, stratify_thresh, stratify_std, feature_col, \n",
    "                   adjust_cols, test_df, component_folder):   \n",
    "    all_dots = test_df[feature_col].to_numpy()\n",
    "    all_phecodes = test_df[stratify_column].to_numpy()\n",
    "\n",
    "    if len(adjust_cols) > 0:\n",
    "        all_adjustments = test_df[adjust_cols].to_numpy()\n",
    "        formula = f'phecode ~ {\" + \".join(adjust_cols)} + component' \n",
    "    else:\n",
    "        formula = f'phecode ~ component'\n",
    "    \n",
    "    \n",
    "    data = {'component': all_dots, 'phecode': all_phecodes}\n",
    "    for i, col in enumerate(adjust_cols):\n",
    "        data[col] = all_adjustments[:, i]\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    try:\n",
    "        results = smf.logit(formula, data=df).fit(disp=False)\n",
    "        stat_key = 'z'\n",
    "        smf_ols_p_value = float(results.summary2().tables[1][f'P>|{stat_key}|']['component'])\n",
    "        smf_ols_t_stat = float(results.summary2().tables[1][f'{stat_key}']['component'])\n",
    "        return results.summary2().tables[1], None, None, None\n",
    "    except (np.linalg.LinAlgError, statsmodels.tools.sm_exceptions.PerfectSeparationError) as e:\n",
    "        print(f'Phecode {stratify_column} Failed')\n",
    "        return None, None, None, None\n",
    "    \n",
    "def merge_and_stratify_phecode_file(latent_df, test_df, latent_cols, adjust_cols, \n",
    "                                    phecode_file, test_phecode_file, min_cases, \n",
    "                                    component_folder, permute=False):\n",
    "    \n",
    "    if 'PheCode' not in phecode_file:\n",
    "        return None, None, None, None, None, None\n",
    "    df = pd.read_csv(phecode_file, sep='\\t')\n",
    "    phecode_name = f'phe_{df.iloc[0].phenotype}'.replace('.', '_').replace(' ', '')\n",
    "    #print(f'phe file {phecode_file} has name: {phecode_name} cases: {df.has_disease.sum()}')\n",
    "    ratio = df.has_disease.sum() / len(df.has_disease)\n",
    "    if (df.has_disease.sum() > min_cases and min_cases > 1) or ratio > min_cases:\n",
    "        df = process_phecode_df(df, phecode_name)\n",
    "        latent_df[\"LINKER_ID\"] = latent_df[\"LINKER_ID\"].astype(int)\n",
    "        latent_df = pd.merge(latent_df, df, left_on='LINKER_ID', right_on='linker_id', how='inner')\n",
    "        \n",
    "        test_phe_df = pd.read_csv(test_phecode_file, sep='\\t')\n",
    "        test_phe_df = process_phecode_df(test_phe_df, phecode_name)\n",
    "        test_df[\"LINKER_ID\"] = test_df[\"LINKER_ID\"].astype(int)\n",
    "        test_df = pd.merge(test_df, test_phe_df, left_on='LINKER_ID', right_on='linker_id', how='inner')\n",
    "        if len(latent_df[phecode_name].value_counts()) > 1 and latent_df[phecode_name].value_counts()[1] > min_cases:\n",
    "            if len(latent_cols) == 1:\n",
    "                results, vector, auc1, auc2 = phewas_feature(phecode_name, 1, 0, latent_cols[0], adjust_cols, \n",
    "                                                 test_df, component_folder)\n",
    "            else:\n",
    "                results, vector, auc1, auc2 = stratify_and_project_latent_space(phecode_name, 1, 0, latent_cols, adjust_cols, \n",
    "                                              latent_df, test_df, component_folder, permute=permute,\n",
    "                                              save_components=False, histograms=False)                \n",
    "            return results, phecode_name, vector, test_phe_df[phecode_name].sum(), auc1, auc2\n",
    "    return None, None, None, None, None, None\n",
    "         \n",
    "    \n",
    "def process_phecode_df(df, phecode_name):\n",
    "    df = df.rename(columns={\"has_disease\": phecode_name})\n",
    "    df['age_sqr'] = df.partners_ecg_age * df.partners_ecg_age\n",
    "    for c in [\"linker_id\", \"partners_ecg_age\", \"white\"]:\n",
    "        df[c] = df[c].astype(np.float64)\n",
    "    df['age_sqr'] = df.partners_ecg_age * df.partners_ecg_age\n",
    "    df['sex_int'] = (df.sex == 'Male').astype(int)\n",
    "    return df\n",
    "\n",
    "def merge_and_stratify_by_code_folder(latent_df, test_df, latent_cols, adjust_cols, component_folder,\n",
    "                                      phe_folder='./phecodes/', test_phe_folder='./phecodes/', \n",
    "                                      min_cases=20, permute=False):\n",
    "    ses = {}\n",
    "    betas = {}\n",
    "    p_vals = {}\n",
    "    counts = {}\n",
    "    vectors = {}\n",
    "    auc1 = {}\n",
    "    auc2 = {}\n",
    "    for phe_file in sorted(os.listdir(phe_folder)):\n",
    "        results, name, vector, n, a1, a2 = merge_and_stratify_phecode_file(latent_df, test_df, latent_cols, \n",
    "                                                                        adjust_cols, phe_folder + phe_file, \n",
    "                                                                        test_phe_folder + phe_file, \n",
    "                                                                        min_cases, component_folder, permute)\n",
    "        if results is not None:\n",
    "            counts[name] = n\n",
    "            p_vals[name] = results['P>|z|']['component']\n",
    "            betas[name] = results['Coef.']['component']\n",
    "            ses[name] = results['Std.Err.']['component']\n",
    "            vectors[name] = vector\n",
    "            auc1[name] = a1\n",
    "            auc2[name] = a2\n",
    "            print(f'Phe:{name}, N: {n}, P: {p_vals[name]:0.3E} betas {betas[name]:0.3f} std err: {ses[name]:0.3f}')\n",
    "            print(f'\\tPhe:{name}, AUC w ECG component:{auc1[name]:0.3f} AUC no ECG:{auc2[name]:0.3f}')\n",
    "    return p_vals, betas, ses, counts, vectors, auc1, auc2\n",
    "\n",
    "\n",
    "\n",
    "def merge_code_folder(latent_df, phe_folder='/home/sam/select_phecodes/', min_cases=4, max_codes=35):\n",
    "    phe_codes = []\n",
    "    for phe_file in sorted(os.listdir(phe_folder)):\n",
    "        latent_df, phe_code = merge_phecode_file(latent_df, phe_folder + phe_file, min_cases)\n",
    "        if phe_code in latent_df:\n",
    "            print(f'{phe_code} has enough prevalence: {latent_df[phe_code].value_counts()[1]}')\n",
    "            phe_codes.append(phe_code)\n",
    "            if len(phe_codes) >= max_codes:\n",
    "                break\n",
    "    return latent_df, phe_codes\n",
    "\n",
    "def ttest_feature(feature, snp):\n",
    "    ref = latent_df[latent_df[snp] == 0][feature].dropna().to_numpy(dtype=np.float32)\n",
    "    het = latent_df[latent_df[snp] == 1][feature].dropna().to_numpy(dtype=np.float32)\n",
    "    hom = latent_df[latent_df[snp] == 2][feature].dropna().to_numpy(dtype=np.float32)\n",
    "    var = latent_df[(latent_df[snp] == 1) | (latent_df[snp] == 2)][feature].dropna().to_numpy(dtype=np.float32)\n",
    "    t2, p2 = stats.ttest_ind(var, ref, equal_var = False)\n",
    "    print(f\"Reference n={len(ref)}, Heterozygous n={len(het)}, Homozygous n={len(hom)}, Non-reference n={len(var)}\")\n",
    "    t_het_ref, p_het_ref = stats.ttest_ind(het, ref, equal_var = False)\n",
    "    print(f\"Ref v Het {feature}:\\t\\t T-Statistic = {t_het_ref:0.2f}, P-Value = {p_het_ref}\")\n",
    "    t_hom_ref, p_hom_ref = stats.ttest_ind(hom, ref, equal_var = False)\n",
    "    print(f\"Ref v Hom {feature}:\\t\\t T-Statistic = {t_hom_ref:0.2f}, P-Value = {p_hom_ref}\")\n",
    "    t_var_ref, p_var_ref = stats.ttest_ind(var, ref, equal_var = False)\n",
    "    print(f\"Ref v Var {feature}:\\t\\t T-Statistic = {t_var_ref:0.2f}, P-Value = {p_var_ref}\\n\")\n",
    "    return {#'T-test REF vs HET '+snp: (t_het_ref, p_het_ref), \n",
    "            #'T-test REF vs HOM '+snp: (t_hom_ref, p_hom_ref),\n",
    "            'T-test REF vs VAR '+snp: (t_var_ref, p_var_ref)}\n",
    "    \n",
    "def plot_nested_dictionary(all_scores):\n",
    "    n = 4\n",
    "    eps = 1e-300\n",
    "    for model in all_scores:\n",
    "        n = max(n, len(all_scores[model]))\n",
    "    cols = max(2, int(math.ceil(math.sqrt(n))))\n",
    "    rows = max(2, int(math.ceil(n / cols)))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 3), sharex=True)\n",
    "    renest = defaultdict(dict)\n",
    "    errors = defaultdict(dict)\n",
    "    lens = {}\n",
    "    max_tstat = 0\n",
    "    max_pval = 0\n",
    "    for model in all_scores:\n",
    "        for metric in all_scores[model]:\n",
    "            renest[metric][model] = all_scores[model][metric][0]\n",
    "            errors[metric][model] = all_scores[model][metric][1]\n",
    "            lens[metric] = all_scores[model][metric][2]\n",
    "            max_tstat = max(abs(all_scores[model][metric][0]), max_tstat)\n",
    "            max_pval = max(-np.log10(all_scores[model][metric][1]+eps), max_pval)\n",
    "    for metric, ax in zip(renest, axes.ravel()):\n",
    "         \n",
    "        models = [k for k,v in sorted(renest[metric].items(), key=lambda x: x[0].lower())]\n",
    "        tstats = [abs(v) for k,v in sorted(renest[metric].items(), key=lambda x: x[0].lower())]\n",
    "        pvalues = [-np.log10(v) if v > 1e-4800 else 500 for k,v in sorted(errors[metric].items(), key=lambda x: x[0].lower())]\n",
    "        y_pos = np.arange(len(models))\n",
    "        x = np.linspace(0, 1, int(max_pval))\n",
    "        plt.imshow(x[:, np.newaxis], cmap=cm.jet)\n",
    "        cb = plt.colorbar(ax=ax, ticks=[0, 1.0])\n",
    "        cb.set_label('Negative Log P-Value')\n",
    "        cb.ax.set_yticklabels(['0', f'{max_pval:0.0f}'])\n",
    "        ax.barh(y_pos, tstats, color=[cm.jet(p/max_pval) for p in pvalues], align='center')\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(models)\n",
    "        ax.invert_yaxis()  # labels read top-to-bottom\n",
    "        ax.set_xlabel('T–Statistic')\n",
    "        ax.xaxis.set_tick_params(which='both', labelbottom=True)\n",
    "        ax.set_title(f'{metric}\\n n={lens[metric]}')\n",
    "            \n",
    "    plt.tight_layout()    \n",
    "    \n",
    "\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "            angle_between((1, 0, 0), (0, 1, 0))\n",
    "            90\n",
    "            angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            180\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0)) * 180 / 3.141592\n",
    "\n",
    "def get_phenotype_vector(stratify_column, stratify_thresh, stratify_std, latent_cols, latent_df):\n",
    "    hit = latent_df.loc[latent_df[stratify_column] >= stratify_thresh+stratify_std][latent_cols].to_numpy()\n",
    "    miss = latent_df.loc[latent_df[stratify_column] < stratify_thresh-stratify_std][latent_cols].to_numpy()\n",
    "    miss_mean_vector = np.mean(miss, axis=0)\n",
    "    hit_mean_vector = np.mean(hit, axis=0)\n",
    "    angle = angle_between(miss_mean_vector, hit_mean_vector)\n",
    "#     print(f'Angle between {stratify_column} and all others: {angle}, \\n'\n",
    "#           f'Hit shape {hit.shape}, miss:{miss.shape} threshold:{stratify_thresh}\\n'\n",
    "#           f'Distance: {np.linalg.norm(hit_mean_vector - miss_mean_vector):.3f}, '\n",
    "#           f'Hit std {np.std(hit, axis=1).mean():.3f}, miss std:{np.std(miss, axis=1).mean():.3f}\\n')\n",
    "    return hit_mean_vector - miss_mean_vector   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION_DIR = os.path.expanduser(\"~\")  # downloaded data will be stored here\n",
    "mgh_ecg_meta_path = download_s3_if_not_exists(\n",
    "    bucket_name='2017P001650',\n",
    "    bucket_path='csvs/06-25_explore_mgh.pq',\n",
    "    local_dir=SESSION_DIR,\n",
    ")\n",
    "bwh_ecg_meta_path = download_s3_if_not_exists(\n",
    "    bucket_name='2017P001650',\n",
    "    bucket_path='csvs/08-16_explore_bwh.pq',\n",
    "    local_dir=SESSION_DIR,\n",
    ")\n",
    "# load the wide file\n",
    "mgh_ecg_meta = pd.read_parquet(mgh_ecg_meta_path)\n",
    "bwh_ecg_meta = pd.read_parquet(bwh_ecg_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mgh_ecg_meta.info()\n",
    "# bwh_ecg_meta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgh_ecg_meta_path = download_s3_if_not_exists(\n",
    "    bucket_name='2017P001650',\n",
    "    bucket_path='csvs/mgh_c3po_ecgs.pq',\n",
    "    local_dir=SESSION_DIR,\n",
    ")\n",
    "bwh_ecg_meta_path = download_s3_if_not_exists(\n",
    "    bucket_name='2017P001650',\n",
    "    bucket_path='csvs/bwh_c3po_ecgs.pq',\n",
    "    local_dir=SESSION_DIR,\n",
    ")\n",
    "# load the wide file\n",
    "mgh_ecg_meta = pd.read_parquet(mgh_ecg_meta_path)\n",
    "bwh_ecg_meta = pd.read_parquet(bwh_ecg_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgh_ecg_meta['ecg_date'] = mgh_ecg_meta['datetime'].dt.date\n",
    "bwh_ecg_meta['ecg_date'] = bwh_ecg_meta['datetime'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e44cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./phecodes/PheCode_1016.txt', sep='\\t')\n",
    "bdf = pd.read_csv('./phecodes_bwh/PheCode_1016.txt', sep='\\t')\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('mrn_linker.txt', sep='\\t')\n",
    "# latent = pd.read_csv('mgh_drop_fuse_latent_space.csv')\n",
    "# latent_df = pd.merge(latent, links, left_on='MGH_MRN_0', right_on='MRN', how='inner')\n",
    "\n",
    "#lf='/home/samuel.friedman/trained_models/mgh_biosppy_median_autoencoder_256d_v2022_05_19/hidden_median_mgh_biosppy_median_autoencoder_256d_v2022_05_19.tsv'\n",
    "lf='/home/samuel.friedman/trained_models/mgh_biosppy_median_60bpm_autoencoder_256d_v2022_05_21/hidden_median_mgh_biosppy_median_60bpm_autoencoder_256d_v2022_05_21.tsv'\n",
    "#lf='/home/samuel.friedman/trained_models/mgh_biosppy_median_60bpm_lead_I_autoencoder_256d_v2022_05_24/hidden_median_mgh_biosppy_median_60bpm_lead_I_autoencoder_256d_v2022_05_24.tsv'\n",
    "\n",
    "#latent = pd.read_csv('./trained_models/ecg_2500_autoencoder_mgh_c3po_128d_v2021_12_17/mgh_latent_ecg_2500_autoencoder_mgh_c3po_128d_v2021_12_17.tsv', sep='\\t')\n",
    "#latent = pd.read_csv('./trained_models/mgh_ecg_rest_median_raw_10_autoencoder_256d_v2022_04_13/mgh_latent_mgh_ecg_rest_median_raw_10_autoencoder_256d_v2022_04_13.tsv', sep='\\t')\n",
    "#latent = pd.read_csv('./trained_models/mgh_ecg_rest_median_raw_10_lead_I_autoencoder_256d_v2022_04_09/mgh_latent_lead_I_mgh_ecg_rest_median_raw_10_lead_I_autoencoder_256d_v2022_04_09.tsv', sep='\\t')\n",
    "\n",
    "latent = pd.read_csv(lf, sep='\\t')\n",
    "\n",
    "latent_df = pd.merge(latent, links, left_on='sample_id', right_on='MRN', how='inner')\n",
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "latent_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37563527",
   "metadata": {},
   "outputs": [],
   "source": [
    "lf='/home/samuel.friedman/trained_models/bwh_biosppy_median_60bpm_autoencoder_256d_v2022_05_21/hidden_median_bwh_biosppy_median_60bpm_autoencoder_256d_v2022_05_21.tsv'\n",
    "#lf='/home/samuel.friedman/trained_models/bwh_biosppy_median_autoencoder_256d_v2022_05_19/hidden_median_bwh_biosppy_median_autoencoder_256d_v2022_05_19.tsv'\n",
    "#lf='/home/samuel.friedman/trained_models/bwh_biosppy_median_60bpm_lead_I_autoencoder_256d_v2022_05_24/hidden_median_bwh_biosppy_median_60bpm_lead_I_autoencoder_256d_v2022_05_24.tsv'\n",
    "#bwf_df = pd.read_csv('./trained_models/ecg_2500_autoencoder_mgh_c3po_128d_v2021_12_17/bwh_latent_ecg_2500_autoencoder_mgh_c3po_128d_v2021_12_17.tsv', sep='\\t')\n",
    "#bwf_df = pd.read_csv('./trained_models/mgh_ecg_lead_I_2500_std_autoencoder_v2022_03_28/bwh_latent_lead_I_mgh_ecg_lead_I_2500_std_autoencoder_v2022_03_28.tsv', sep='\\t')\n",
    "#bwf_df = pd.read_csv('./trained_models/mgh_ecg_rest_median_raw_10_autoencoder_256d_v2022_04_13/bwh_latent_mgh_ecg_rest_median_raw_10_autoencoder_256d_v2022_04_13.tsv', sep='\\t')\n",
    "#bwf_df = pd.read_csv('/home/samuel.friedman/trained_models/bwh_biosppy_median_ae_256d/hidden_median_bwh_biosppy_median_ae_256d.tsv', sep='\\t')\n",
    "bwf_df = pd.read_csv(lf, sep='\\t')\n",
    "\n",
    "bwh_links = pd.read_csv('hidden_inference_ecg_2500_hyperoptimized_autoencoder_mish_c3po_bwh_linked_dates.tsv', sep='\\t')\n",
    "bwf_df.info()\n",
    "bwh_df = pd.merge(bwf_df, bwh_links[['id', 'BWH_MRN_0']], left_on='sample_id', right_on='BWH_MRN_0', how='inner')\n",
    "bwh_df = bwh_df.rename(columns={\"id\": 'LINKER_ID'})\n",
    "bwf_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ec5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_phecode_df(df, 'phecode_name')\n",
    "latent_df[\"LINKER_ID\"] = latent_df[\"LINKER_ID\"].astype(int)\n",
    "latent_df = pd.merge(latent_df, df[['linker_id', 'partners_ecg_datetime']],  #, 'white', 'partners_ecg_age', 'sex'\n",
    "                     left_on='LINKER_ID', right_on='linker_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ce4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in bwh_df if 'latent' not in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in latent_df if 'latent' not in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df73c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf = process_phecode_df(bdf, 'phecode_name')\n",
    "bwh_df[\"LINKER_ID\"] = bwh_df[\"LINKER_ID\"].astype(int)\n",
    "bwh_df = pd.merge(bwh_df, bdf[['linker_id', 'partners_ecg_datetime']], #, 'white', 'partners_ecg_age', 'sex'\n",
    "                     left_on='LINKER_ID', right_on='linker_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e004af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bwh_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ed97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_latent_df = pd.merge(latent_df, mgh_ecg_meta, left_on=['sample_id'], \n",
    "                    right_on=['sample_id'], how='inner')\n",
    "# new_latent_df = pd.merge(latent_df, mgh_ecg_meta, left_on=['MRN'], \n",
    "#                      right_on=['sample_id'], how='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a767458",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_latent_df.ecg_date = new_latent_df.ecg_date.astype(str)\n",
    "new_latent_df.partners_ecg_datetime = new_latent_df.partners_ecg_datetime.astype(str)\n",
    "new_latent_df[['sample_id','ecg_date','partners_ecg_datetime', 'num_zeros']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_latent_df = new_latent_df[new_latent_df.ecg_date == new_latent_df.partners_ecg_datetime]\n",
    "\n",
    "keep_cols = [c for c in new_latent_df if 'latent' not in c]\n",
    "new_latent_df[keep_cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_latent_df['time'] = new_latent_df['ecg_date'].apply(lambda x: pd.to_datetime(x).value/10**17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f829741",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bwh_df = pd.merge(bwh_df, bwh_ecg_meta, left_on=['sample_id'], \n",
    "                     right_on=['sample_id'], how='inner')\n",
    "new_bwh_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12f9735",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bwh_df.ecg_date = new_bwh_df.ecg_date.astype(str)\n",
    "new_bwh_df.partners_ecg_datetime = new_bwh_df.partners_ecg_datetime.astype(str)\n",
    "\n",
    "#new_bwh_df = new_bwh_df[new_bwh_df.ecg_date == new_bwh_df.partners_ecg_datetime]\n",
    "new_bwh_df['time'] = new_bwh_df['ecg_date'].apply(lambda x: pd.to_datetime(x).value/10**17)\n",
    "new_bwh_df[['sample_id','ecg_date','partners_ecg_datetime', 'num_zeros']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ef121",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bwh_df['date_diff'] = pd.to_datetime(new_bwh_df.partners_ecg_datetime) - pd.to_datetime(new_bwh_df.ecg_date)\n",
    "new_bwh_df[['sample_id','ecg_date','partners_ecg_datetime', 'date_diff', 'num_zeros']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee43259",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bwh_df['date_diff'] = new_bwh_df['date_diff'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39731799",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bwh_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ce6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bwh_df = new_bwh_df[new_bwh_df.date_diff > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d7d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bwh_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bwh_df2 = new_bwh_df.sort_values('date_diff').groupby('sample_id').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bwh_df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b67fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_latent_df = new_latent_df.drop_duplicates(subset = [\"sample_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf51300",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_latent_df.info()\n",
    "new_bwh_df2.info()\n",
    "print([c for c in new_bwh_df2.columns if 'latent' not in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c64e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_latent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ed387",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = new_latent_df.sample(frac=0.5, random_state=1234)\n",
    "test = new_latent_df.drop(train.index)\n",
    "\n",
    "train_bwh = new_bwh_df2.sample(frac=0.5, random_state=1234)\n",
    "test_bwh = new_bwh_df2.drop(train_bwh.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac54c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([c for c in test_bwh.columns if 'latent' not in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23759952",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MGH Latent Space Zero Table total: {len(new_latent_df)}')\n",
    "for low,high,label in [(0,250,'7.5-10s'), (250,500,'2.5-7.5s'), (500,17500,'0-2.5s')]:\n",
    "    for c in new_latent_df:\n",
    "        if 'zeros' in c:\n",
    "            n = len(new_latent_df[(low < new_latent_df[c]) & (high > new_latent_df[c]) ])\n",
    "            print(f'For lead: {c} n: {n}   time no zeros {label}  Ratio: {n/len(new_latent_df):0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98147425",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'BWH Latent Space Zero Table total: {len(new_bwh_df2)}')\n",
    "for low,high,label in [(0,250,'7.5-10s'), (250,500,'2.5-7.5s'), (500,17500,'0-2.5s')]:\n",
    "    for c in new_bwh_df2:\n",
    "        if 'zeros' in c:\n",
    "            n = len(new_bwh_df2[(low < new_bwh_df2[c]) & (high > new_bwh_df2[c]) ])\n",
    "            print(f'For lead: {c} n: {n}   time no zeros {label}  Ratio: {n/len(new_bwh_df2):0.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b988c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_bwh_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8753b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_cols = [ 'BWH_MRN_0', 'linker_id', 'partners_ecg_datetime', 'white', 'partners_ecg_age', 'sex', \n",
    "#              'num_zeros', 'gender', 'patientage', 'ventricularrate_md', 'qrsduration_md', 'printerval_md',\n",
    "#              'qtinterval_md', 'paxis_md', 'raxis_md', 'taxis_md', 'weightlbs', 'heightin', 'ecg_date', 'time']\n",
    "# new_bwh_df2[keep_cols].to_csv('bwh_phewas_covariates.tsv', index=False, sep='\\t')\n",
    "# train_bwh[keep_cols].to_csv('bwh_derive_set_phewas_covariates.tsv', index=False, sep='\\t')\n",
    "# test_bwh[keep_cols].to_csv('bwh_validation_set_phewas_covariates.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([c for c in test_bwh.columns if 'latent' not in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a47e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_cols = ['MRN', 'linker_id', 'partners_ecg_datetime', 'white', 'partners_ecg_age', 'sex', \n",
    "#              'num_zeros', 'gender', 'patientage', 'ecg_date', 'time']\n",
    "keep_cols = [c for c in new_latent_df if 'latent' not in c]\n",
    "new_latent_df[keep_cols].to_csv('mgh_phewas_covariates_v2022_04_04.tsv', index=False, sep='\\t')\n",
    "# train[keep_cols].to_csv('mgh_derive_set_phewas_covariates.tsv', index=False, sep='\\t')\n",
    "# test[keep_cols].to_csv('mgh_validation_set_phewas_covariates.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25710909",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "mgh_pvals, mgh_betas, mgh_ses, mgh_counts, mgh_vectors, mgh_auc1, mgh_auc2 = merge_and_stratify_by_code_folder(\n",
    "    train, \n",
    "    test, \n",
    "    latent_cols, \n",
    "    adjust_cols, './drop_fuse_phecode_projections2/',\n",
    "    phe_folder='./phecodes/', \n",
    "    test_phe_folder='./phecodes/', \n",
    "    min_cases=1.1,\n",
    "    permute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "bwh_pvals, bwh_betas, bwh_ses, bwh_counts, bwh_vectors, bwh_auc1, bwh_auc2 = merge_and_stratify_by_code_folder(\n",
    "    train, \n",
    "    new_bwh_df2,\n",
    "    latent_cols, \n",
    "    adjust_cols,\n",
    "    './drop_fuse_phecode_projections2/',\n",
    "    phe_folder='./phecodes/',\n",
    "    test_phe_folder='./phecodes_bwh/',\n",
    "    min_cases=1.1, \n",
    "    permute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be7b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgh_intervals = pd.read_csv('all_ecgs_xin_20211217.csv')\n",
    "mgh_intervals.partners_ecg_datetime = pd.to_datetime(mgh_intervals.partners_ecg_datetime)\n",
    "mgh_intervals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db134898",
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in mgh_intervals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580d563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test, mgh_intervals[['LINKER_ID', 'partners_ecg_datetime', 'partners_ecg_qrs_md',\n",
    "                                     'partners_ecg_qt_md', 'partners_ecg_rate_md', 'partners_ecg_pr_md',\n",
    "                                    ]], \n",
    "                right_on =['LINKER_ID', 'partners_ecg_datetime'],\n",
    "                left_on =['LINKER_ID', 'datetime']\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747175c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in test if 'latent' not in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3648546",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_cols = ['partners_ecg_qrs_md']\n",
    "test[latent_cols] = test[latent_cols].astype(float)\n",
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "mgh_qrs_pvals, mgh_qrs_betas, mgh_qrs_ses, mgh_qrs_counts, _ = merge_and_stratify_by_code_folder(train, test, \n",
    "                                                                                           latent_cols, adjust_cols, \n",
    "                                                          './drop_fuse_phecode_projections2/',\n",
    "                                                          phe_folder='./phecodes/', \n",
    "                                                          test_phe_folder='./phecodes/', \n",
    "                                                          min_cases=1.1, permute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_cols = ['partners_ecg_qt_md']\n",
    "test[latent_cols] = test[latent_cols].astype(float)\n",
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "mgh_qt_pvals, mgh_qt_betas, mgh_qt_ses, mgh_qt_counts, _ = merge_and_stratify_by_code_folder(train, test, \n",
    "                                                                                           latent_cols, adjust_cols, \n",
    "                                                          './drop_fuse_phecode_projections2/',\n",
    "                                                          phe_folder='./phecodes/', \n",
    "                                                          test_phe_folder='./phecodes/', \n",
    "                                                          min_cases=1.1, permute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b03d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_cols = ['partners_ecg_pr_md']\n",
    "test[latent_cols] = test[latent_cols].astype(float)\n",
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "mgh_pr_pvals, mgh_pr_betas, mgh_pr_ses, mgh_pr_counts, _ = merge_and_stratify_by_code_folder(train, test, \n",
    "                                                                                           latent_cols, adjust_cols, \n",
    "                                                          './drop_fuse_phecode_projections2/',\n",
    "                                                          phe_folder='./phecodes/', \n",
    "                                                          test_phe_folder='./phecodes/', \n",
    "                                                          min_cases=1.1, permute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_cols = ['qrsduration_md']\n",
    "new_bwh_df2[latent_cols] = new_bwh_df2[latent_cols].astype(float)\n",
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "bwh_qrs_pvals, bwh_qrs_betas, bwh_qrs_ses, bwh_qrs_counts, _ = merge_and_stratify_by_code_folder(train, new_bwh_df2, \n",
    "                                                                                           latent_cols, adjust_cols, \n",
    "                                                          './drop_fuse_phecode_projections2/',\n",
    "                                                          phe_folder='./phecodes/', \n",
    "                                                          test_phe_folder='./phecodes_bwh/', \n",
    "                                                          min_cases=1.1, permute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b48985",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_cols = ['qtinterval_md']\n",
    "new_bwh_df2[latent_cols] = new_bwh_df2[latent_cols].astype(float)\n",
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "bwh_qt_pvals, bwh_qt_betas, bwh_qt_ses, bwh_qt_counts, _ = merge_and_stratify_by_code_folder(train, new_bwh_df2, \n",
    "                                                                                           latent_cols, adjust_cols, \n",
    "                                                          './drop_fuse_phecode_projections2/',\n",
    "                                                          phe_folder='./phecodes/', \n",
    "                                                          test_phe_folder='./phecodes_bwh/', \n",
    "                                                          min_cases=1.1, permute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0485391",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_cols = ['printerval_md']\n",
    "new_bwh_df2[latent_cols] = new_bwh_df2[latent_cols].astype(float)\n",
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "bwh_pr_pvals, bwh_pr_betas, bwh_pr_ses, bwh_pr_counts, _ = merge_and_stratify_by_code_folder(train, new_bwh_df2, \n",
    "                                                                                           latent_cols, adjust_cols, \n",
    "                                                          './drop_fuse_phecode_projections2/',\n",
    "                                                          phe_folder='./phecodes/', \n",
    "                                                          test_phe_folder='./phecodes_bwh/', \n",
    "                                                          min_cases=1.1, permute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b7a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "latent_dimension = 128\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "mgh_10s_pvals, mgh_10s_betas, mgh_10s_ses, mgh_10s_counts, mgh_10s_vectors = merge_and_stratify_by_code_folder(train, test, \n",
    "                                                                                           latent_cols, \n",
    "                                                 adjust_cols, './drop_fuse_phecode_projections2/',\n",
    "                                                 phe_folder='./phecodes/', \n",
    "                                                 test_phe_folder='./phecodes/', \n",
    "                                                 min_cases=100,\n",
    "                                                 permute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df121866",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "latent_dimension = 256\n",
    "mgh_lead_I_pvals, mgh_lead_I_betas, mgh_lead_I_ses, mgh_lead_I_counts, mgh_lead_I_vectors = merge_and_stratify_by_code_folder(train, test, \n",
    "                                                                                           latent_cols, \n",
    "                                                 adjust_cols, './drop_fuse_phecode_projections2/',\n",
    "                                                 phe_folder='./phecodes/', \n",
    "                                                 test_phe_folder='./phecodes/', \n",
    "                                                 min_cases=1.1,\n",
    "                                                 permute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "latent_dimension = 256\n",
    "latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "bwh_lead_I_pvals, bwh_lead_I_betas, bwh_lead_I_ses, bwh_lead_I_counts, bwh_lead_I_vectors = merge_and_stratify_by_code_folder(train, new_bwh_df2, \n",
    "                                                                                           latent_cols, adjust_cols, \n",
    "                                                          './drop_fuse_phecode_projections2/',\n",
    "                                                          phe_folder='./phecodes/', \n",
    "                                                          test_phe_folder='./phecodes_bwh/', \n",
    "                                                          min_cases=1.1, permute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "# bwh_wmgh_pvals, bwh_wmgh_betas, bwh_wmgh_ses, bwh_wmgh_counts, bwh_wmgh_vectors= merge_and_stratify_by_code_folder(train_bwh, test, latent_cols, adjust_cols, \n",
    "#                                                           './drop_fuse_phecode_projections2/',\n",
    "#                                                           phe_folder='./phecodes_bwh/', \n",
    "#                                                           test_phe_folder='./phecodes/', \n",
    "#                                                           min_cases=100, permute=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da79540",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "bwh_pvals, bwh_betas, bwh_ses, bwh_counts, bwh_vectors = merge_and_stratify_by_code_folder(train_bwh, test_bwh, \n",
    "                                                                                           latent_cols, adjust_cols, \n",
    "                                                          './drop_fuse_phecode_projections2/',\n",
    "                                                          phe_folder='./phecodes_bwh/', \n",
    "                                                          test_phe_folder='./phecodes_bwh/', \n",
    "                                                          min_cases=100, permute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c495314",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "permuted_ten = merge_and_stratify_by_code_folder(train, test, latent_cols, adjust_cols,\n",
    "                                             './drop_fuse_phecode_projections2/',\n",
    "                                                          phe_folder='./phecodes/', \n",
    "                                                          test_phe_folder='./phecodes/', \n",
    "                                                          min_cases=100, permute=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58159cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "permuted_twenty = merge_and_stratify_by_code_folder(train, test, latent_cols, adjust_cols,\n",
    "                                             './drop_fuse_phecode_projections2/',\n",
    "                                                          phe_folder='./phecodes/', \n",
    "                                                          test_phe_folder='./phecodes/', \n",
    "                                                          min_cases=100, permute=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc37c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "permuted_none = merge_and_stratify_by_code_folder(train, test, latent_cols, adjust_cols,\n",
    "                                             './drop_fuse_phecode_projections2/',\n",
    "                                                          phe_folder='./phecodes/', \n",
    "                                                          test_phe_folder='./phecodes/', \n",
    "                                                          min_cases=100, permute=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c70c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_cols = ['partners_ecg_age', 'age_sqr', 'sex_int', 'white', 'num_zeros', 'time']\n",
    "permuted_fifty = merge_and_stratify_by_code_folder(train, test, latent_cols, adjust_cols,\n",
    "                                             './drop_fuse_phecode_projections2/',\n",
    "                                                          phe_folder='./phecodes/', \n",
    "                                                          test_phe_folder='./phecodes/', \n",
    "                                                          min_cases=100, permute=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7537c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "phecode_meta = pd.read_csv('phecode_definitions.csv') \n",
    "cat_colors= {}\n",
    "for i,k in enumerate(phecode_meta.category.value_counts().keys()):\n",
    "    cat_colors[k] = i\n",
    "    #print(f'{i} {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3dc89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phecode_dicts(pval_dict):\n",
    "    categories = defaultdict(list)\n",
    "    categories_text = defaultdict(list)\n",
    "\n",
    "    for phe, pval in sorted(pval_dict.items(), key=operator.itemgetter(1)):\n",
    "        print(f\"phe is {phe.replace('phe_', '').replace('_', '.')}\")\n",
    "        row = phecode_meta[phecode_meta.phecode == float(phe.replace('phe_', '').replace('_', '.'))].iloc[0]\n",
    "        if row.category in cat_colors:\n",
    "            categories[row.category].append(pval)\n",
    "            categories_text[row.category].append(row.phenotype)\n",
    "            print(f'category: {row.category}\\n phenotype: {row.phenotype}  phecode is {phe} and pvalue {pval:0.4E}\\n' )\n",
    "    return categories, categories_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f34273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_phewas(pvals, betas, ses, counts, vectors, auc1, auc2, file_name, latent_dim=0):\n",
    "    tuples = []\n",
    "    for phe, pval in sorted(pvals.items(), key=operator.itemgetter(1)):\n",
    "\n",
    "        row = phecode_meta[phecode_meta.phecode == float(phe.replace('phe_', '').replace('_', '.'))].iloc[0]\n",
    "        if row.category in cat_colors:\n",
    "            cols = [row.phecode, phe, pval, row.phenotype, row.category, \n",
    "                    counts[phe], betas[phe], ses[phe], auc1[phe], auc2[phe],\n",
    "                   ] + [vectors[phe][i] for i in range(latent_dim)]\n",
    "            tuples.append(tuple(cols))\n",
    "    headers = ['phecode', 'phecode_text', 'p_value', 'phenotype', 'category', \n",
    "               'n', 'beta', 'se', 'AUC_with_ECG', 'AUC_no_ECG'] + [f'pv_{i}' for i in range(latent_dim)]\n",
    "    df = pd.DataFrame(tuples, columns = headers)\n",
    "    df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6294702",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phewas(mgh_pvals, mgh_betas, mgh_ses, mgh_counts, mgh_vectors, \n",
    "             './phewas_lead_I_mgh_with_mgh_v2022_05_25.csv')\n",
    "write_phewas(mgh_pvals, mgh_betas, mgh_ses, mgh_counts, mgh_vectors,\n",
    "             './phewas_lead_I_mgh_with_mgh_plus_vectors_v2022_05_25.csv', \n",
    "             latent_dim=256)\n",
    "write_phewas(bwh_pvals, bwh_betas, bwh_ses, bwh_counts, bwh_vectors, \n",
    "             './phewas_lead_I_bwh_with_mgh_v2022_05_25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phewas(mgh_pvals, mgh_betas, mgh_ses, mgh_counts, mgh_vectors, mgh_auc1, mgh_auc2,\n",
    "             './phewas_mgh_with_mgh_v2022_11_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1087d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phewas(bwh_pvals, bwh_betas, bwh_ses, bwh_counts, bwh_vectors, bwh_auc1, bwh_auc2, \n",
    "             './phewas_bwh_with_mgh_v2022_11_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phewas(bwh_qrs_pvals, bwh_qrs_betas, bwh_qrs_ses, bwh_qrs_counts, _, \n",
    "             './phewas_bwh_qrs.csv')\n",
    "write_phewas(bwh_qt_pvals, bwh_qt_betas, bwh_qt_ses, bwh_qt_counts, _, \n",
    "             './phewas_bwh_qt.csv')\n",
    "write_phewas(bwh_pr_pvals, bwh_pr_betas, bwh_pr_ses, bwh_pr_counts, _, \n",
    "             './phewas_bwh_pq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9451f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phewas(mgh_qt_pvals, mgh_qt_betas, mgh_qt_ses, mgh_qt_counts, _, \n",
    "             './phewas_mgh_qt.csv')\n",
    "write_phewas(mgh_pr_pvals, mgh_pr_betas, mgh_pr_ses, mgh_pr_counts, _, \n",
    "             './phewas_mgh_pq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10396a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phewas(mgh_lead_I_pvals, mgh_lead_I_betas, mgh_lead_I_ses, mgh_lead_I_counts, mgh_lead_I_vectors, \n",
    "             './phewas_mgh_with_mgh_lead_I_v2022_04_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phewas(mgh_lead_I_pvals, mgh_lead_I_betas, mgh_lead_I_ses, mgh_lead_I_counts, mgh_lead_I_vectors,\n",
    "             './phewas_mgh_with_mgh_lead_I_plus_vectors_v2022_04_12.csv', \n",
    "             latent_dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_phewas(bwh_lead_I_pvals, bwh_lead_I_betas, bwh_lead_I_ses, bwh_lead_I_counts, bwh_lead_I_vectors, \n",
    "             './phewas_bwh_with_mgh_lead_I_v2022_04_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7e08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "permed = []\n",
    "for pvals in [permuted_none, permuted_ten, permuted_twenty, permuted_fifty]:\n",
    "    permed.append(phecode_dicts(pvals[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bwh_cat, bwh_text = phecode_dicts(bwh_pvals)\n",
    "mgh_cat, mgh_text = phecode_dicts(mgh_pvals)\n",
    "#bwh_lead_I_cat, bwh_lead_I_text = phecode_dicts(bwh_lead_I_pvals)\n",
    "#mgh_lead_I_cat, mgh_lead_I_text = phecode_dicts(mgh_lead_I_pvals)\n",
    "\n",
    "#mgh_10s_cat, mgh_10s_text = phecode_dicts(mgh_10s_pvals)\n",
    "#val_bwh_cat, val_bwh_text = phecode_dicts(adjusted_bwh_from_mgh)\n",
    "#less_val_bwh_cat, less_val_bwh_text = phecode_dicts(less_adjusted_bwh_from_mgh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092630c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qq_plot_theoretical(categories, text, title='QQ Plot', p_thresh=4):\n",
    "    #p_thresh=-np.log(1/len(text))\n",
    "    fig, ax = plt.subplots(figsize=(18, 10), dpi=300)\n",
    "    sort_cat = sorted(categories.items(), key=operator.itemgetter(0))\n",
    "    \n",
    "    annotations = []\n",
    "    x_offsets = [0]\n",
    "    x_labels = []\n",
    "    for i, (k,v) in enumerate(sort_cat):\n",
    "        if len(categories[k]) < 3:\n",
    "            continue\n",
    "        neglog10p = -np.log10(np.array(categories[k])+1e-300)\n",
    "        expected = -np.log10(np.arange(1.0/len(categories[k]), 1+1e-8, 1.0/len(categories[k]))) + x_offsets[-1]\n",
    "        #print(f'{x_offset} expected {len(expected)}  neglog10p {len(neglog10p)} \\n EXpected {expected[0]}')\n",
    "        ax.scatter(sorted(expected[:len(neglog10p)], reverse=True), sorted(neglog10p[:len(expected)], reverse=True), label=k)\n",
    "        ax.plot([x_offsets[-1], expected[0]],[0, 1]) \n",
    "        x_offsets.append(expected[0] + 0.2)\n",
    "        x_labels.append(k)\n",
    "        for j, txt in enumerate(text[k]):\n",
    "            if neglog10p[j] > p_thresh:\n",
    "                annotations.append(ax.annotate(txt, xy=(expected[j], neglog10p[j])))\n",
    "    print(f'Total hits: {len(annotations)} at thresh: {p_thresh}')            \n",
    "    ax.set_xticks(x_offsets[:-1])\n",
    "    ax.set_xticklabels(x_labels, rotation=30, ha='right')\n",
    "    #plt.ylim(0, 15)\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Expected -log10(P_value) per PheCode category')\n",
    "    ax.set_ylabel('Observed -log10(P_value) per PheCode category')\n",
    "    mask = np.zeros(fig.canvas.get_width_height(), bool)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    for a in annotations:\n",
    "        bbox = a.get_window_extent(renderer=fig.canvas.get_renderer())\n",
    "        if not np.isinf(bbox.x0): \n",
    "            x0 = int(bbox.x0)\n",
    "            x1 = int(math.ceil(bbox.x1))\n",
    "            y0 = int(bbox.y0)\n",
    "            y1 = int(math.ceil(bbox.y1))\n",
    "\n",
    "            s = np.s_[x0:x1+1, y0:y1+1]\n",
    "            if np.any(mask[s]):\n",
    "                a.set_visible(False)\n",
    "            else:\n",
    "                mask[s] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398031d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(mgh_cat, mgh_text,  'MGH Phenotype Vectors PheWAS in MGH, C3PO MGH Trained Biosppy Median ECG Autoencoder Latent Space')\n",
    "qq_plot_theoretical(bwh_cat, bwh_text,  'MGH Phenotype Vectors PheWAS in BWH, C3PO MGH Trained Biosppy Median ECG Autoencoder Latent Space')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43fcc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(mgh_cat, mgh_text,  'MGH Phenotype Vectors PheWAS in MGH, C3PO MGH Trained Biosppy Median ECG Autoencoder Latent Space')\n",
    "qq_plot_theoretical(bwh_cat, bwh_text,  'MGH Phenotype Vectors PheWAS in BWH, C3PO MGH Trained Biosppy Median ECG Autoencoder Latent Space')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(mgh_cat, mgh_text,  'MGH Phenotype Vectors PheWAS in MGH, C3PO MGH Trained Median ECG Autoencoder Latent Space')\n",
    "qq_plot_theoretical(bwh_cat, bwh_text,  'MGH Phenotype Vectors PheWAS in BWH, C3PO MGH Trained Median ECG Autoencoder Latent Space')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644470cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(mgh_lead_I_cat, mgh_lead_I_text, \n",
    "                    'Lead I MGH Phenotype Vectors PheWAS in MGH, MGH Lead I Median Trained ECG Autoencoder Latent Space')\n",
    "qq_plot_theoretical(bwh_lead_I_cat, bwh_lead_I_text, \n",
    "                    'Lead I MGH Phenotype Vectors PheWAS in BWH, MGH Lead I Median Trained ECG Autoencoder Latent Space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(bwh_cat, bwh_text, \n",
    "                    'BWH Phenotype Vectors PheWAS in BWH, MGH Biosppy Median Trained ECG Autoencoder Latent Space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(bwh_cat, bwh_text, \n",
    "                    'BWH Phenotype Vectors PheWAS in BWH, MGH Biosppy Median Trained ECG Autoencoder Latent Space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(mgh_cat, mgh_text,  'MGH Phenotype Vectors PheWAS in MGH, C3PO MGH Trained Median ECG Autoencoder Latent Space')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2b9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(mgh_10s_cat, mgh_10s_text, 'MGH -> MGH ECG Autoencoder Phenotype Vecter PheWAS Cases > 100 prevalent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01193750",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(mgh_cat, mgh_text,  'MGH Phenotype Vectors PheWAS in MGH, C3PO MGH Trained ECG Autoencoder Latent Space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(val_bwh_cat, val_bwh_text, 'MGH -> BWH ECG Autoencoder Phenotype Vector PheWAS Cases > 1% prevalent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c51586",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(permuted_cat, permuted_text, 'Permuted Phecode Labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(permed[0][0], permed[0][1], 'Baseline Phewas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f48d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(permed[1][0], permed[1][1], 'PheWAS with 10% Noisy Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(permed[2][0], permed[2][1], 'PheWAS with 20% Noisy Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca5f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plot_theoretical(permed[3][0], permed[3][1], 'PheWAS with 100% Noisy Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links = pd.read_csv('mrn_linker.txt', sep='\\t')\n",
    "# latent = pd.read_csv('mgh_drop_fuse_latent_space_mv.csv')\n",
    "# latent_df = pd.merge(latent, links, left_on='MGH_MRN_0', right_on='MRN', how='inner')\n",
    "# latent_dimension = 256\n",
    "# latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "# merge_and_stratify_by_code_folder(latent_df, latent_cols, './drop_fuse_phecode_projections_mv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links = pd.read_csv('mrn_linker.txt', sep='\\t')\n",
    "# latent = pd.read_csv('mgh_drop_fuse_latent_space_uni.csv')\n",
    "# latent_df = pd.merge(latent, links, left_on='MGH_MRN_0', right_on='MRN', how='inner')\n",
    "# latent_dimension = 256\n",
    "# latent_cols = [f'latent_{i}' for i in range(latent_dimension)]\n",
    "# merge_and_stratify_by_code_folder(latent_df, latent_cols, './drop_fuse_phecode_projections_uni/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9072d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = pd.read_csv('mgh_drop_fuse_latent_space.csv')\n",
    "latent.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7522a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(latent, links, left_on='MGH_MRN_0', right_on='MRN', how='inner')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ECG + MRI union GWAS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
